<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Apple Silicon MacBook Pro新机配置</title>
    <url>/2022/07/31/apple-silicon-macbook-pro-xin-ji-pei-zhi/</url>
    <content><![CDATA[<blockquote>
<p>本文记录下由intel转移到m1的过程中重装各种环境和工具的命令和配置</p>
</blockquote>
<aside>
💡 第一次使用苹果的time
machine进行迁移，给我的感觉就像把旧电脑的硬盘直接摆在面前一样，迁移文件很好用
</aside>
<h1 id="配置git">配置git</h1>
<p>mac自带git，所以只需要配置下用户名和邮箱</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git config --global user.name <span class="hljs-string">&quot;John Doe&quot;</span><br>git config --global user.email <span class="hljs-string">&quot;johndoe@example.com&quot;</span><br></code></pre></td></tr></table></figure>
<h1 id="安装brew">安装brew</h1>
<p><a href="https://brew.sh/index_zh-cn">Homebrew</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">/bin/bash -c <span class="hljs-string">&quot;<span class="hljs-subst">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)</span>&quot;</span><br></code></pre></td></tr></table></figure>
<p>根据返回的最后内容执行提示的代码，将brew添加到path中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;eval &quot;$(/opt/homebrew/bin/brew shellenv)&quot;&#x27;</span> &gt;&gt; /Users/ashone/.zprofile<br></code></pre></td></tr></table></figure>
<p>最后在终端中输入brew测试是否添加成功</p>
<h1 id="安装iterm2">安装iTerm2</h1>
<p><a href="https://iterm2.com/index.html">iTerm2 - macOS Terminal
Replacement</a></p>
<h1 id="安装oh-my-zsh">安装oh-my-zsh</h1>
<p><a href="https://ohmyz.sh/#install">Oh My Zsh - a delightful &amp;
open source framework for Zsh</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sh -c <span class="hljs-string">&quot;<span class="hljs-subst">$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)</span>&quot;</span><br></code></pre></td></tr></table></figure>
<h1 id="安装zsh主题">安装zsh主题</h1>
<p>我选择安装powerlevel10k主题，链接在这里https://github.com/romkatv/powerlevel10k</p>
<ol type="1">
<li><p>安装字体（可跳过）</p>
<p><a href="https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Regular.ttf">MesloLGS
NF Regular.ttf</a></p>
<p><a href="https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold.ttf">MesloLGS
NF Bold.ttf</a></p>
<p><a href="https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Italic.ttf">MesloLGS
NF Italic.ttf</a></p>
<p><a href="https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold%20Italic.ttf">MesloLGS
NF Bold Italic.ttf</a></p></li>
<li><p>手动安装主题文件</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> --depth=1 https://github.com/romkatv/powerlevel10k.git <span class="hljs-variable">$&#123;ZSH_CUSTOM:-<span class="hljs-variable">$HOME</span>/.oh-my-zsh/custom&#125;</span>/themes/powerlevel10k<br></code></pre></td></tr></table></figure></p></li>
<li><p>编辑配置文件，修改主题为10k</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">code ~/.zshrc<br></code></pre></td></tr></table></figure></p>
<p>也可以使用其他编辑器打开这个文件</p>
<p>然后找到第11行修改主题为</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">powerlevel10k/powerlevel10k<br></code></pre></td></tr></table></figure></p></li>
<li><p>重启iterm，加载主题文件</p>
<p><img src="/2022/07/31/apple-silicon-macbook-pro-xin-ji-pei-zhi/Untitled.png"></p></li>
<li><p>依次根据样式进行配置</p></li>
<li><p>重启iterm就可以看到崭新的主题了</p></li>
</ol>
<h1 id="安装oh-my-zsh自动补全插件">安装oh-my-zsh自动补全插件</h1>
<p><a href="https://github.com/zsh-users/zsh-autosuggestions">GitHub -
zsh-users/zsh-autosuggestions: Fish-like autosuggestions for zsh</a></p>
<ol type="1">
<li><p>下载插件</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/zsh-users/zsh-autosuggestions <span class="hljs-variable">$&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;</span>/plugins/zsh-autosuggestions<br></code></pre></td></tr></table></figure></p></li>
<li><p>编辑zshrc配置文件，增加插件，修改配色</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">code ~/.zshrc<br></code></pre></td></tr></table></figure></p>
<p><figure class="highlight makefile"><table><tr><td class="code"><pre><code class="hljs makefile">plugins=( <br>    <span class="hljs-comment"># other plugins...</span><br>    zsh-autosuggestions<br>)<br><span class="hljs-comment"># 此处修改autosuggestions插件的配色</span><br>ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE=<span class="hljs-string">&quot;fg=#d0d0d0,underline&quot;</span><br></code></pre></td></tr></table></figure></p></li>
<li><p>重开iterm</p></li>
</ol>
<p>查看效果：</p>
<p><img src="/2022/07/31/apple-silicon-macbook-pro-xin-ji-pei-zhi/Untitled%201.png"></p>
<h1 id="配置python和conda">配置python和conda</h1>
<p><a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda -
Conda documentation</a></p>
<h2 id="安装miniconda对应版本的pkg双击后直接安装在终端测试conda命令是否正常">安装miniconda对应版本的pkg，双击后直接安装，在终端测试conda命令是否正常</h2>
<h2 id="查看conda环境-创建新python环境">查看conda环境,
创建新python环境</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">conda <span class="hljs-built_in">env</span> list<br>conda create -n your_env_name python=x.x<br><br>conda activate dl<br>conda deactivate<br></code></pre></td></tr></table></figure>
<h1 id="安装pytorchapple-silicon版本">安装pytorch（Apple
Silicon版本）</h1>
<p><a href="https://pytorch.org/">PyTorch</a></p>
<p><img src="/2022/07/31/apple-silicon-macbook-pro-xin-ji-pei-zhi/Untitled%202.png"></p>
<p>pytorch从1.13版本开始支持苹果芯片gpu加速,目前（7.30）还得安装nightly版本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">conda install pytorch -c pytorch-nightly<br></code></pre></td></tr></table></figure>
<p>用python测试查看版本号，torch版本为1.13开发版就代表安装成功</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">❯ python<br>Python 3.8.13 (default, Mar 28 2022, 06:13:39)<br>[Clang 12.0.0 ] :: Anaconda, Inc. on darwin<br>Type <span class="hljs-string">&quot;help&quot;</span>, <span class="hljs-string">&quot;copyright&quot;</span>, <span class="hljs-string">&quot;credits&quot;</span> or <span class="hljs-string">&quot;license&quot;</span> <span class="hljs-keyword">for</span> more information.<br>&gt;&gt;&gt; import torch<br>&gt;&gt;&gt; torch.__version__<br><span class="hljs-string">&#x27;1.13.0.dev20220729&#x27;</span><br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Apple</tag>
        <tag>配置</tag>
        <tag>conda</tag>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title>Arch/Manjaro系统ssh断开后tmux会话中断的问题</title>
    <url>/2023/06/20/arch-manjaro-xi-tong-ssh-duan-kai-hou-tmux-hui-hua-zhong-duan-de-wen-ti/</url>
    <content><![CDATA[<h1 id="问题">问题</h1>
<p>系统：Manjaro或Arch</p>
<p>桌面系统：<strong>Gnome</strong>（万恶之源）</p>
<p>描述：通过SSH连接到Manjaro上并开启tmux会话，每次在tmux
detach后也认真<code>tmux ls</code>发现session保存才敢下线，但是发现ssh
log out后所有的session都没有被保存下来。</p>
<p>其实是一个经历许久的问题，应该是遇到相同问题的人不太多，今天终于花时间找到了解决方案。</p>
<h1 id="解决方案">解决方案</h1>
<p>原帖在这里，大家不走弯路直接看社区的解决方案：<a href="https://forum.manjaro.org/t/how-to-keep-tmux-running-after-ssh-is-disconnected/123225">post</a></p>
<p>修改这个文件<code>/etc/systemd/logind.conf.d/20-kill-user-processes.conf</code>成图中的样子，其实只修改了一个地方，就是把<code>KillUserProcesses=</code>后面的<strong>yes</strong>改为了<strong>no</strong>。或者你也可以像社区一样，<em>直接把这个该死的文件删除</em>。</p>
<figure>
<img src="/2023/06/20/arch-manjaro-xi-tong-ssh-duan-kai-hou-tmux-hui-hua-zhong-duan-de-wen-ti/tmux.png" alt="修改yes为no">
<figcaption aria-hidden="true">修改yes为no</figcaption>
</figure>
<p>然后重启manjaro应该就解决了。</p>
<h1 id="分析">分析</h1>
<p>原帖里遇到的问题和我是一样的，在其他系统的机器上tmux都不会在ssh log
out后关闭会话。只有这个manjaro系统（的Gnome桌面，因为其他朋友用KDE桌面还真没有这个问题）。</p>
<p>然后我修改了<code>tmux.conf</code>文件没用，修改<code>systemd/logind.conf</code>中的·KillUserProcesses·也没用，中途还遇到了网卡bug害得我以为要寄了，结果是GNOME搞得鬼，生成的conf文件覆盖了原本的配置。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>tmux</tag>
        <tag>Manjaro</tag>
        <tag>Linux</tag>
        <tag>SSH</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>ESPNet代码结构（Recipe）</title>
    <url>/2023/07/23/espnet-dai-ma-jie-gou-recipe/</url>
    <content><![CDATA[<h1 id="文件结构介绍">文件结构介绍</h1>
<p><img src="/2023/07/23/espnet-dai-ma-jie-gou-recipe/ code-structure.png" alt="recipe结构" style="zoom:40%;"></p>
<p>图中表示ESPNet的文件目录结构</p>
<p>在<code>corpus-name</code>下，任务文件夹<code>enh1</code>表示用于语音增强任务（单人增强，多人分离）</p>
<p><code>conf</code>表示模型训练和推理时用到的配置文件</p>
<p><code>local</code>表示与该语音数据集相关的准备脚本</p>
<p><code>data</code>表示在代码运行过程中产生的Kaldi格式的运行文件</p>
<p><code>dump</code>表示对data目录中内容进行进一步处理后得到的数据文件</p>
<p><code>exp</code>存放实验相关的文件</p>
<p><code>enh.sh</code>模板脚本</p>
<p><code>run.sh</code>入口脚本文件，向模板文件输入数据</p>
<p><img src="/2023/07/23/espnet-dai-ma-jie-gou-recipe/model- structure.png" alt="模型" style="zoom:40%;"></p>
<p>图中表示模型部分的三大重点结构</p>
<p><code>bin</code>python脚本入口，调用tasks中的py</p>
<p><code>tasks/enh.py</code>表示任务，调用下层的文件</p>
<p><code>enh/espnet_model.py</code>表示模型</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>语音</tag>
        <tag>ESPNet</tag>
      </tags>
  </entry>
  <entry>
    <title>富有表现力的语音合成系统（Expressive TTS）</title>
    <url>/2023/02/10/expressive-tts/</url>
    <content><![CDATA[<h1 id="富有表现力的语音合成系统">富有表现力的语音合成系统</h1>
<h2 id="tacotron-gst">Tacotron-GST</h2>
<p>在Tacotron引入了<strong>全局风格标签（Global Style
Token，GST）</strong>。模型包括reference encoder，style attention，style
embedding</p>
<figure>
<img src="/2023/02/10/expressive-tts/tacotron-gst.png" alt="Tacotron-GST模型结构">
<figcaption aria-hidden="true">Tacotron-GST模型结构</figcaption>
</figure>
<h2 id="styletoken-tts">StyleToken-TTS</h2>
<p>在数据集上增加<strong>风格标签</strong>，代表话语风格的短语或词，例如情感、意图和语调。由于风格是用自然语言标记的，因此控制说话风格是直观和可解释的。</p>
<p>使用的韩语数据集<strong>FSNR0</strong>，内容为三元组 {speech,
transcript, style tag} ，有 327
个风格标签，包括各种情绪、意图、语音语调和速度。</p>
<figure>
<img src="/2023/02/10/expressive-tts/截屏2023-02-10%2013.51.22.png" alt="ST-TTS模型结构">
<figcaption aria-hidden="true">ST-TTS模型结构</figcaption>
</figure>
<h2 id="prompttts">PromptTTS</h2>
<p>使用微软的TTS合成语音<a href="https://speechresearch.github.io/prompttts/">自建数据集</a>，在LibriSpeech的真人数据上做验证。</p>
<p>其风格提示词假定有五个风格相关内容，如高声调、女声</p>
<p>用<code>[CLS]</code>Token学习隐藏的风格表示，BERT经过微调，用于输出五个风格相关特征</p>
<figure>
<img src="/2023/02/10/expressive-tts/prompt-tts.png" alt="Prompt-TTS模型结构">
<figcaption aria-hidden="true">Prompt-TTS模型结构</figcaption>
</figure>
<p>其中Content Encoder顶层的Variance
Adaptor来自FastSpeech2，用于预测持续时间、音高、能量等。</p>
<p><img src="/2023/02/10/expressive-tts/image-20230407211240554.png" alt="FastSpeech2" style="zoom: 33%;"></p>
<h2 id="instructtts">InstructTTS</h2>
<p>香港中文大学+腾讯AI Lab合作</p>
<p>demo地址：<a href="http://dongchaoyang.top/InstructTTS/">http://dongchaoyang.top/InstructTTS/</a></p>
<p>使用自然语言作为提示，指导语音合成的情绪，提示句包含整体感知情绪、话语情感水平、话语风格，每条语音由五个人写出提示句。<strong>NLSpeech内部数据集</strong>时长约44小时。</p>
<figure>
<img src="/2023/02/10/expressive-tts/截屏2023-02-10%2013.23.58.png" alt="InstructTTS">
<figcaption aria-hidden="true">InstructTTS</figcaption>
</figure>
<figure>
<img src="/2023/02/10/expressive-tts/截屏2023-02-10%2014.26.38.png" alt="模型结构">
<figcaption aria-hidden="true">模型结构</figcaption>
</figure>
<p><img src="/2023/02/10/expressive-tts/截屏2023-02-17 13.20.26.png" alt="Mel-VQ-VAE" style="zoom: 67%;"></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>语音合成</tag>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>Flutter学习笔记</title>
    <url>/2021/09/28/flutter-xue-xi-bi-ji/</url>
    <content><![CDATA[<h1 id="flutter学习笔记">Flutter学习笔记</h1>
<h2 id="statelesswidget和statefulwidget">StatelessWidget和StatefulWidget</h2>
<ul>
<li>StatelessWidget在创建之后将不会更改，想要更改只能new一个新的做替换。<br>
</li>
<li>StatefulWidget通过在State类中调用setState((){})更新视图，触发State.build，将整个组件重新绘制，<strong>同时会导致所有子组件重新构造生成，该结点的兄弟结点组件也会被重新构造</strong>。</li>
</ul>
<h2 id="开发时如何选择">开发时如何选择</h2>
<ul>
<li>优先使用 StatelessWidget<br>
</li>
<li>含有大量子 Widget（如根布局、次根布局）慎用 SatefulWidget</li>
<li>尽量在叶子节点时使用 StatefulWidget</li>
<li>将会调用到setState((){})
的代码尽可能的和要更新的视图封装在一个尽可能小的模块里</li>
<li>如果一个Widget需要reBuild，那么它的子节点、兄弟节点、兄弟节点的子节点应该尽可能少</li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Flutter</tag>
        <tag>Dart</tag>
      </tags>
  </entry>
  <entry>
    <title>GitLab本地部署（1）Docker部署和配置</title>
    <url>/2023/10/01/gitlab-ben-di-bu-shu-1-docker-bu-shu-he-pei-zhi/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>本地部署Git仓库和管理对于程序员来说一直是很重要的，毕竟一些私人代码哪怕放到私有仓库里依然难以给人安全感。在体验了Gitea和Gitlab两个不同的工具之后我选择了Gitlab-CE版本。</p>
<p><img src="/2023/10/01/gitlab-ben-di-bu-shu-1-docker-bu-shu-he-pei-zhi/image-20231001213601432-6167369.png" alt="两个仓库项目的镜像大小对比" style="zoom: 67%;"></p>
<p>首先是gitea需要额外设置mysql数据库，不过由于比较轻量化，启动速度很快，并且占用的内存大约200MB；而gitlab直接部署就可以使用，但是启动耗时较长，占用内存经常超过5GB，重量了许多。当前没有选择这个版本的gitea原因是某次调整配置重启后无法打开管理界面，最后还是回到了小狐狸的怀抱。</p>
<h1 id="docker部署在黑群晖上">Docker部署在黑群晖上</h1>
<p>在群晖系统上运行docker也是轻松又惬意，下面是一些需要配置的内容做参考：</p>
<p><img src="/2023/10/01/gitlab-ben-di-bu-shu-1-docker-bu-shu-he-pei-zhi/image-20231001214248311-6167770.png" alt="端口参考" style="zoom:67%;"></p>
<p>22，443，和80端口是需要放出来的，我这里由于后面需要调整内网的端口转发和LFS的需求，不使用默认的80端口，如果读者和我相同需求，最好容器和本地端口配置为相同的。</p>
<p><img src="/2023/10/01/gitlab-ben-di-bu-shu-1-docker-bu-shu-he-pei-zhi/image-20231001214520189-6167921.png" alt="路径参考" style="zoom:67%;"></p>
<p>三个文件夹是需要提前都在群晖上配置好的。其他的配置都使用默认即可，十分简单。</p>
<p>如果读者这里使用默认80端口，启动后一分钟就可以在ip:57080端口访问到gitlab首页了，第一次登陆需要用root账户，root密码在我们刚刚配置的<code>docker/gitlab/config/initial_root_password</code>中，这个是不能修改的。通常我们不用这个root账户，而是在控制台里新建一个账户，分配管理员权限。</p>
<blockquote>
<p>这里网络上很多教程，我就跳过不写了，不同版本的gitlab-ce界面不太一样</p>
</blockquote>
<p>如果像我一样调整了端口，就还需要进入配置文件修改nginx的监听端口，<strong>不然是没法使用LFS的</strong></p>
<p>这里可以进入群晖的<code>docker/gitlab/config/</code>找到gitlab.rb文件下载后进行修改覆盖(上传后记得修改这个文件的读写权限给admin用户)，也可以直接在运行的docker内调整，调整内容是一样的</p>
<p><img src="/2023/10/01/gitlab-ben-di-bu-shu-1-docker-bu-shu-he-pei-zhi/image-20231001214846991-6168128.png" alt="终端机" style="zoom:67%;"></p>
<p>进入docker的终端机新增一个bash，输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">vi /etc/gitlab/gitlab.rb<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这整个文件都是带#号的，<strong>注意一定要去掉每行前面的#</strong></p>
</blockquote>
<p>在<strong>32行</strong>应该是配置<code>external_url</code>，我这里修改为<code>external_url 'http://192.168.1.xx:57080'</code></p>
<p>此外还需要调整<code>nginx['listen_port']</code>，我这里在<strong>1467行</strong>，把值修改为57080对应上自己的配置。</p>
<p>之后在内网环境内通过<code>ip:端口</code>的方式就可以正常进入web首页了～</p>
<figure>
<img src="/2023/10/01/gitlab-ben-di-bu-shu-1-docker-bu-shu-he-pei-zhi/image-20231008192838639-6764524.png" alt="web端可以显示克隆地址，但是只会显示external_url的配置">
<figcaption aria-hidden="true">web端可以显示克隆地址，但是只会显示external_url的配置</figcaption>
</figure>
<p><strong>不过这个方法的缺点是仓库地址中的克隆地址是内网的地址，如果在外网克隆需要手动修改为SSH
host或者外网的ip/域名等</strong>，有一些其他方法（https://zhuanlan.zhihu.com/p/109834567）能解决这个问题，但是对于Git
LFS是无效的，本文的方法是我自用没有问题的方法。</p>
<p>下一篇内容是配置路由器上的端口转发，使得在更大的局域网（如校园网）内可以访问。</p>
<h1 id="相关链接">相关链接</h1>
<p>需要详细配置的可以参考下面的链接：</p>
<p>https://forums.docker.com/t/gitlab-lfs-dial-tco-error/102263</p>
<p>https://docs.gitlab.com/omnibus/settings/configuration.html</p>
<p>https://zhuanlan.zhihu.com/p/486410391</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
        <tag>Docker</tag>
        <tag>群晖</tag>
      </tags>
  </entry>
  <entry>
    <title>Github Pages与Hexo deploy的一点小问题</title>
    <url>/2023/04/16/github-pages-yu-hexo-deploy-de-yi-dian-xiao-wen-ti/</url>
    <content><![CDATA[<h1 id="前情提要">前情提要</h1>
<blockquote>
<p>顺便如果你还没撸过这个学生党羊毛：https://education.github.com/pack/offers</p>
<p>一共有三家域名商给提供这个羊毛，慢慢撸</p>
</blockquote>
<p>前段时间想玩玩域名，于是趁着GitHub学生包还在赶紧撸两个免费的一年域名。简单的注册域名绑定在GitHub
Pages上之后就没有再deploy到仓库上新的博文，只是在本地修改过，于是忘记了有这么一回事。</p>
<p>namecheap这家域名商在用学生包注册时很鸡贼地补充一句：<strong>现在是唯一将你域名和GitHub
Pages绑定的时机</strong></p>
<p>其实，在博客的仓库setting下手动设置Custom domain并没有多复杂。</p>
<p><strong>直到今天我在deploy了hexo的修改后，发现域名下的博客怎么404了</strong></p>
<figure>
<img src="/2023/04/16/github-pages-yu-hexo-deploy-de-yi-dian-xiao-wen-ti/404.png" alt="404">
<figcaption aria-hidden="true">404</figcaption>
</figure>
<h1 id="省流版">省流版</h1>
<p>Hexo有针对配置GitHub Pages定制域名的方法，在这个<a href="https://github.com/hexojs/hexo/issues/4121">issue</a>中提到：在Hexo目录下的<code>source</code>目录中创建<code>CNAME</code>文件，并将域名写入，之后的每次构建和部署都会带有域名信息。</p>
<figure>
<img src="/2023/04/16/github-pages-yu-hexo-deploy-de-yi-dian-xiao-wen-ti/cname.png" alt="cname">
<figcaption aria-hidden="true">cname</figcaption>
</figure>
<h1 id="问题排查">问题排查</h1>
<ol type="1">
<li><p><strong>怀疑是Hexo构建出了问题</strong>，但是404应该是<code>index.html</code>不正常才会有的问题</p>
<p><code>hexo clean</code>然后重新<code>hexo g</code>
<code>hexo d</code>，然后发现暴露出了另一个错误：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[master b137740] Site updated: 2023-04-16 15:33:52<br> 2 files changed, 792 insertions(+), 796 deletions(-)<br>kex_exchange_identification: Connection closed by remote host<br>Connection closed by 198.18.1.13 port 22<br>fatal: Could not <span class="hljs-built_in">read</span> from remote repository.<br><br>Please make sure you have the correct access rights<br>and the repository exists.<br></code></pre></td></tr></table></figure>
<p>这是我以为就是git在链接上的故障，于是重新生成了SSH密钥上传到GitHub上，但是故障依旧</p></li>
<li><p><strong>排查SSH问题</strong>，搜索到使用的代理可能会出现不允许22端口的情况</p>
<p>于是在<code>~/.ssh/config</code>中添加了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs config">Host github.com<br>  HostName ssh.github.com<br>  Port 443<br></code></pre></td></tr></table></figure>
<p>表示强制使用443端口连接GitHub的SSH</p>
<p>使用<code>ssh -vT git@github.com</code>测试GitHub：</p>
<p>一串跑码之后收到回复：<code>Hi Ash-one! You've successfully authenticated, but GitHub does not provide shell access.</code>
看来SSH的问题解决了</p>
<p>继续测试deploy，发现Hexo正常构建合并了分支到仓库中。</p>
<p>但是，故障依旧还在。</p></li>
<li><p>到这里，我选择<strong>检查了commit记录</strong>，因为在印象中有看到仓库根目录下有<code>CNAME</code>文件标记是哪个域名，结果在所有commit记录中都没有见到这一条，commit的文本也都是Hexo自动生成的update文本。</p>
<p>终于意识到了是<strong>Hexo在deploy的时候肯定是将CNAME文件覆盖掉</strong>了，重新进入仓库的设置，果然发现曾经配置过的域名消失了</p>
<figure>
<img src="/2023/04/16/github-pages-yu-hexo-deploy-de-yi-dian-xiao-wen-ti/custom-domain.png" alt="对这里熟悉完全是因为配置HTTPS证书时的痛苦">
<figcaption aria-hidden="true">对这里熟悉完全是因为配置HTTPS证书时的痛苦</figcaption>
</figure></li>
</ol>
<p>重新在图中3的位置上填上了域名后，成功解决了这次的404问题。</p>
<p>但是很简单的状况是：下次deploy还会覆盖掉CNAME</p>
<p>实际上Hexo有针对配置GitHub Pages的方法，在这个<a href="https://github.com/hexojs/hexo/issues/4121">issue</a>中提到：在Hexo目录下的<code>source</code>目录中创建<code>CNAME</code>文件，并将域名写入，就完成了，之后的每次构建和部署都会带有域名信息。</p>
<h1 id="小结">小结</h1>
<p>整体而言只是因为工具不熟悉出现的一次小问题，花了半小时的排查来回，还出现SSH上的奇怪问题，确实是很奇妙了。。。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>git</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客在matery主题下插入mermaid流程图</title>
    <url>/2022/07/12/hexo-bo-ke-zai-matery-zhu-ti-xia-cha-ru-mermaid-liu-cheng-tu/</url>
    <content><![CDATA[<h1 id="hexo博客在matery主题下插入mermaid流程图">Hexo博客在matery主题下插入mermaid流程图</h1>
<blockquote>
<p>本文解决hexo本身无法渲染mermaid流程图的问题,本质是加载对应的js文件</p>
<p>其他主题可以直接参考https://github.com/webappdevelp/hexo-filter-mermaid-diagrams</p>
</blockquote>
<p>官方指定在<code>after-footer.ejs</code>文件中插入以下代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs ejs">&lt;% if (theme.mermaid.enable) &#123; %&gt;<br>  &lt;script src=&#x27;https://unpkg.com/mermaid@&lt;%= theme.mermaid.version %&gt;/dist/mermaid.min.js&#x27;&gt;&lt;/script&gt;<br>  &lt;script&gt;<br>    if (window.mermaid) &#123;<br>      mermaid.initialize(&#123;theme: &#x27;forest&#x27;&#125;);<br>    &#125;<br>  &lt;/script&gt;<br>&lt;% &#125; %&gt;<br></code></pre></td></tr></table></figure>
<p>而实际上在matery主题中没有该文件</p>
<h2 id="解决方法">解决方法</h2>
<h3 id="第一步-增加js代码">第一步 增加js代码</h3>
<p>在matery主题路径<code>themes/hexo-theme-matery/layout/_partial</code>下找到<code>footer.ejs</code></p>
<p>直接在该文件的最后添加如下代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs ejs">&lt;% if (theme.mermaid.enable) &#123; %&gt;<br>  &lt;script src=&#x27;https://unpkg.com/mermaid/dist/mermaid.min.js&#x27;&gt;&lt;/script&gt;<br>  &lt;script&gt;<br>    if (window.mermaid) &#123;<br>      mermaid.initialize(&#123;theme: &#x27;forest&#x27;&#125;);<br>    &#125;<br>  &lt;/script&gt;<br>&lt;% &#125; %&gt;<br></code></pre></td></tr></table></figure>
<p><strong>注意到去掉了原本中间的版本控制,
因为版本选择可能会导致加载的js不能正常显示typora中的mermaid图</strong></p>
<ul>
<li>如果想要修改主题则直接在这里修改theme后的内容为如下: <em>default |
dark | forest | neutral</em></li>
</ul>
<h3 id="第二步-增加yml文本">第二步 增加yml文本</h3>
<p>在<em>主题的配置文件</em>下<code>themes/hexo-theme-matery/_config.yml</code>增加文本</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">mermaid:</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure>
<h2 id="结语">结语</h2>
<p>不出意外到这里进行测试就可以见到hexo能够加载出来mermaid图了(撒花)</p>
<p>如果没能成功加载, 可以查看源代码查找mermaid,
看看增加的ejs代码是否成功渲染</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>blog</tag>
        <tag>typora</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo安装和配置插件</title>
    <url>/2022/08/01/hexo-an-zhuang-he-pei-zhi-cha-jian/</url>
    <content><![CDATA[<h1 id="hexo安装和配置插件">Hexo安装和配置插件</h1>
<aside>
💡 本文安装配置了hexo博客的常用插件，包括pandoc、mermaid、本地图片等插件
</aside>
<h1 id="准备工作">准备工作</h1>
<h2 id="安装node环境">安装node环境</h2>
<p>可以直接在nodejs官网下载安装包</p>
<h2 id="准备路径后安装hexo">准备路径后安装hexo</h2>
<p>在想要安装node的路径下建立一个新的文件夹，避免装在根目录下</p>
<p>在新的文件夹下执行命令安装hexo</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><code class="hljs cmake">npm <span class="hljs-keyword">install</span> hexo<br></code></pre></td></tr></table></figure>
<p>测试hexo命令</p>
<h1 id="安装各种插件">安装各种插件</h1>
<h2 id="pandoc渲染latex公式">pandoc渲染latex公式</h2>
<p>先在官网安装pandoc的包</p>
<p><a href="https://pandoc.org/installing.html">Installing
pandoc</a></p>
<p>再执行命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">npm install hexo-renderer-pandoc --save<br></code></pre></td></tr></table></figure>
<h2 id="安装mermaid流程图插件">安装mermaid流程图插件</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">npm install --save hexo-filter-mermaid-diagrams<br></code></pre></td></tr></table></figure>
<p>安装后不能直接使用，需要修改部分文件，修改内容如下</p>
<p>参考文章：</p>
<p><a href="https://ash-one.github.io/2022/07/12/hexo-bo-ke-zai-matery-zhu-ti-xia-cha-ru-mermaid-liu-cheng-tu/">Hexo博客在matery主题下插入mermaid流程图</a></p>
<h2 id="安装支持本地图片的插件">安装支持本地图片的插件</h2>
<ol type="1">
<li><p>插件安装</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">npm install hexo-asset-image --save<br></code></pre></td></tr></table></figure></p></li>
<li><p>由于插件内容老旧失效，找到文件进行修改</p>
<p>位置在/node_modules/hexo-asset-image/index.js</p>
<p><figure class="highlight jsx"><table><tr><td class="code"><pre><code class="hljs jsx"><span class="hljs-meta">&#x27;use strict&#x27;</span>;<br><span class="hljs-keyword">var</span> cheerio = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;cheerio&#x27;</span>);<br><br><span class="hljs-comment">// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string</span><br><span class="hljs-keyword">function</span> <span class="hljs-title function_">getPosition</span>(<span class="hljs-params">str, m, i</span>) &#123;<br>  <span class="hljs-keyword">return</span> str.<span class="hljs-title function_">split</span>(m, i).<span class="hljs-title function_">join</span>(m).<span class="hljs-property">length</span>;<br>&#125;<br><br><span class="hljs-keyword">var</span> version = <span class="hljs-title class_">String</span>(hexo.<span class="hljs-property">version</span>).<span class="hljs-title function_">split</span>(<span class="hljs-string">&#x27;.&#x27;</span>);<br>hexo.<span class="hljs-property">extend</span>.<span class="hljs-property">filter</span>.<span class="hljs-title function_">register</span>(<span class="hljs-string">&#x27;after_post_render&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">data</span>)&#123;<br>  <span class="hljs-keyword">var</span> config = hexo.<span class="hljs-property">config</span>;<br>  <span class="hljs-keyword">if</span>(config.<span class="hljs-property">post_asset_folder</span>)&#123;<br>    	<span class="hljs-keyword">var</span> link = data.<span class="hljs-property">permalink</span>;<br>	<span class="hljs-keyword">if</span>(version.<span class="hljs-property">length</span> &gt; <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-title class_">Number</span>(version[<span class="hljs-number">0</span>]) == <span class="hljs-number">3</span>)<br>	   <span class="hljs-keyword">var</span> beginPos = <span class="hljs-title function_">getPosition</span>(link, <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>;<br>	<span class="hljs-keyword">else</span><br>	   <span class="hljs-keyword">var</span> beginPos = <span class="hljs-title function_">getPosition</span>(link, <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-number">3</span>) + <span class="hljs-number">1</span>;<br>	<span class="hljs-comment">// In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.</span><br>	<span class="hljs-keyword">var</span> endPos = link.<span class="hljs-title function_">lastIndexOf</span>(<span class="hljs-string">&#x27;/&#x27;</span>) + <span class="hljs-number">1</span>;<br>    link = link.<span class="hljs-title function_">substring</span>(beginPos, endPos);<br><br>    <span class="hljs-keyword">var</span> toprocess = [<span class="hljs-string">&#x27;excerpt&#x27;</span>, <span class="hljs-string">&#x27;more&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>];<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; toprocess.<span class="hljs-property">length</span>; i++)&#123;<br>      <span class="hljs-keyword">var</span> key = toprocess[i];<br> <br>      <span class="hljs-keyword">var</span> $ = cheerio.<span class="hljs-title function_">load</span>(data[key], &#123;<br>        <span class="hljs-attr">ignoreWhitespace</span>: <span class="hljs-literal">false</span>,<br>        <span class="hljs-attr">xmlMode</span>: <span class="hljs-literal">false</span>,<br>        <span class="hljs-attr">lowerCaseTags</span>: <span class="hljs-literal">false</span>,<br>        <span class="hljs-attr">decodeEntities</span>: <span class="hljs-literal">false</span><br>      &#125;);<br><br>      $(<span class="hljs-string">&#x27;img&#x27;</span>).<span class="hljs-title function_">each</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)&#123;<br>		<span class="hljs-keyword">if</span> ($(<span class="hljs-variable language_">this</span>).<span class="hljs-title function_">attr</span>(<span class="hljs-string">&#x27;src&#x27;</span>))&#123;<br>			<span class="hljs-comment">// For windows style path, we replace &#x27;\&#x27; to &#x27;/&#x27;.</span><br>			<span class="hljs-keyword">var</span> src = $(<span class="hljs-variable language_">this</span>).<span class="hljs-title function_">attr</span>(<span class="hljs-string">&#x27;src&#x27;</span>).<span class="hljs-title function_">replace</span>(<span class="hljs-string">&#x27;\\&#x27;</span>, <span class="hljs-string">&#x27;/&#x27;</span>);<br>			<span class="hljs-keyword">if</span>(!<span class="hljs-regexp">/http[s]*.*|\/\/.*/</span>.<span class="hljs-title function_">test</span>(src) &amp;&amp;<br>			   !<span class="hljs-regexp">/^\s*\//</span>.<span class="hljs-title function_">test</span>(src)) &#123;<br>			  <span class="hljs-comment">// For &quot;about&quot; page, the first part of &quot;src&quot; can&#x27;t be removed.</span><br>			  <span class="hljs-comment">// In addition, to support multi-level local directory.</span><br>			  <span class="hljs-keyword">var</span> linkArray = link.<span class="hljs-title function_">split</span>(<span class="hljs-string">&#x27;/&#x27;</span>).<span class="hljs-title function_">filter</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params">elem</span>)&#123;<br>				<span class="hljs-keyword">return</span> elem != <span class="hljs-string">&#x27;&#x27;</span>;<br>			  &#125;);<br>			  <span class="hljs-keyword">var</span> srcArray = src.<span class="hljs-title function_">split</span>(<span class="hljs-string">&#x27;/&#x27;</span>).<span class="hljs-title function_">filter</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params">elem</span>)&#123;<br>				<span class="hljs-keyword">return</span> elem != <span class="hljs-string">&#x27;&#x27;</span> &amp;&amp; elem != <span class="hljs-string">&#x27;.&#x27;</span>;<br>			  &#125;);<br>			  <span class="hljs-keyword">if</span>(srcArray.<span class="hljs-property">length</span> &gt; <span class="hljs-number">1</span>)<br>				srcArray.<span class="hljs-title function_">shift</span>();<br>			  src = srcArray.<span class="hljs-title function_">join</span>(<span class="hljs-string">&#x27;/&#x27;</span>);<br>			  $(<span class="hljs-variable language_">this</span>).<span class="hljs-title function_">attr</span>(<span class="hljs-string">&#x27;src&#x27;</span>, config.<span class="hljs-property">root</span> + link + src);<br>			  <span class="hljs-variable language_">console</span>.<span class="hljs-property">info</span>&amp;&amp;<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">info</span>(<span class="hljs-string">&quot;update link as:--&gt;&quot;</span>+config.<span class="hljs-property">root</span> + link + src);<br>			&#125;<br>		&#125;<span class="hljs-keyword">else</span>&#123;<br>			<span class="hljs-variable language_">console</span>.<span class="hljs-property">info</span>&amp;&amp;<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">info</span>(<span class="hljs-string">&quot;no src attr, skipped...&quot;</span>);<br>			<span class="hljs-variable language_">console</span>.<span class="hljs-property">info</span>&amp;&amp;<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">info</span>($(<span class="hljs-variable language_">this</span>));<br>		&#125;<br>      &#125;);<br>      data[key] = $.<span class="hljs-title function_">html</span>();<br>    &#125;<br>  &#125;<br>&#125;);<br></code></pre></td></tr></table></figure></p></li>
<li><p>打开hexo配置文件_config.yml，找到这个配置项开启功能，目的是在每次使用hexo
new生成新博客时，自动生成一个同名的目录存放静态文件</p>
<p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">post_asset_folder:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure></p></li>
</ol>
<p>可以生成测试是否能正常加载blog中的本地图片</p>
<p>如果没能正确生成可以使用命令清理文件重新编译</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">hexo clean<br></code></pre></td></tr></table></figure>
<h1 id="参考链接">参考链接</h1>
<p><a href="https://juejin.cn/post/7006594302604214280">解决hexo引用本地图片无法显示的问题
- 掘金</a></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>配置</tag>
        <tag>blog</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Gitlab本地部署（2）Git LFS从外网访问的问题和解决</title>
    <url>/2023/10/08/gitlab-ben-di-bu-shu-2-git-lfs-cong-wai-wang-fang-wen-de-wen-ti-he-jie-jue/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>上一篇自部署的Gitlab已经能够在内网环境内访问了，在校园环境内我们通常是在机房的服务器上运行程序，因此从机房服务器到实验室内的Gitlab宿主机这条路需要打通：</p>
<pre><code class=" mermaid">graph LR
  机房服务器 --&gt; 个人路由器 --&gt; Gitlab宿主机
</code></pre>
<p>如果你的个人路由器无法被机房服务器访问，那么这篇文章的完整过程可能无法复现，但是可以作为借鉴。</p>
<p>本篇主要解决的问题是git
lfs在通过路由器端口转发后无法正常被宿主机解析，导致lfs请求的地址是无法从外部访问的内网地址，最终卡在downloading界面没有反应。</p>
<p>省流版：<u>在clone命令中加入可访问内网地址的跳板机作为代理，通过内网地址进行lfs的仓库克隆。</u></p>
<h1 id="问题">问题</h1>
<p>上一篇提到我们在内网中留下了3个端口，分别是SSH端口、HTTP端口和HTTPS端口，</p>
<p>在内网中无论是通过ssh访问还是http访问都没有出现问题，特别是lfs追踪的大文件，都可以以理想速度进行下载。但是在大局域网（下称：外网）中，<code>git clone</code>或者<code>git lfs clone</code>都无法正常下载lfs追踪的大文件，表现为卡在下载环节，这时候仓库其他内容已经下载完成，只等lfs下载</p>
<figure>
<img src="/2023/10/08/gitlab-ben-di-bu-shu-2-git-lfs-cong-wai-wang-fang-wen-de-wen-ti-he-jie-jue/image-20231008200716761-6766838.png" alt="卡在LFS下载环节">
<figcaption aria-hidden="true">卡在LFS下载环节</figcaption>
</figure>
<blockquote>
<p>通过SSH clone也没有办法下载lfs文件</p>
</blockquote>
<p>类似的问题在lfs官方的issue中有人曾经提到过，在Gitea中也遇到了：<a href="https://github.com/git-lfs/git-lfs/issues/3457">issue</a></p>
<p>在回复中作者表示不会解决这个问题，应该由Gitea来解决，Gitlab也一样。</p>
<p>问题如上面描述的一样，在LFS中处理大文件链接所解析得到的ip地址是Gitlab部署时配置的内网地址，即使在外网访问，LFS也不会修改这个地址，那解决方案很清晰明了。</p>
<h1 id="解决方案">解决方案</h1>
<p>需要一台在Gitlab宿主机相同内网的<strong>跳板机</strong>或者能访问Gitlab宿主机的跳板机</p>
<p>我这里选择了一台跟Gitlab在同一内网环境的clash，将clash的http代理端口通过路由器端口转发到校园网范围内，这个代理端口能够被机房服务器访问，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git lfs <span class="hljs-built_in">clone</span> -c http.proxy=<span class="hljs-string">&quot;http://路由器ip:代理端口&quot;</span> http://内网ip:端口/repo.git<br></code></pre></td></tr></table></figure>
<h1 id="对于git-clone-设置代理">对于Git clone 设置代理</h1>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 一次性代理</span><br>git <span class="hljs-built_in">clone</span> -c http.proxy=<span class="hljs-string">&quot;http://127.0.0.1:1087&quot;</span> https://github.com/xxx.git<br><span class="hljs-comment"># 全局设置代理</span><br>git config --global http.https://github.com.proxy socks5://127.0.0.1:1086<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Git</tag>
        <tag>LFS</tag>
        <tag>端口转发</tag>
      </tags>
  </entry>
  <entry>
    <title>Python中GB2312转UTF-8的问题（2023.07.31）</title>
    <url>/2023/07/31/python-zhong-wen-jian-bian-ma-du-qu-he-bao-cun-cun-zai-de-wen-ti-2023-07-31/</url>
    <content><![CDATA[<h1 id="问题描述">问题描述</h1>
<p><img src="/2023/07/31/python-zhong-wen-jian-bian-ma-du-qu-he-bao-cun-cun-zai-de-wen-ti-2023-07-31/GB2312编码.png" alt="GB2312和UTF8对应表" style="zoom: 67%;"></p>
<p>中文的单个破折号<code>—</code>字符在GB2312编码中使用两个字节，十六进制表示为<code>A1AA</code>。</p>
<p>根据这幅图中的对应关系在UTF-8编码中应该使用三个字节<code>E28094</code>（VSCode内置的<code>通过编码保存</code>功能得到的也是这个结果）</p>
<p><img src="/2023/07/31/python-zhong-wen-jian-bian-ma-du-qu-he-bao-cun-cun-zai-de-wen-ti-2023-07-31/Python保存前后.png" alt="Python保存前后" style="zoom:67%;"></p>
<p>是在通过Python的<code>open</code>函数读取GB2312文件并重新保存为UTF-8编码时，结果变成了<code>E28095</code>，成为了另一个长相相同但是编码不同的字符。</p>
<p>接下来我们查询一下UTF-8中这些字符真正对应的内容，<a href="https://www.utf8-chartable.de/unicode-utf8-table.pl">UTF-8编码查询参考网站</a></p>
<p><img src="/2023/07/31/python-zhong-wen-jian-bian-ma-du-qu-he-bao-cun-cun-zai-de-wen-ti-2023-07-31/Unicode和UTF-8.png" alt="Unicode和UTF-8" style="zoom:67%;"></p>
<p>可以看到这里<code>E28090-E28096</code>都是不同长短的折线。</p>
<p>我在Edge浏览器中使用搜索工具搜索中文破折号（Shift-），这时候打出了两个相同字符，删除其中的一个，高亮显示都是<code>E28094</code>字符的破折号，看起来是微软统一使用该转换方式，而Python选择了另外的转换方式，本身不是大问题，但是可能会导致意料之外的结果。</p>
<h1 id="结论">结论</h1>
<p>在涉及到中文字符的编码和处理时最好统一先全部处理为相同的固定格式，并且做好清洗和预处理工作，防止意料外结果出现。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>utf8</tag>
        <tag>gb2312</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu上基于docker搭建Hadoop集群</title>
    <url>/2022/10/07/ubuntu-shang-de-ji-yu-docker-da-jian-hadoop-ji-qun/</url>
    <content><![CDATA[<h1 id="docker操作">Docker操作</h1>
<p>先学习一下基础的docker命令，后面常用，这里放出来备查</p>
<h2 id="查看容器container">查看容器container</h2>
<p>docker ps 的命令包括： 1）-a 列出所有容器 2）-l 列出最新创建容器
3）-n=2 列出最近创建的2个容器 4）-q 仅列出容器ID 5）-s 显示容器大小</p>
<figure class="highlight css"><table><tr><td class="code"><pre><code class="hljs css">sudo docker ps -<span class="hljs-selector-tag">a</span><br></code></pre></td></tr></table></figure>
<h2 id="删除容器">删除容器</h2>
<figure class="highlight apache"><table><tr><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> docker rm <span class="hljs-number">1051267</span>f9afb<br></code></pre></td></tr></table></figure>
<h2 id="查看镜像image">查看镜像image</h2>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">sudo docker images</span><br></code></pre></td></tr></table></figure>
<h2 id="删除镜像">删除镜像</h2>
<figure class="highlight apache"><table><tr><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> docker rmi <span class="hljs-number">5</span>d0da3dc9764<br></code></pre></td></tr></table></figure>
<h2 id="启动容器">启动容器</h2>
<figure class="highlight apache"><table><tr><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> docker run -itd weicg/hadoop:<span class="hljs-number">1</span>.<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure>
<ul>
<li>-d表示在后台运行，需要进入容器</li>
</ul>
<figure class="highlight applescript"><table><tr><td class="code"><pre><code class="hljs applescript">sudo docker exec -<span class="hljs-keyword">it</span> be349f8dd945 bash<br></code></pre></td></tr></table></figure>
<ul>
<li>使用exec 进入容器时exit命令不会结束容器</li>
</ul>
<h1 id="hadoop集群搭建">Hadoop集群搭建</h1>
<h2 id="准备镜像">准备镜像</h2>
<p>我选择的是dockerhub上的<code>weicg/hadoop:1.2</code>,同样是一位初学者制作的，试用还算可以（单机可以开箱即用）不过这里搭建集群还需要修改一些内容。来源：https://hub.docker.com/r/weicg/hadoop</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo docker pull weicg/hadoop:1.2<br></code></pre></td></tr></table></figure>
<p>我们打算建立一个<strong>一主两从</strong>的集群，需要开三个容器</p>
<h2 id="建立网桥">建立网桥</h2>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><code class="hljs livecodeserver">sudo docker network <span class="hljs-built_in">create</span> <span class="hljs-comment">--driver bridge hadoop-br</span><br></code></pre></td></tr></table></figure>
<h2 id="开启多个容器">开启多个容器</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo docker run -itd --network hadoop-br --name hadoop1 -p 50070:50070 -p 8088:8088 weicg/hadoop:1.2<br>sudo docker run -itd --network hadoop-br --name hadoop2 weicg/hadoop:1.2<br>sudo docker run -itd --network hadoop-br --name hadoop3 weicg/hadoop:1.2<br></code></pre></td></tr></table></figure>
<p>得到三个容器</p>
<ul>
<li>23c1187f8492</li>
<li>676e08f5ecc5</li>
<li>d2ec810e1e89</li>
</ul>
<p>进入这些容器只需要</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><code class="hljs applescript">sudo docker exec -<span class="hljs-keyword">it</span> hadoop1 bash<br>sudo docker exec -<span class="hljs-keyword">it</span> hadoop2 bash<br>sudo docker exec -<span class="hljs-keyword">it</span> hadoop3 bash<br></code></pre></td></tr></table></figure>
<h2 id="查看网桥配置">查看网桥配置</h2>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><code class="hljs mipsasm">sudo docker network <span class="hljs-keyword">inspect </span>hadoop-<span class="hljs-keyword">br </span><br></code></pre></td></tr></table></figure>
<figure class="highlight json"><table><tr><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;Containers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;23c1187f84929b19883f3ff3452688fca46c101e43bdfcc2a0cabaa4cd4fc593&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;hadoop1&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;EndpointID&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;27504f3d67c0a1e884ab8420c717b7bf5f3aa7db211360fa19a0d501fa6f9ed7&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;MacAddress&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;02:42:ac:12:00:02&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;IPv4Address&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;172.18.0.2/16&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;IPv6Address&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;676e08f5ecc5273542efd51e554ef1fa8790b2aa4a57fa3516cb39d6b09cfb7f&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;hadoop2&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;EndpointID&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;b766f1d85e339558f0bbf89e52e8e9a103c8d8e5b593dbcb6832367a925dcb4f&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;MacAddress&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;02:42:ac:12:00:03&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;IPv4Address&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;172.18.0.3/16&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;IPv6Address&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;d2ec810e1e897f47add8b09f8a813b6c23ab892fddd0706b88373d7f67f76b2f&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;hadoop3&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;EndpointID&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;552975d97feddc22fcf5d4ac1afa61be698846f08727e249d7581aaa33e220c2&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;MacAddress&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;02:42:ac:12:00:04&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;IPv4Address&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;172.18.0.4/16&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;IPv6Address&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>
<p>可以看到三个docker的ip地址</p>
<p>172.18.0.2 hadoop1</p>
<p>172.18.0.3 hadoop2</p>
<p>172.18.0.4 hadoop3</p>
<p>使用<code>ping</code>命令分别检查是否网络通畅</p>
<p>以下命令需要分别进入三个容器内执行</p>
<p>1.更改hosts文件<code>vim /etc/hosts</code>,加入如下配置</p>
<figure class="highlight accesslog"><table><tr><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">172.18.0.2</span> hadoop1 <br><span class="hljs-number">172.18.0.3</span> hadoop2 <br><span class="hljs-number">172.18.0.4</span> hadoop3 <br></code></pre></td></tr></table></figure>
<p>2.分别在三个容器内配置ssh,因为镜像已经生成了密钥，此处将本机密钥加入本机的访问列表中。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/.ssh<br><span class="hljs-built_in">cat</span> id_rsa.pub &gt;&gt; authorized_keys<br></code></pre></td></tr></table></figure>
<p>完成后可以<code>ssh root@hadoop2</code>查看是否成功配置ssh和网络。</p>
<h2 id="配置hadoop文件">配置hadoop文件</h2>
<p>进入hadoop1,创建一些配置用到的文件夹</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk">mkdir <span class="hljs-regexp">/home/</span>hadoop<br>mkdir <span class="hljs-regexp">/home/</span>hadoop<span class="hljs-regexp">/tmp /</span>home<span class="hljs-regexp">/hadoop/</span>hdfs_name <span class="hljs-regexp">/home/</span>hadoop/hdfs_data<br></code></pre></td></tr></table></figure>
<p>切到hadoop配置目录</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk">cd <span class="hljs-variable">$HADOOP_HOME</span><span class="hljs-regexp">/etc/</span>hadoop/<br></code></pre></td></tr></table></figure>
<p>下面的编辑部分可以直接拷贝覆盖粘贴</p>
<h3 id="编辑workers文件">编辑workers文件</h3>
<p><code>vim workers</code></p>
<figure class="highlight smali"><table><tr><td class="code"><pre><code class="hljs smali">hadoop2<br>hadoop3<br></code></pre></td></tr></table></figure>
<h3 id="编辑core-site.xml">编辑core-site.xml</h3>
<figure class="highlight xml"><table><tr><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://hadoop1:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/home/hadoop/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>io.file.buffer.size<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>131702<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>
<h3 id="编辑hdfs-site.xml">编辑hdfs-site.xml</h3>
<figure class="highlight xml"><table><tr><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br> <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/home/hadoop/hdfs_name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/home/hadoop/hdfs_data<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>2<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop1:9001<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>
<h3 id="编辑mapred-site.xml">编辑mapred-site.xml</h3>
<figure class="highlight xml"><table><tr><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>   <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop1:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop1:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>
<h3 id="编辑yarn-site.xml">编辑yarn-site.xml</h3>
<figure class="highlight xml"><table><tr><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>   <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.auxservices.mapreduce.shuffle.class<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop1:8032<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop1:8030<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop1:8031<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop1:8033<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop1:8088<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>
<p>把上面配置好的文件拷贝到2、3号机</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk">scp -r <span class="hljs-regexp">/home/</span>hadoop hadoop2:<span class="hljs-regexp">/home/</span><br>scp -r <span class="hljs-regexp">/home/</span>hadoop hadoop3:<span class="hljs-regexp">/home/</span><br>scp -r <span class="hljs-variable">$HADOOP_HOME</span><span class="hljs-regexp">/etc/</span>hadoop<span class="hljs-regexp">/ hadoop2:$HADOOP_HOME/</span>etc<span class="hljs-regexp">/hadoop/</span><br>scp -r <span class="hljs-variable">$HADOOP_HOME</span><span class="hljs-regexp">/etc/</span>hadoop<span class="hljs-regexp">/ hadoop3:$HADOOP_HOME/</span>etc<span class="hljs-regexp">/hadoop/</span><br></code></pre></td></tr></table></figure>
<h2 id="可选增加sbin目录的环境变量方便随意启动">（可选）增加sbin目录的环境变量，方便随意启动</h2>
<ol type="1">
<li><p>分别连接三台机器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -it hadoop1 bash<br>docker <span class="hljs-built_in">exec</span> -it hadoop2 bash<br>docker <span class="hljs-built_in">exec</span> -it hadoop3 bash<br></code></pre></td></tr></table></figure></li>
<li><p>将hadoop/sbin目录加入PATH环境变量中<code>vim ～/.bashrc</code></p>
<p>追加内容<code>export PATH=$PATH:$HADOOP_HOME/sbin</code></p>
<p>然后执行<code>source ~/.bashrc</code></p></li>
</ol>
<p><strong>这一步略过的话，启动hadoop的相关命令需要先<code>cd $HADOOP_HOME/sbin</code></strong></p>
<h2 id="启动hadoop">启动HADOOP</h2>
<p>进入hadoop1号主节点</p>
<p>第一次启动需要格式化hdfs，后续<strong><u>绝对不要再</u></strong>执行这一条<code>hdfs namenode -format</code></p>
<p>先在主节点上启动文件系统：<code>start-dfs.sh</code></p>
<p>使用<code>jps</code>命令此时可以观察到：</p>
<p>hadoop1上启动了<u>名称节点</u>和<u>第二名称节点</u>（第二名称节点可以配置在其他节点上）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">root@5d574541fd94:/opt/hadoop-3.1.3/etc/hadoop<span class="hljs-comment"># jps</span><br>1649 NameNode<br>1854 SecondaryNameNode<br>1967 Jps<br></code></pre></td></tr></table></figure>
<p>hadoop2和hadoop3上启动了<u>数据节点</u>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">root@004916b254fc:/opt/hadoop-3.1.3/etc/hadoop<span class="hljs-comment"># jps</span><br>294 DataNode<br>361 Jps<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">root@c5bea89663f9:/<span class="hljs-comment"># jps</span><br>279 Jps<br>188 DataNode<br></code></pre></td></tr></table></figure>
<p>第二步在主节点上启动yarn管理系统：<code>start-yarn.sh</code></p>
<p>Hadoop1:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">root@5d574541fd94:/opt/hadoop-3.1.3/etc/hadoop<span class="hljs-comment"># jps</span><br>3751 Jps<br>3255 SecondaryNameNode<br>3049 NameNode<br>3455 ResourceManager<br></code></pre></td></tr></table></figure>
<p>Hadoop2和hadoop3:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">root@004916b254fc:/opt/hadoop-3.1.3/etc/hadoop<span class="hljs-comment"># jps</span><br>851 NodeManager<br>731 DataNode<br>975 Jps<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">root@c5bea89663f9:/<span class="hljs-comment"># jps</span><br>644 DataNode<br>890 Jps<br>766 NodeManager<br></code></pre></td></tr></table></figure>
<p>可以看到两台从节点都多了一个NodeManager</p>
<p>此时hadoop应用已经成功运行。</p>
<p>启动应用<u>不推荐</u>使用start-all</p>
<p>停止应用：<code>stop-dfs.sh</code>和<code>stop-yarn.sh</code>或者<code>stop-all.sh</code></p>
<blockquote>
<p>在hadoop运行中有哪个datanode掉了很正常🤣🤣</p>
<p>使用下面命令在数据节点上重开⬇️</p>
<p><code>hdfs --daemon start datanode</code></p>
</blockquote>
<p>在宿主机上可以通过IP:8088查看Hadoop运行状态。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>ubuntu</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>VALL-E</title>
    <url>/2023/01/13/vall-e/</url>
    <content><![CDATA[<h1 id="vall-e">VALL-E</h1>
<h2 id="模型">模型</h2>
<p>使用60k小时英语语音训练，使得模型出现上下文学习能力。只需要3秒特定录音，就可以学习到说话人的说话方式，甚至是背景音。</p>
<p>demo演示：<a href="https://valle-demo.github.io/">https://valle-demo.github.io/</a></p>
<figure>
<img src="/2023/01/13/vall-e/model.png" alt="模型总览">
<figcaption aria-hidden="true">模型总览</figcaption>
</figure>
<h2 id="音频量化-speech-quantization">音频量化 Speech Quantization</h2>
<p>对于常见的一秒音频，16位，48kHz，意味着需要每个step有<span class="math inline">\(2^{16}=65536\)</span>个值，整个序列长度接近5万。语音量化的目的是压缩这两个数值。</p>
<p>Wavenet中曾使用<span class="math inline">\(\mu\)</span>-law变换可以使用256个值重建高质量音频，压缩一半，但没有减少序列长度。</p>
<p>后面出现了矢量量化（vector
quantization），应用在vq-wav2vec、HuBERT。</p>
<p>文章采用AudioLM的方法，神经编码解码器模型（neural codec
models），优点如下：</p>
<ul>
<li>在低比特率下表现比传统音频编解码器更好。</li>
<li>包含说话人信息和声学信息，HuBERT做不到保存说话人信息。</li>
<li>有学者提出的现有的解码器，用于将离散标记转换为波形，不用设计解码器。🤣</li>
<li>可以做到减少时间序列长度。</li>
</ul>
<p>文章采用预训练的神经音频编解码器模型EnCodec作为tokenizer，生成声学代码矩阵（acoustic
code
matrix）。EnCodec是一种卷积编码器-解码器模型，其输入和输出均为可变比特率的24kHz音频。其编码器将24kHz的输入波形生成75Hz的嵌入，采样率降低了320倍。每个嵌入都通过残差矢量量化(RVQ)建模，八个量化器每个有1024个条目。</p>
<figure>
<img src="/2023/01/13/vall-e/EnCodec.png" alt="RVQ">
<figcaption aria-hidden="true">RVQ</figcaption>
</figure>
<p>对于VQ1使用AR学习到重要的说话人特征，VQ2-8使用NAR学习其他特征。</p>
<h2 id="模型-1">模型</h2>
<p>优化目标：<span class="math inline">\(\max p(C|x,\tilde
C)\)</span></p>
<figure>
<img src="/2023/01/13/vall-e/LM.png" alt="LM">
<figcaption aria-hidden="true">LM</figcaption>
</figure>
<h2 id="推理">推理</h2>
<p>将文本转换为音素序列，并将登记的录音编码为声学矩阵，形成音素提示和声学提示。声学提示可能与要合成的语音在语义上相关，也可能不相关，导致两种情况：</p>
<ul>
<li>VALL-E：只学习prompt语音的声学条件，按照文本生成语音。</li>
<li>VALL-E-continual：按照完整prompt语音转录的文本作为音素提示，使用语音的前3秒作为声学提示，生成的语音语义上接着prompt语音。</li>
</ul>
<h2 id="数据">数据</h2>
<p>LibriLight包含英语有声读物60K小时无标记语音，说话人数量约7000</p>
<p>使用Kaldi的ASR模型，为无标记语音数据生成音素和对齐。</p>
<p>将平均长度为60秒的音频随机裁剪为10-20秒的随机长度，其对应的音素序列作为prompt。在NAR中的prompt会使用同一段话中的3秒随机音频。</p>
<p>16个 NVIDIA TESLA V100
32GB，每个GPU的批量大小为6k声学标记，800k步。使用AdamW优化器优化模型，前32k步更新的学习率预热到
5 × 10−4 的峰值，然后对其进行线性衰减。</p>
<h2 id="分析">分析</h2>
<ul>
<li>多样性丰富：原本的mel谱图生成基于每个步骤的重建，其随机性较差，由于VALL-E使用采样的方式生成离散标记，相同文本的输出不同，其多样性丰富。</li>
<li>能保持环境音：作者认为，VALL-E的数据集声学条件更多，当prompt带有混响，baseline得到的是干净的声音，VALL-E可以得到相同的混响效果。</li>
<li>能保持说话人的情绪：emotional。可以在0-shot条件下保留prompt中的情绪。</li>
<li>鲁棒性有待提升：由于VQ1是自回归模型，其中的transformer注意力无序，也没有增加约束，导致在合成结果中出现不清楚、遗漏和重复的问题。</li>
<li>数据覆盖有限：由于是有声读物，口音没有覆盖完全，并且只有阅读风格，需要扩大覆盖范围。</li>
<li>模型的滥用风险：伪造政客、电信诈骗等应用较为危险。类似于google的AudioLM可能需要同时推出一个分类器用于区分检测VALL-E的合成语音。</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>语音合成</tag>
      </tags>
  </entry>
  <entry>
    <title>esxi安装黑群晖记录</title>
    <url>/2022/10/02/esxi-an-zhuang-hei-qun-hui-ji-lu/</url>
    <content><![CDATA[<h1 id="esxi系统安装">esxi系统安装</h1>
<p>用U盘刷好系统，具体省略</p>
<h1 id="准备">准备</h1>
<h2 id="镜像">镜像</h2>
<p>黑群晖镜像链接:
https://pan.baidu.com/s/1ZOLCEvfAgF0tTZRkMt3MjA?pwd=ya4g</p>
<p>其中不同镜像对应的就是不同的群晖硬件，我一开始使用的ds918+一直卡在最后一步安装失败，所以后面选用的<strong>ds2617xs</strong></p>
<p>镜像分为引导文件(.img)和系统安装包(.pat)，要下载好对应的版本</p>
<h2 id="硬件准备">硬件准备</h2>
<p>最好准备一块以上未使用的硬盘，专门为黑群晖使用做数据盘，防止各种环节上出错</p>
<h2 id="img转vmdk">img转vmdk</h2>
<h3 id="本地qemu工具转换">本地qemu工具转换</h3>
<p>众所周知，esxi的系统需要单独制作vmdk文件</p>
<p>对于img文件，以Mac为例，使用常用的<code>qemu</code>工具转换</p>
<p>没安装qemu的先使用brew安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">brew install qemu<br></code></pre></td></tr></table></figure>
<p>qemu转换img为vmdk的命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">qemu-img convert -f raw name.img -O vmdk name.vmdk<br></code></pre></td></tr></table></figure>
<p>此时我们的vmdk<u>还不能在esxi上直接使用</u>，必须使用esxi的命令再转换一次</p>
<h3 id="上传到esxi系统转换">上传到esxi系统转换</h3>
<ol type="1">
<li><p><strong>右键主机-服务-启用安全Shell</strong>，打开esxi的ssh登陆，然后通过ssh登陆后台</p>
<figure>
<img src="https://s2.loli.net/2022/10/02/945pvVtThizKP2n.png" alt="启动SSH">
<figcaption aria-hidden="true">启动SSH</figcaption>
</figure></li>
<li><p><strong>右键存储-浏览数据存储</strong>
点击上载，将本地的vmdk上传到esxi上</p></li>
<li><p>在ssh会话中找到上传的文件，<code>/vmfs/volumes/</code>下是硬盘</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /vmfs/volumes/datastore1/<br></code></pre></td></tr></table></figure>
<figure>
<img src="https://s2.loli.net/2022/10/02/tHPp8UrCVEAXMfF.png" alt="查看路径">
<figcaption aria-hidden="true">查看路径</figcaption>
</figure></li>
<li><p>执行转换命令</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><code class="hljs stylus">vmkfstools -<span class="hljs-selector-tag">i</span> ds3617<span class="hljs-selector-class">.vmdk</span> ds3617_esxi.vmdk<br></code></pre></td></tr></table></figure></li>
<li><p>最好做下备份，因为esxi删除虚拟机时会删除掉vmdk文件</p></li>
</ol>
<h1 id="创建虚拟机">创建虚拟机</h1>
<ol type="1">
<li>创建类型：新虚拟机</li>
<li>名称、兼容性：随便选一个linux</li>
<li>选择存储：装在系统盘上</li>
<li><strong>自定义设置</strong></li>
</ol>
<h2 id="自定义设置">自定义设置</h2>
<p>CPU内存根据需要，我这里选择了2核4G，删除掉原本的硬盘1和SCSI控制器0、CD等选项</p>
<h3 id="添加sata控制器">添加SATA控制器</h3>
<p>添加其他设备- SATA控制器</p>
<h3 id="添加硬盘">添加硬盘</h3>
<p>我添加一块现有硬盘和一块新标准硬盘</p>
<ul>
<li>现有硬盘，<strong>选择vmdk作为黑群晖的系统盘</strong>，保证其控制器位置是SATA控制器0，（0:0）表示最先启动的硬盘</li>
<li>新标准硬盘，<strong>作为黑群晖的数据盘</strong>。选择空硬盘分配全部大小上限，选择SATA控制器1，跟系统盘区分开</li>
<li>如果你有更多的硬盘可以继续添加，可以选择非0号的其他SATA控制器即可</li>
</ul>
<p>其余均作默认设置即可，不出意外的话就可以启动虚拟机了</p>
<h1 id="启动黑群晖虚拟机">启动黑群晖虚拟机</h1>
<p>启动后在esxi中显示如图</p>
<blockquote>
<p>Loading Linux...</p>
<p>Starting kernel with SATA boot</p>
</blockquote>
<figure>
<img src="https://s2.loli.net/2022/10/02/qSiyMOHnG5uLfmg.png" alt="启动成功">
<figcaption aria-hidden="true">启动成功</figcaption>
</figure>
<p>此时需要通过路由器查看黑群晖获得的IP地址</p>
<p>或者使用群晖的SynologyAssistant软件搜索IP地址</p>
<blockquote>
<p>如果你的路由器没有开DHCP就必须使用软件搜索，找到之后设置静态路由地址，不过非常不推荐此处设置静态路由地址，因为后续黑群晖安装时会不断重启，丢失设置好的IP导致配置失败</p>
</blockquote>
<blockquote>
<p>如果在这一步搜索不到IP地址，可能是卡在内核启动了，原因可能很多，建议直接重装（</p>
</blockquote>
<p>访问IP地址的5005端口就可以开始配置黑群晖了！</p>
<p>PS：</p>
<p>如果等待10分钟倒计时后显示配置错误之类的，多次尝试无果的，多半是因为硬件和软件不匹配，建议更换镜像重新启动虚拟机。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>群晖</tag>
        <tag>虚拟机</tag>
        <tag>esxi</tag>
      </tags>
  </entry>
  <entry>
    <title>《声与情：播音用声的实证研究》笔记</title>
    <url>/2022/11/03/sheng-yu-qing-bo-yin-yong-sheng-de-shi-zheng-yan-jiu-bi-ji/</url>
    <content><![CDATA[<blockquote>
<p>链接：https://www.zhizhen.com/detail_38502727e7500f26ca5684ae8f3c3b6429bcb36a14c533e11921b0a3ea25510134114c969f2eae5c9837344477b6470412f90171de0b6360e6b1c5d917c82372d97823f6a9338067eed855d3fbe548a5?&amp;apistrclassfy=0_7_3</p>
</blockquote>
<h1 id="意义">意义</h1>
<p>播音学原则：<strong>以情带声</strong></p>
<p>探讨<u>播音语言的艺术用声</u>在韵律节奏上的</p>
<ul>
<li>规律、特点</li>
<li>声学表现特征</li>
<li>发音人的呼吸特点</li>
</ul>
<p>用于指导：</p>
<ul>
<li>具体实践，解决主持人和播音员的用声问题</li>
<li>播音教学</li>
</ul>
<h1 id="实验内容">实验内容</h1>
<h2 id="设备">设备</h2>
<ul>
<li><p>话筒和调音台：语音信号</p></li>
<li><p>电子声门仪：嗓音信号</p></li>
<li><p>呼吸带：胸呼吸信号、腹呼吸信号</p></li>
</ul>
<h3 id="实证研究一">实证研究一</h3>
<table>

<thead>
<tr class="header">
<th style="text-align: center;">语料分类</th>
<th style="text-align: center;">语料来源</th>
<th style="text-align: center;">字数</th>
<th style="text-align: center;">发言人</th>
<th style="text-align: center;">有效人数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">散文语句</td>
<td style="text-align: center;">《匆匆》《石缝间的生命》完整片段</td>
<td style="text-align: center;">200+</td>
<td style="text-align: center;">吉林大学播音专业大三学生</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;">新闻语句</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">200+</td>
<td style="text-align: center;">吉林大学播音专业大三学生</td>
<td style="text-align: center;">6</td>
</tr>
</tbody>
</table>
<table>

<thead>
<tr class="header">
<th style="text-align: center;">文本类型</th>
<th style="text-align: center;">物理特征</th>
<th style="text-align: left;">实验结果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">散文语句</td>
<td style="text-align: center;">停顿</td>
<td style="text-align: left;">不带情感的小停顿多于大停顿
带情感的大停顿多于不带情感的大停顿 带情感的小停顿多于等于大停顿数量</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">基频</td>
<td style="text-align: left;">变化不大。男80-250Hz，女150-330Hz</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">能量</td>
<td style="text-align: left;">变化不大。15-17dB</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">呼吸</td>
<td style="text-align: left;">有感情呼吸在次数、重置幅度都变多。其中腹呼吸抖动比胸呼吸多，说明有更多的偷气。胸腹呼吸起伏走向大体一致。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">新闻语句</td>
<td style="text-align: center;">停顿</td>
<td style="text-align: left;">不对比有无情感。</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">基频</td>
<td style="text-align: left;">男100-200Hz，女150-300Hz</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">能量</td>
<td style="text-align: left;">男22.82-89.51dB，女22.52-89.47dB</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">呼吸</td>
<td style="text-align: left;">胸腹呼吸起伏走向大体一致。</td>
</tr>
</tbody>
</table>
<h3 id="实证研究二">实证研究二</h3>
<table style="width:100%;">

<thead>
<tr class="header">
<th style="text-align: center;">语料分类</th>
<th style="text-align: center;">语料来源</th>
<th style="text-align: center;">字数</th>
<th style="text-align: center;">发言人</th>
<th style="text-align: center;">有效人数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">散文语句</td>
<td style="text-align: center;">《大海啊故乡》、《乡愁》、《夜过北海桥》</td>
<td style="text-align: center;">300-</td>
<td style="text-align: center;">吉林大学播音专业大一学生（第三周）</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">散文语句</td>
<td style="text-align: center;">《大海啊故乡》、《乡愁》、《夜过北海桥》</td>
<td style="text-align: center;">300-</td>
<td style="text-align: center;">吉林大学播音专业大一学生（第八周）</td>
<td style="text-align: center;">6</td>
</tr>
</tbody>
</table>
<p><u><strong>这里会要求学生的情感宁过勿欠</strong></u></p>
<table>

<thead>
<tr class="header">
<th style="text-align: center;">文本类型</th>
<th style="text-align: center;">物理特征</th>
<th style="text-align: left;">实验结果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">散文语句</td>
<td style="text-align: center;">停顿</td>
<td style="text-align: left;">总数多，带情感的大停顿显著多于小停顿，时长有所不同</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">基频</td>
<td style="text-align: left;">女150-290Hz变为150-320Hz，男100-260Hz变为120-230Hz</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">能量</td>
<td style="text-align: left;">有情的能量低</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">呼吸</td>
<td style="text-align: left;">有情的呼吸重置次数增多，幅度加大，无声段时长更长。胸腹呼吸基本保持一致。</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">时长</td>
<td style="text-align: left;">带情感的句子时长是不带情感的时长近乎2倍</td>
</tr>
</tbody>
</table>
<h1 id="播音学解释">播音学解释</h1>
<p>“声足情欠”“情足声欠”说明不和谐，“情欠”不好，“声欠”也不好，这都影响韵律。</p>
<p><strong>音步</strong>作为汉语的小节奏单元，本文把汉语中的音步概括为：</p>
<p>由若干个音节构成的语音片段，在音步内和音步间也存在长短、高低、强弱的对比，且<u><strong>音步间被停顿分开</strong></u>。本文对散文语句的韵律层级的划分也将从音步开始。</p>
<p><img src="/2022/11/03/sheng-yu-qing-bo-yin-yong-sheng-de-shi-zheng-yan-jiu-bi-ji/image-20221106140548462.png" alt="image-20221106140548462" style="zoom:50%;"></p>
<p>①叶军：《汉语语句韵律的功能研究》：http://www.docin.com/p-12614263.html.</p>
<p>在实际的言语中，韵律有着不同的层级，各层级之间的过渡和接口则承载着非常重要的言语节律特征。在声学上，它们主要表现为停延。<strong>停延是说话或朗读时语流中声音的中断和延连</strong>，它起到言语在语流中的分合作用。</p>
<p><img src="/2022/11/03/sheng-yu-qing-bo-yin-yong-sheng-de-shi-zheng-yan-jiu-bi-ji/image-20221103222828943.png" alt="image-20221103222828943" style="zoom:50%;"></p>
<p><img src="/2022/11/03/sheng-yu-qing-bo-yin-yong-sheng-de-shi-zheng-yan-jiu-bi-ji/image-20221103222922094.png" alt="image-20221103222922094" style="zoom:50%;"></p>
<p>节奏的技巧是欲高先低，欲低先高；欲轻先重，欲重先轻；逢慢必先快，逢快必先慢，即<strong>节奏是通过高低、快慢、轻重</strong>体现。</p>
<p>从上文论述中，我们得出理论上的假设是：情感的表现与音高变化、声音强度、快慢有关，而这些又都与呼吸停顿直接相关，恰恰<strong>停顿最能体现汉语言节奏的特点</strong>，因而本文就是通过实证性的研究证明播音艺术语言使用中，情感影响呼吸，呼吸影响停延，停延表现语言节奏，这些语音的实际表现形式又决定了播音语言语义信息及情感信息表达的信度和效度。</p>
]]></content>
  </entry>
  <entry>
    <title>Hexo快速使用指北</title>
    <url>/2020/10/12/hexo-kuai-su-shi-yong-zhi-bei/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<p>可以指定模板</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br>$ hexo new post <span class="hljs-string">&quot;这是一个新的笔记&quot;</span><br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br>$ hexo s<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br>$ hexo g<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br>$ hexo d<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
<h3 id="命令可以组合使用">命令可以组合使用</h3>
<blockquote>
<p>hexo g &amp;&amp; hexo d &amp;&amp; hexo s</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>Python基础知识点</title>
    <url>/2021/09/18/python-ji-chu-zhi-shi-dian/</url>
    <content><![CDATA[<h1 id="python基础知识点">Python基础知识点</h1>
<blockquote>
<p>本篇为给高二学生上课用的复习内容, 高二学生都能看懂!!!</p>
</blockquote>
<h2 id="数据类型6个">数据类型6个</h2>
<ol type="1">
<li><strong>整型 int</strong><br>
数学中的整数，如1，-8080，0<br>
</li>
<li><strong>实型（浮点数）float</strong><br>
数学中的实数，如3.14，9e-4<br>
</li>
<li><strong>字符串 string</strong><br>
以引号开始结束的一串字符，如<code>'this is a string'</code><br>
</li>
<li><strong>布尔型 bool</strong><br>
只有<code>True</code>和<code>False</code>两个值<br>
</li>
<li><strong>列表 list</strong><br>
以中括号开始结束的一种数据类型，如<code>[1,2,3,4,5]</code><br>
</li>
<li><strong>字典 dictionary</strong><br>
以大括号开始结束，存储内容为键值对，如<code>&#123;'name':'wow','age':17&#125;</code><br>
取出下列字典中的'name'键对应的值： <figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">d=&#123;<span class="hljs-string">&#x27;name&#x27;</span>:<span class="hljs-string">&#x27;wow&#x27;</span>,<span class="hljs-string">&#x27;age&#x27;</span>:<span class="hljs-number">17</span>&#125;  <br>d[<span class="hljs-string">&#x27;name&#x27;</span>]=<br></code></pre></td></tr></table></figure> #### 索引与切片
请写出下列索引与切片的结果 <figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">info=[<span class="hljs-string">&#x27;hello&#x27;</span>,<span class="hljs-string">&#x27;what&#x27;</span>,<span class="hljs-number">5432</span>]  <br>info2=[ [<span class="hljs-string">&#x27;world&#x27;</span>,<span class="hljs-string">&#x27;you&#x27;</span>],[<span class="hljs-number">231</span>,<span class="hljs-string">&#x27;how&#x27;</span>] ]   <br>info[<span class="hljs-number">1</span>]=  <br>info[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>]=  <br>info[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>:<span class="hljs-number">3</span>]=  <br>info2[<span class="hljs-number">0</span>]=  <br>info2[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>]=  <br>info2[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>][<span class="hljs-number">0</span>]=  <br>info2[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>][<span class="hljs-number">1</span>:<span class="hljs-number">3</span>]=  <br></code></pre></td></tr></table></figure> ***</li>
</ol>
<h2 id="运算符">运算符</h2>
<h3 id="算数运算符">算数运算符</h3>
<p><code>+-*/</code>加减乘除 <code>//</code>整除，结果取整数部分<br>
<code>%</code>取余数 <code>**</code>乘方</p>
<p><em>算数运算符得到的结果为数</em> ### 关系运算符
<code>&gt;&lt;</code>大于小于 <code>&gt;= &lt;=</code>大于等于
小于等于<br>
<code>==</code>等于<code>!=</code>不等于<br>
<code>in</code>包含于</p>
<p><em>关系运算得到的结果为布尔型，即<code>True</code>和<code>False</code></em></p>
<h3 id="逻辑运算符">逻辑运算符</h3>
<p><code>and</code>与运算，只有两个<code>True</code>结果才为<code>True</code><br>
<code>or</code>
或运算，只要有一个<code>True</code>结果就为<code>True</code><br>
<code>not</code>非运算，<code>not True</code>结果为<code>False</code></p>
<p><em>逻辑运算得到的结果为布尔型，即<code>True</code>和<code>False</code></em></p>
<hr>
<h2 id="变量和赋值">变量和赋值</h2>
<p><strong>常量</strong>：0，3.14，60000，pi，e等数学上的客观数字<br>
<strong>变量</strong>：在编程中声明/定义的一个代号，用于存储数据。变量名可以包括字母、数字、下划线，不可以用数字开头</p>
<p><strong>赋值语句</strong><br>
<code>=</code>用于赋值，将等号右侧的值赋给左侧的变量<br>
&gt;n=0 #将0赋值给变量n<br>
n=n+1 #将n+1的值赋给变量n<br>
n+=1 #将n+1的值赋给变量n，即n的值增加1</p>
<p><em>注意：<code>==</code>和<code>=</code>在用法上完全不同</em></p>
<h2 id="常用函数">常用函数</h2>
<p><code>print(x)</code>输出x的值<br>
<code>input(x)</code>将x的值输出在屏幕上，并读取用户的输入，以字符串存储<br>
<code>int(x)</code>将x转换为整型<br>
<code>float(x)</code>将x转换为浮点数</p>
<hr>
<h2 id="分支结构">分支结构</h2>
<blockquote>
<p>if 条件:<br>
  语句<br>
elif 条件:<br>
  语句<br>
else:<br>
  语句</p>
</blockquote>
<p>例：<br>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> x%<span class="hljs-number">2</span>==<span class="hljs-number">0</span>:  <br>		<span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;偶数&#x27;</span>)  <br>esle:  <br>		<span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;奇数&#x27;</span>)<br></code></pre></td></tr></table></figure></p>
<h2 id="循环结构">循环结构</h2>
<h4 id="for循环">for循环</h4>
<p>序列遍历完成后退出循环 &gt;for 变量 in 序列:<br>
  循环体</p>
<p>例：<br>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s=<span class="hljs-number">0</span>  <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">101</span>,<span class="hljs-number">1</span>):  <br>		s+=i  <br>		<span class="hljs-built_in">print</span>(i)  <br></code></pre></td></tr></table></figure> #### while循环
循环条件为<code>True</code>时进入循环，否则退出循环<br>
&gt;while 循环条件:<br>
  循环体</p>
<p>例：<br>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s=<span class="hljs-number">0</span>  <br>i=<span class="hljs-number">0</span>  <br><span class="hljs-keyword">while</span> i&lt;=<span class="hljs-number">100</span>:  <br>    s+=i<br>    i+=<span class="hljs-number">1</span><br>    <span class="hljs-built_in">print</span>(i)<br><span class="hljs-built_in">print</span>(s)<br></code></pre></td></tr></table></figure></p>
<p><strong><em>代码除了横向阅读，也要纵向阅读</em></strong><br>
<strong><em>横向阅读看<code>功能</code>，纵向阅读看<code>结构</code></em></strong><br>
<strong><em>注意循环体和分支结构语句块的缩进</em></strong></p>
<hr>
<h2 id="习题">习题</h2>
<p>使用for循环和while循环两种方式计算[100,1000]中所有奇数的和<br>
请在下方书写<br>
<em>提示：判断一个数是偶数还是奇数是用余数的方式</em></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>信息技术</tag>
        <tag>支教</tag>
      </tags>
  </entry>
  <entry>
    <title>使用BERTopic提取文本主题</title>
    <url>/2023/03/28/shi-yong-bertopic-ti-qu-wen-ben-zhu-ti/</url>
    <content><![CDATA[<h1 id="使用bertopic提取文本主题">使用BERTopic提取文本主题</h1>
<h2 id="加载数据集">加载数据集</h2>
<p>挂载Google
Drive用于读取数据集，这里会要求登陆Google账号授权，每次都需要重新授权，建议一开始在colab中选好gpu分配资源。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive<br>drive.mount(<span class="hljs-string">&#x27;/content/drive&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>数据集来自外卖平台中文评论，数据集地址：https://raw.githubusercontent.com/SophonPlus/ChineseNlpCorpus/master/datasets/waimai_10k/waimai_10k.csv，可以直接wget获取。该数据集本身用于情感二分类。
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>df = pd.read_csv(<span class="hljs-string">&#x27;/content/drive/MyDrive/colab/waimai_10k.csv&#x27;</span>)<br>df[<span class="hljs-string">&#x27;label&#x27;</span>].value_counts()<br></code></pre></td></tr></table></figure></p>
<p>结果为：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-number">0</span>    <span class="hljs-number">7987</span><br><span class="hljs-number">1</span>    <span class="hljs-number">4000</span><br><span class="hljs-attr">Name:</span> <span class="hljs-string">label,</span> <span class="hljs-attr">dtype:</span> <span class="hljs-string">int64</span><br></code></pre></td></tr></table></figure>
<p>0 表示负面评论<br>
1 表示正面评论<br>
不过这些label并不使用，只需要文本review</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.head(n=<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure>
<figure>
<img src="/2023/03/28/shi-yong-bertopic-ti-qu-wen-ben-zhu-ti/查看数据集dataframe.png" alt="数据集dataframe">
<figcaption aria-hidden="true">数据集dataframe</figcaption>
</figure>
<p>将数据集整理为列表方便输入</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">dataset = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> df[<span class="hljs-string">&#x27;review&#x27;</span>]]<br>dataset[:<span class="hljs-number">10</span>]<br></code></pre></td></tr></table></figure>
<p>输出：</p>
<p><code>['很快，好吃，味道足，量大', '没有送水没有送水没有送水', '非常快，态度好。', '方便，快捷，味道可口，快递给力', '菜味道很棒！送餐很及时！', '今天师傅是不是手抖了，微辣格外辣！', '送餐快,态度也特别好,辛苦啦谢谢', '超级快就送到了，这么冷的天气骑士们辛苦了。谢谢你们。麻辣香锅依然很好吃。', '经过上次晚了2小时，这次超级快，20分钟就送到了……', '最后五分钟订的，卖家特别好接单了，谢谢。']</code></p>
<p>去除停用词（没用到，数据集已经过清洗）</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><code class="hljs pgsql">stopwords = [<span class="hljs-string">&#x27; &#x27;</span>]+[<span class="hljs-type">line</span>.strip() <span class="hljs-keyword">for</span> <span class="hljs-type">line</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">open</span>(&quot;cn_stopwords.txt&quot;, &quot;rt&quot;, encoding=&quot;utf-8&quot;).readlines()]<br></code></pre></td></tr></table></figure>
<h2 id="bertopic建模">BERTopic建模</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">!pip install bertopic<br><br><span class="hljs-keyword">from</span> bertopic <span class="hljs-keyword">import</span> BERTopic<br><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer<br><span class="hljs-keyword">from</span> umap <span class="hljs-keyword">import</span> UMAP<br><span class="hljs-keyword">from</span> hdbscan <span class="hljs-keyword">import</span> HDBSCAN<br><span class="hljs-keyword">from</span> bertopic.vectorizers <span class="hljs-keyword">import</span> ClassTfidfTransformer<br></code></pre></td></tr></table></figure>
<p>使用<code>sentence-transformers</code>支持多语言的大模型进行embedding，在colab上下载速度很快，约400M瞬间完成。
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">embedding_model = SentenceTransformer(<span class="hljs-string">&#x27;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#x27;</span>)<br></code></pre></td></tr></table></figure> <strong>降维</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">umap_model = UMAP(n_neighbors=<span class="hljs-number">20</span>, n_components=<span class="hljs-number">5</span>, min_dist=<span class="hljs-number">0.0</span>, metric=<span class="hljs-string">&#x27;cosine&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p><strong>聚类</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">hdbscan_model = HDBSCAN(min_cluster_size=<span class="hljs-number">10</span>, metric=<span class="hljs-string">&#x27;euclidean&#x27;</span>, cluster_selection_method=<span class="hljs-string">&#x27;eom&#x27;</span>, prediction_data=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>tokenizer <figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br>vectorizer_model = CountVectorizer()<br></code></pre></td></tr></table></figure>
<strong>加权</strong>：使用改进tf-idf的c-tf-idf方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">ctfidf_model = ClassTfidfTransformer()<br></code></pre></td></tr></table></figure>
<p>输入BERTopic模型 <figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">topic_model = BERTopic(<br>​    embedding_model=embedding_model,<br>​    umap_model=umap_model,<br>​    hdbscan_model=hdbscan_model,<br>​    vectorizer_model=vectorizer_model,<br>​    ctfidf_model=ctfidf_model,<br>​    nr_topics=<span class="hljs-number">10</span>                        <br>)<br></code></pre></td></tr></table></figure> 训练 <figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">topics, probabilities = topic_model.fit_transform(dataset)<br></code></pre></td></tr></table></figure></p>
<h2 id="可视化呈现和结果分析">可视化呈现和结果分析</h2>
<p><strong>查看聚类结果</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">topic_model.get_document_info(dataset)<br></code></pre></td></tr></table></figure>
<figure>
<img src="/2023/03/28/shi-yong-bertopic-ti-qu-wen-ben-zhu-ti/聚类后结果.png" alt="结果">
<figcaption aria-hidden="true">结果</figcaption>
</figure>
<p>查看各话题文本数量。<br>
-1表示没有聚类</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">topic_model.get_topic_freq()<br></code></pre></td></tr></table></figure>
<p><img src="/2023/03/28/shi-yong-bertopic-ti-qu-wen-ben-zhu-ti/话题文本数量.png" alt="话题文本数量" style="zoom: 50%;"></p>
<p>查看话题7的文本并按照重要程度排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">topic_model.get_topic(<span class="hljs-number">7</span>)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">[(&#x27;就是有点油&#x27;, 0.12314684980074718),</span><br><span class="hljs-string"> (&#x27;就是油太大&#x27;, 0.12314684980074718),</span><br><span class="hljs-string"> (&#x27;全是油&#x27;, 0.10826034220928046),</span><br><span class="hljs-string"> (&#x27;味道不错&#x27;, 0.07580202124764789),</span><br><span class="hljs-string"> (&#x27;挺好的&#x27;, 0.07380868069892178),</span><br><span class="hljs-string"> (&#x27;灰常满意&#x27;, 0.06720667864215085),</span><br><span class="hljs-string"> (&#x27;一层厚厚的油&#x27;, 0.06720667864215085),</span><br><span class="hljs-string"> (&#x27;红油抄手贵&#x27;, 0.06720667864215085),</span><br><span class="hljs-string"> (&#x27;红油抄手好多油啊&#x27;, 0.06720667864215085),</span><br><span class="hljs-string"> (&#x27;红油抄手不错&#x27;, 0.06720667864215085)]</span><br><span class="hljs-string"> &#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure>
<p><strong>可视化查看各话题分数排序</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">topic_model.visualize_barchart()<br></code></pre></td></tr></table></figure>
<figure>
<img src="/2023/03/28/shi-yong-bertopic-ti-qu-wen-ben-zhu-ti/分数排序.png" alt="分数排序">
<figcaption aria-hidden="true">分数排序</figcaption>
</figure>
<p>能够看到一部分结果聚类效果很好，比如集中描述送餐慢、凉、咖啡奶茶、披萨、油等主题，而其他一部分看起来好坏参半，原因应该是该主题聚类可能将评价好坏都列为“评价主题”而分到一起。</p>
<p><strong>可视化呈现点云图</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">embeddings = embedding_model.encode(dataset, show_progress_bar=<span class="hljs-literal">False</span>)<br>topic_model.visualize_documents(dataset, embeddings=embeddings)<br></code></pre></td></tr></table></figure>
<figure>
<img src="/2023/03/28/shi-yong-bertopic-ti-qu-wen-ben-zhu-ti/点云图.png" alt="点云图">
<figcaption aria-hidden="true">点云图</figcaption>
</figure>
<p>点云图中颜色相同的属于同一主题，灰色属于无法聚类的文本。</p>
<p><strong>可视化呈现热度图</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">topic_model.visualize_heatmap()<br></code></pre></td></tr></table></figure>
<figure>
<img src="/2023/03/28/shi-yong-bertopic-ti-qu-wen-ben-zhu-ti/热度图.png" alt="热度图">
<figcaption aria-hidden="true">热度图</figcaption>
</figure>
<p>热度图中颜色相近的色块表示相似度高，可以看到01两主题的内容很相似，颜色较深；同时01两个话题与其他话题的相似度都很高；2号主题与其他的相似度较低，可以从颜色和文本中观察到。</p>
<p><strong>可视化呈现话题间距离</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">topic_model.visualize_topics()<br></code></pre></td></tr></table></figure>
<figure>
<img src="/2023/03/28/shi-yong-bertopic-ti-qu-wen-ben-zhu-ti/话题间距离.png" alt="话题间距离">
<figcaption aria-hidden="true">话题间距离</figcaption>
</figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Bert</tag>
        <tag>NLP</tag>
        <tag>BERTopic</tag>
        <tag>文本主题</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Bert进行中文NER命名实体识别feat.fastNLP（上：模型篇）</title>
    <url>/2023/03/18/shi-yong-bert-jin-xing-ner-ming-ming-shi-ti-shi-bie-feat-fastnlp/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<blockquote>
<p>项目工程地址：https://github.com/Ash-one/ChineseBert-finetuned-NER</p>
</blockquote>
<p>chatGPT的大火让很多NLP工作者的研究都陷入僵局，NER这种传统任务对于这种LLM已经可以说是小菜一碟。</p>
<figure>
<img src="/2023/03/18/shi-yong-bert-jin-xing-ner-ming-ming-shi-ti-shi-bie-feat-fastnlp/newbingner.png" alt="NewBing进行ner">
<figcaption aria-hidden="true">NewBing进行ner</figcaption>
</figure>
<p>虽然没能力搞个GPT出来，搞个简单的Bert微调还是可以做到的。</p>
<p>本文对于NER命名实体识别任务，使用复旦大学的fastNLP工具包快速完成Bert微调和预测任务，还实现了Bert+BiLSTM+CRF的模型提高预测准确率，最终部署在服务器上可视化呈现。</p>
<figure>
<img src="https://s2.loli.net/2023/03/25/e53mHihFl8JENqV.png" alt="结果展示">
<figcaption aria-hidden="true">结果展示</figcaption>
</figure>
<p>fastNLP<a href="http://document.fastnlp.top/docs/fastNLP/">文档</a>和<a href="https://gitee.com/fastnlp/fastNLP">gitee仓库</a>最近更新在五个月前，还比较活跃。fastNLP在手册上有序列标注的<a href="http://www.fastnlp.top/docs/fastNLP/master/tutorials/torch/fastnlp_torch_tutorial_seq_labeling.html">源码实现</a>，本文基于此进行改写。</p>
<h1 id="数据预处理">数据预处理</h1>
<h2 id="使用内置的dataloader加载weibo数据集">使用内置的dataloader加载Weibo数据集</h2>
<p>fastNLP自带库中有许多内置数据集，这里选择微博数据集展示，其实体类别分为人物，机构组织，地址和地缘政治实体四个类别，且每个类别可细分为特指（NAM，如“张三”标签为“PER.NAM”）和泛指（NOM，如“男人”标签为“PER.NOM”）。总数据量1890条。</p>
<table>
<thead>
<tr class="header">
<th>含义</th>
<th>标签</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>地区名特指，如深圳</td>
<td>B-GPE.NAM I-GPE.NAM</td>
</tr>
<tr class="even">
<td>地名特指，如华克山庄</td>
<td>B-LOC.NAM I-LOC.NAM</td>
</tr>
<tr class="odd">
<td>地名泛指，如寺庙</td>
<td>B-LOC.NOM I-LOC.NOM</td>
</tr>
<tr class="even">
<td>组织名特指</td>
<td>B-ORG.NAM I-ORG.NAM</td>
</tr>
<tr class="odd">
<td>组织名泛指</td>
<td>B-ORG.NOM I-ORG.NOM</td>
</tr>
<tr class="even">
<td>人名特指，如方进玉</td>
<td>B-PER.NAM I-PER.NAM</td>
</tr>
<tr class="odd">
<td>人名泛指，如男人</td>
<td>B-PER.NOM I-PER.NOM</td>
</tr>
<tr class="even">
<td>其他</td>
<td>O</td>
</tr>
</tbody>
</table>
<p>17个标签的分布如图所示：</p>
<figure>
<img src="/2023/03/18/shi-yong-bert-jin-xing-ner-ming-ming-shi-ti-shi-bie-feat-fastnlp/数据集标签总览.png" alt="数据集标签总览">
<figcaption aria-hidden="true">数据集标签总览</figcaption>
</figure>
<p>接下来开始使用fastNLP库的loader下载并加载数据到<code>data_bundle</code>中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastNLP.io <span class="hljs-keyword">import</span> WeiboNERLoader<br>data_bundle = WeiboNERLoader().load()<br><span class="hljs-built_in">print</span>(data_bundle)<br><span class="hljs-built_in">print</span>(data_bundle.get_dataset(<span class="hljs-string">&#x27;train&#x27;</span>)[:<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>
<p><code>data_bundle</code>和它的名字一样，是训练集、验证集、测试集的打包，需要分别提取。</p>
<figure class="highlight lasso"><table><tr><td class="code"><pre><code class="hljs lasso"><span class="hljs-keyword">In</span> total <span class="hljs-number">3</span> datasets:<br>        dev has <span class="hljs-number">270</span> instances.<br>        test has <span class="hljs-number">270</span> instances.<br>        train has <span class="hljs-number">1350</span> instances.<br><br>+------------------------------------------+------------------------------------------+<br>| raw_chars                                | target                                   |<br>+------------------------------------------+------------------------------------------+<br>| <span class="hljs-meta">[</span><span class="hljs-string">&#x27;科&#x27;</span>, <span class="hljs-string">&#x27;技&#x27;</span>, <span class="hljs-string">&#x27;全&#x27;</span>, <span class="hljs-string">&#x27;方&#x27;</span>, <span class="hljs-string">&#x27;位&#x27;</span>, <span class="hljs-string">&#x27;资&#x27;</span>, <span class="hljs-params">...</span> | <span class="hljs-meta">[</span><span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;... |</span><br><span class="hljs-string">| [&#x27;</span>对<span class="hljs-string">&#x27;, &#x27;</span>，<span class="hljs-string">&#x27;, &#x27;</span>输<span class="hljs-string">&#x27;, &#x27;</span>给<span class="hljs-string">&#x27;, &#x27;</span>一<span class="hljs-string">&#x27;, &#x27;</span>个<span class="hljs-string">&#x27;, ... | [&#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>B<span class="hljs-params">-PER...</span> |<br>| <span class="hljs-meta">[</span><span class="hljs-string">&#x27;今&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;下&#x27;</span>, <span class="hljs-string">&#x27;午&#x27;</span>, <span class="hljs-string">&#x27;起&#x27;</span>, <span class="hljs-string">&#x27;来&#x27;</span>, <span class="hljs-params">...</span> | <span class="hljs-meta">[</span><span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;... |</span><br><span class="hljs-string">| [&#x27;</span>今<span class="hljs-string">&#x27;, &#x27;</span>年<span class="hljs-string">&#x27;, &#x27;</span>拜<span class="hljs-string">&#x27;, &#x27;</span>年<span class="hljs-string">&#x27;, &#x27;</span>不<span class="hljs-string">&#x27;, &#x27;</span>短<span class="hljs-string">&#x27;, ... | [&#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span>O<span class="hljs-string">&#x27;, &#x27;</span><span class="hljs-params">...</span> |<br>+------------------------------------------+------------------------------------------+<br></code></pre></td></tr></table></figure>
<h2 id="计算数据集中的属性">计算数据集中的属性</h2>
<p>使用BertTokenizer和BPE算法处理文本，得到<code>input_ids|input_len | first| seq_len | new_target</code>这几列，其中<code>first</code>表示<code>bpe</code>算法的结果，在后面的模型中会使用，这里使用<code>new_target</code>作为最终label的编码表示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastNLP.transformers.torch <span class="hljs-keyword">import</span> BertTokenizer<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> cache_results, Vocabulary<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_data</span>(<span class="hljs-params">data_bundle, model_name</span>):<br>    tokenizer = BertTokenizer.from_pretrained(model_name)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">bpe</span>(<span class="hljs-params">raw_words</span>):<br>        bpes = [tokenizer.cls_token_id]<br>        first = [<span class="hljs-number">0</span>]<br>        first_index = <span class="hljs-number">1</span>  <span class="hljs-comment"># 记录第一个bpe的位置</span><br>        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> raw_words:<br>            bpe = tokenizer.encode(word, add_special_tokens=<span class="hljs-literal">False</span>)<br>            bpes.extend(bpe)<br>            first.append(first_index)<br>            first_index += <span class="hljs-built_in">len</span>(bpe)<br>        bpes.append(tokenizer.sep_token_id)<br>        first.append(first_index)<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;input_ids&#x27;</span>: bpes, <span class="hljs-string">&#x27;input_len&#x27;</span>: <span class="hljs-built_in">len</span>(bpes), <span class="hljs-string">&#x27;first&#x27;</span>: first, <span class="hljs-string">&#x27;seq_len&#x27;</span>: <span class="hljs-built_in">len</span>(raw_words)&#125;<br>    <span class="hljs-comment"># 对data_bundle中每个dataset的每一条数据中的raw_chars使用bpe函数，并且将返回的结果加入到每条数据中。</span><br>    data_bundle.apply_field_more(bpe, field_name=<span class="hljs-string">&#x27;raw_chars&#x27;</span>, num_proc=<span class="hljs-number">4</span>)<br>		<span class="hljs-comment"># --------------------------------------------这里需要注意field_name</span><br>    <span class="hljs-comment"># tag的词表，由于这是词表，所以不需要有padding和unk</span><br>    tag_vocab = Vocabulary(padding=<span class="hljs-literal">None</span>, unknown=<span class="hljs-literal">None</span>)<br>    <span class="hljs-comment"># 从 train 数据的 raw_target 中获取建立词表</span><br>    tag_vocab.from_dataset(data_bundle.get_dataset(<span class="hljs-string">&#x27;train&#x27;</span>), field_name=<span class="hljs-string">&#x27;target&#x27;</span>)<br>    <span class="hljs-comment"># 使用词表将每个 dataset 中的target转为数字，并且将写入到new_target这个field中</span><br>    tag_vocab.index_dataset(data_bundle.datasets.values(), field_name=<span class="hljs-string">&#x27;target&#x27;</span>, new_field_name=<span class="hljs-string">&#x27;new_target&#x27;</span>)<br>    <br>    <span class="hljs-comment"># 可以将 vocabulary 绑定到 data_bundle 上，方便之后使用。</span><br>    data_bundle.set_vocab(tag_vocab, field_name=<span class="hljs-string">&#x27;new_target&#x27;</span>)<br>    <br>    <span class="hljs-keyword">return</span> data_bundle, tokenizer<br><br>data_bundle, tokenizer = process_data(data_bundle, <span class="hljs-string">&#x27;hfl/rbt3&#x27;</span>)<br><span class="hljs-built_in">print</span>(data_bundle)<br><span class="hljs-built_in">print</span>(data_bundle.get_dataset(<span class="hljs-string">&quot;train&quot;</span>)[:<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>
<p>可以看出<code>input_len</code>比<code>seq_len</code>多两个，分别是一头一尾两个token。</p>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><code class="hljs jboss-cli">[08<span class="hljs-function">:23</span><span class="hljs-function">:40</span> AM] INFO     In total 3 datasets:                                  1356482314.py<span class="hljs-function">:35</span><br>                               dev has 270 instances.                                        <br>                               test has 270 instances.                                       <br>                               train has 1350 instances.                                     <br>                       In total 1 vocabs:                                                    <br>                               new_target has 17 entries.                                    <br>                                                                                             <br>              INFO     +<span class="hljs-params">----------------</span>+<span class="hljs-params">----------------</span>+<span class="hljs-params">----------------</span>+- 1356482314.py<span class="hljs-function">:36</span><br>                       <span class="hljs-params">----------</span>+<span class="hljs-params">----------------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">---------------</span>                 <br>                       -+                                                                    <br>                       | raw_chars      | target         | input_ids      |                  <br>                       input_len | first          | seq_len | new_target                     <br>                       |                                                                 <br>                       +<span class="hljs-params">----------------</span>+<span class="hljs-params">----------------</span>+<span class="hljs-params">----------------</span>+-                 <br>                       <span class="hljs-params">----------</span>+<span class="hljs-params">----------------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">---------------</span>                 <br>                       -+                                                                    <br>                       | [&#x27;科&#x27;, &#x27;技&#x27;<span class="hljs-string">...</span> | [&#x27;O&#x27;, &#x27;O&#x27;, <span class="hljs-string">...</span> | [101, 4906,<span class="hljs-string">...</span> |                  <br>                       28        | [0, 1, 2, 3.<span class="hljs-string">..</span> | 26      | [0, 0, 0, 0.<span class="hljs-string">..</span>                 <br>                       |                                                                     <br>                       | [&#x27;对&#x27;, &#x27;，&#x27;<span class="hljs-string">...</span> | [&#x27;O&#x27;, &#x27;O&#x27;, <span class="hljs-string">...</span> | [101, 2190,<span class="hljs-string">...</span> |                  <br>                       17        | [0, 1, 2, 3.<span class="hljs-string">..</span> | 15      | [0, 0, 0, 0.<span class="hljs-string">..</span>                 <br>                       |                                                                     <br>                       | [&#x27;今&#x27;, &#x27;天&#x27;<span class="hljs-string">...</span> | [&#x27;O&#x27;, &#x27;O&#x27;, <span class="hljs-string">...</span> | [101, 791, <span class="hljs-string">...</span> |                  <br>                       81        | [0, 1, 2, 3.<span class="hljs-string">..</span> | 79      | [0, 0, 0, 0.<span class="hljs-string">..</span>                 <br>                       |                                                                     <br>                       | [&#x27;今&#x27;, &#x27;年&#x27;<span class="hljs-string">...</span> | [&#x27;O&#x27;, &#x27;O&#x27;, <span class="hljs-string">...</span> | [101, 791, <span class="hljs-string">...</span> |                  <br>                       20        | [0, 1, 2, 3.<span class="hljs-string">..</span> | 18      | [0, 0, 0, 0.<span class="hljs-string">..</span>                 <br>                       |                                                                     <br>                       +<span class="hljs-params">----------------</span>+<span class="hljs-params">----------------</span>+<span class="hljs-params">----------------</span>+-                 <br>                       <span class="hljs-params">----------</span>+<span class="hljs-params">----------------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">---------------</span>                 <br>                       -+ <br></code></pre></td></tr></table></figure>
<h2 id="将计算后的数据放入dataloader">将计算后的数据放入dataloader</h2>
<p>制作dataloader方便遍历，bs大小256大约占用20G显存。</p>
<p><strong>对输入和输出分别进行padding</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> prepare_torch_dataloader<br><br>dataloaders = prepare_torch_dataloader(data_bundle, batch_size=<span class="hljs-number">256</span>)<br><br><span class="hljs-keyword">for</span> dl <span class="hljs-keyword">in</span> dataloaders.values():<br>    <span class="hljs-comment"># 可以通过 set_pad 修改 padding 的行为。</span><br>    dl.set_pad(<span class="hljs-string">&#x27;input_ids&#x27;</span>, pad_val=tokenizer.pad_token_id)<br>    dl.set_pad(<span class="hljs-string">&#x27;new_target&#x27;</span>, pad_val=-<span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure>
<h1 id="bert模型微调">Bert模型微调</h1>
<p>Bert模型的提供者们往往提供的是预训练模型，我们可以在预训练模型之后添加其他模型或层来改变输出，而将Bert的部分当作对文字编码的部分使用。这里后接MLP作为NER任务的baseline做参考，然后在Bert后添加BiLSTM和CRF进行对比。</p>
<h2 id="设计bertmlp模型">设计Bert+MLP模型</h2>
<p>fastNLP的模型基于torch，所以写法是一样的；同时内置的transformer库也是huggingface的直接迁移，用法上完全一样，只是默认的模型加载路径和huggingface的transformer库不一样，如果同时使用可能会发现缓存位置不同而重复下载。</p>
<ul>
<li>这里使用<code>hfl/rbt3</code>这个中文Bert模型，大小约500M，<code>BertModel.from_pretrained()</code>函数会从远程拉取该模型保存在缓存后加载（复旦源，国内很快）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> fastNLP.transformers.torch <span class="hljs-keyword">import</span> BertModel<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> seq_len_to_mask<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BertNER</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_name, num_class</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.bert = BertModel.from_pretrained(model_name)<br>        self.mlp = nn.Sequential(nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size),<br>                                nn.Dropout(<span class="hljs-number">0.3</span>),<br>                                nn.Linear(self.bert.config.hidden_size, num_class))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, input_len, first</span>):<br>        attention_mask = seq_len_to_mask(input_len)<br>        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)<br>        last_hidden_state = outputs.last_hidden_state<br>        first = first.unsqueeze(-<span class="hljs-number">1</span>).repeat(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, last_hidden_state.size(-<span class="hljs-number">1</span>))<br>        first_bpe_state = last_hidden_state.gather(dim=<span class="hljs-number">1</span>, index=first)<br>        first_bpe_state = first_bpe_state[:, <span class="hljs-number">1</span>:-<span class="hljs-number">1</span>]  <span class="hljs-comment"># 删除 cls 和 sep</span><br><br>        pred = self.mlp(first_bpe_state)<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;pred&#x27;</span>: pred&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_step</span>(<span class="hljs-params">self, input_ids, input_len, first, target</span>):<br>        pred = self(input_ids, input_len, first)[<span class="hljs-string">&#x27;pred&#x27;</span>]<br>        loss = F.cross_entropy(pred.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), target)<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_step</span>(<span class="hljs-params">self, input_ids, input_len, first</span>):<br>        pred = self(input_ids, input_len, first)[<span class="hljs-string">&#x27;pred&#x27;</span>].argmax(dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;pred&#x27;</span>: pred&#125;<br>    <br>model = BertNER(<span class="hljs-string">&#x27;hfl/rbt3&#x27;</span>, <span class="hljs-built_in">len</span>(data_bundle.get_vocab(<span class="hljs-string">&#x27;new_target&#x27;</span>)))<br></code></pre></td></tr></table></figure>
<p><code>forward</code>函数和torch写法相同，<code>train_step</code>会被后面声明的trainer对象调用，计算训练的每一步loss，<code>evaluate_step</code>会被后面声明的evaluator对象调用，相当于预测函数，返回的是预测标签对应的数字index。</p>
<h2 id="设计bertbilstmcrf模型">设计Bert+BiLSTM+CRF模型</h2>
<p>这里需要考虑的是三个模型之间的输入输出要匹配，去掉了bpe算法部分方便将bert结果输入LSTM，另外在CRF模型的输入中mask大小不是Bert输入的带有前后标记的attention
mask，而是最简单的长度mask，所以重新制作了mask输入crf中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> fastNLP.transformers.torch <span class="hljs-keyword">import</span> BertModel<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> seq_len_to_mask<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> fastNLP.modules.torch <span class="hljs-keyword">import</span> ConditionalRandomField<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BertBilstmCrfNER</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_name,num_class, embedding_dim = <span class="hljs-number">768</span>,hidden_size=<span class="hljs-number">512</span>,dropout=<span class="hljs-number">0.5</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.bert = BertModel.from_pretrained(model_name)<br>        <br>        self.lstm = nn.LSTM(<br>            input_size=embedding_dim,<br>            num_layers=<span class="hljs-number">2</span>,<br>            hidden_size=hidden_size,<br>            bidirectional=<span class="hljs-literal">True</span>,<br>            batch_first=<span class="hljs-literal">True</span>)<br>        self.dropout = nn.Dropout(dropout)<br>        self.fc = nn.Linear(hidden_size * <span class="hljs-number">2</span>, num_class)<br>        self.crf = ConditionalRandomField(num_class)<br>        <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, input_len,target=<span class="hljs-literal">None</span></span>):<br>        attention_mask = seq_len_to_mask(input_len)<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)<br>        last_hidden_state = outputs.last_hidden_state<br><br>        first_bpe_state = last_hidden_state[:, <span class="hljs-number">1</span>:-<span class="hljs-number">1</span>]<br>        feats, _ = self.lstm(first_bpe_state) <span class="hljs-comment"># 输入lstm</span><br>        feats = self.fc(feats)<br>        feats = self.dropout(feats)<br>        logits = F.log_softmax(feats, dim=-<span class="hljs-number">1</span>)<br>        <br>        mask = seq_len_to_mask(input_len-<span class="hljs-number">2</span>)<br>        <br>        <span class="hljs-keyword">if</span> target <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            pred, _ = self.crf.viterbi_decode(logits, mask)<br>            <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;pred&#x27;</span>: pred&#125;<br>        <span class="hljs-keyword">else</span>:<br>            loss = self.crf(logits, target, mask).mean()<br>            <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_step</span>(<span class="hljs-params">self, input_ids, input_len, target</span>):<br>        <span class="hljs-comment"># &#123;&#x27;loss&#x27;:loss&#125;</span><br>        <span class="hljs-keyword">return</span> self(input_ids, input_len,target)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_step</span>(<span class="hljs-params">self, input_ids, input_len</span>):<br>        <span class="hljs-comment">#  &#123;&#x27;pred&#x27;: pred&#125;</span><br>        <span class="hljs-keyword">return</span> self(input_ids, input_len)<br><br>model = BertBilstmCrfNER(<span class="hljs-string">&#x27;hfl/rbt3&#x27;</span>, <span class="hljs-built_in">len</span>(data_bundle.get_vocab(<span class="hljs-string">&#x27;new_target&#x27;</span>)))<br></code></pre></td></tr></table></figure>
<h2 id="开始训练">开始训练</h2>
<p>这里我们准备Trainer对象的各个参数，具体细节不做深入解释，看名字很好理解。</p>
<p><strong>其中Trainer对象默认调用数据的标签的表头是target，所以这里需要这个函数将我们自己设计的new_target列调整。</strong>如果你和我一样是按照官方文档的写法，直接调用官方loader加载，在这里就需要这个函数，因为在文档里的ipython结果是从文件读取的，列名称和loader加载的不同。</p>
<p>实际训练中CRF模型训练需要调大学习率，否则转移矩阵的学习结果会很差，实际使用的lr为2e-2，是mlp模型的一千倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> Trainer, LoadBestModelCallback, TorchWarmupCallback<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> SpanFPreRecMetric<br><br>optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br>callbacks = [<br>    LoadBestModelCallback(),<br>    TorchWarmupCallback(),<br>]<br>metrics = &#123;<br>    <span class="hljs-string">&quot;f&quot;</span>: SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab(<span class="hljs-string">&#x27;new_target&#x27;</span>)),<br>&#125;<br><br><span class="hljs-comment"># ————重要函数----Trainer对象默认调用数据的标签的表头是target，所以这里需要这个函数将我们自己设计的new_target列调整</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">input_mapping</span>(<span class="hljs-params">data</span>):<br>    data[<span class="hljs-string">&#x27;target&#x27;</span>] = data[<span class="hljs-string">&#x27;new_target&#x27;</span>]<br>    <span class="hljs-keyword">return</span> data<br><br>trainer = Trainer(model=model, train_dataloader=dataloaders[<span class="hljs-string">&#x27;train&#x27;</span>], optimizers=optimizer,<br>                  evaluate_dataloaders=dataloaders[<span class="hljs-string">&#x27;dev&#x27;</span>],<br>                  metrics=metrics, n_epochs=<span class="hljs-number">50</span>, callbacks=callbacks,<br>                  monitor=<span class="hljs-string">&#x27;f#f&#x27;</span>,device=<span class="hljs-string">&#x27;cuda&#x27;</span>,driver=<span class="hljs-string">&quot;torch&quot;</span>,input_mapping=input_mapping)<br>trainer.run()<br></code></pre></td></tr></table></figure>
<ul>
<li>Bert+MLP模型：50轮跑完结果如下，自动将最佳模型加载到model对象，这里在验证集上的F1值有0.573477，不算很高，因为Bert直接微调效果有限，但是预测结果有一定的参考价值了。</li>
</ul>
<figure class="highlight smali"><table><tr><td class="code"><pre><code class="hljs smali">[11:36:55 AM] INFO     The best performance for<span class="hljs-built_in"> monitor </span>f<span class="hljs-comment">#f:0.573477  progress_callback.py:37</span><br>                       was achieved in Epoch:47, Global Batch:282.                           <br>                       The evaluation result:                                                <br>                       &#123;&#x27;f<span class="hljs-comment">#f&#x27;: 0.573477, &#x27;pre#f&#x27;: 0.535714, &#x27;rec#f&#x27;:                         </span><br>                       0.616967&#125;                                                             <br>              INFO     Loading best model from buffer with    load_best_model_callback.py:120<br>                       f<span class="hljs-comment">#f: 0.573477 (achieved in Epoch: 47,                                 </span><br>                       Global Batch: 282) ... <br></code></pre></td></tr></table></figure>
<ul>
<li><p>Bert+BiLSTM+CRF模型：F1值有0.705416，提升明显。</p>
<figure>
<img src="/2023/03/18/shi-yong-bert-jin-xing-ner-ming-ming-shi-ti-shi-bie-feat-fastnlp/三段模型结果.png" alt="Bert+BiLSTM+CRF模型结果">
<figcaption aria-hidden="true">Bert+BiLSTM+CRF模型结果</figcaption>
</figure></li>
</ul>
<h2 id="模型保存和加载">模型保存和加载</h2>
<p>训练好模型之后需要进行保存，这里使用torch的保存，fastNLP也有自己的保存方法，是相同的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br>torch.save(model,<span class="hljs-string">&#x27;rbt3-mlp-ner.pth&#x27;</span>)<br>ner_model = torch.load(<span class="hljs-string">&#x27;rbt3-mlp-ner.pth&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h1 id="使用模型预测">使用模型预测</h1>
<p>由于后续需要部署到服务器上进行使用，这里需要构建好整个预测流程，fastNLP工具包本身没有这个功能，只是用来快速构建模型验证，但是预测流程本身与训练流程相同，并不复杂。</p>
<ul>
<li>将预测文本放入dataset，再放入databundle，经过bpe计算，</li>
<li>放入dataloader，交给evaluator调用预测函数得到预测结果。</li>
</ul>
<h2 id="构建dataset">构建dataset</h2>
<p>其实是构建一个只有一条数据的的dataset再放入databundle对象中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastNLP.io <span class="hljs-keyword">import</span> DataBundle<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> DataSet, Instance<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">text2dataset</span>(<span class="hljs-params">text:<span class="hljs-built_in">str</span></span>):<br>    ds = DataSet()<br>    <span class="hljs-keyword">if</span> text != <span class="hljs-string">&#x27;&#x27;</span>:  <br>        ds.append(Instance(raw_words = <span class="hljs-built_in">list</span>(text)))<br>    <span class="hljs-keyword">return</span> ds<br><br>text = <span class="hljs-string">&#x27;我今天就要在中国传媒大学吃上崔永元真面！&#x27;</span><br><br>predict_data_bundle = DataBundle(datasets=&#123;<br>    <span class="hljs-string">&quot;predict&quot;</span>: text2dataset(text),<br>&#125;)<br><span class="hljs-built_in">print</span>(predict_data_bundle)<br><span class="hljs-built_in">print</span>(predict_data_bundle.get_dataset(<span class="hljs-string">&quot;predict&quot;</span>))<br></code></pre></td></tr></table></figure>
<p>结果如下，这里Instance对象赋给输入的列名是<code>raw_words</code>，和前面默认loader加载是不同的。</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><code class="hljs ada"><span class="hljs-comment">--------------------------+| raw_words|+---------------------------------------+                                           </span><br>| [<span class="hljs-string">&#x27;我&#x27;</span>, <span class="hljs-string">&#x27;今&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;就&#x27;</span>, <span class="hljs-string">&#x27;要&#x27;</span>, <span class="hljs-string">&#x27;在&#x27;</span>, <span class="hljs-string">&#x27;中&#x27;</span>, <span class="hljs-string">&#x27;国&#x27;</span>, <span class="hljs-string">&#x27;传&#x27;</span>, <span class="hljs-string">&#x27;媒&#x27;</span>, <span class="hljs-string">&#x27;大&#x27;</span>, <span class="hljs-string">&#x27;学&#x27;</span>, ... |                                         <br>+<span class="hljs-comment">------------------------------------------------------------------------------+ </span><br></code></pre></td></tr></table></figure>
<h2 id="构建dataloader">构建dataloader</h2>
<p>其实就是把前面的函数改一改，甚至可以将前面的函数加参数重构，重复使用。<strong>需要注意的是loader的列名不一样</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastNLP.transformers.torch <span class="hljs-keyword">import</span> BertTokenizer<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> cache_results, Vocabulary<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_predict_data</span>(<span class="hljs-params">data_bundle, model_name</span>):<br><br>    tokenizer = BertTokenizer.from_pretrained(model_name)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">bpe</span>(<span class="hljs-params">raw_words</span>):<br>        bpes = [tokenizer.cls_token_id]<br>        first = [<span class="hljs-number">0</span>]<br>        first_index = <span class="hljs-number">1</span>  <span class="hljs-comment"># 记录第一个bpe的位置</span><br>        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> raw_words:<br>            bpe = tokenizer.encode(word, add_special_tokens=<span class="hljs-literal">False</span>)<br>            bpes.extend(bpe)<br>            first.append(first_index)<br>            first_index += <span class="hljs-built_in">len</span>(bpe)<br>        bpes.append(tokenizer.sep_token_id)<br>        first.append(first_index)<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;input_ids&#x27;</span>: bpes, <span class="hljs-string">&#x27;input_len&#x27;</span>: <span class="hljs-built_in">len</span>(bpes), <span class="hljs-string">&#x27;first&#x27;</span>: first, <span class="hljs-string">&#x27;seq_len&#x27;</span>: <span class="hljs-built_in">len</span>(raw_words)&#125;<br>    <span class="hljs-comment"># 对data_bundle中每个dataset的每一条数据中的raw_words使用bpe函数，并且将返回的结果加入到每条数据中。</span><br>    data_bundle.apply_field_more(bpe, field_name=<span class="hljs-string">&#x27;raw_words&#x27;</span>, num_proc=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> data_bundle, tokenizer<br><br>predict_data_bundle, predict_tokenizer = process_predict_data(predict_data_bundle, <span class="hljs-string">&#x27;hfl/rbt3&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(predict_data_bundle)<br><span class="hljs-built_in">print</span>(predict_data_bundle.get_dataset(<span class="hljs-string">&quot;predict&quot;</span>))<br><br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> prepare_torch_dataloader<br><br>predict_dataloaders = prepare_torch_dataloader(predict_data_bundle, batch_size=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>结果如下，和前面的loader相比只是少了target一列，不过因为是做预测本身也用不到。</p>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><code class="hljs jboss-cli">+<span class="hljs-params">---------------------</span>+<span class="hljs-params">--------------------</span>+<span class="hljs-params">-----------</span>+<span class="hljs-params">--------------------</span>+<span class="hljs-params">---------</span>+<br>| raw_words | input_ids | input_len | first | seq_len |<br>+<span class="hljs-params">---------------------</span>+<span class="hljs-params">--------------------</span>+<span class="hljs-params">-----------</span>+<span class="hljs-params">--------------------</span>+<span class="hljs-params">---------</span>+<br>| [&#x27;我&#x27;, &#x27;今&#x27;, &#x27;天<span class="hljs-string">...</span> | [101, 2769, 791.<span class="hljs-string">..</span> | 22 | [0, 1, 2, 3, 4,<span class="hljs-string">...</span> | 20 |                                      <br>+<span class="hljs-params">---------------------</span>+<span class="hljs-params">--------------------</span>+<span class="hljs-params">-----------</span>+<span class="hljs-params">--------------------</span>+<span class="hljs-params">---------</span>+ <br></code></pre></td></tr></table></figure>
<h2 id="进行预测">进行预测</h2>
<h3 id="第一种方法evaluator对象进行预测">第一种方法：Evaluator对象进行预测</h3>
<p>通常的预测方法是构建一个evaluator对象用于调用模型的预测函数，<strong>这里需要加载数据集中的vocab用于进行idx2word</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_output_labeling</span>(<span class="hljs-params">evaluator, batch</span>):<br>    outputs = evaluator.evaluate_step(batch)[<span class="hljs-string">&quot;pred&quot;</span>]<br>    raw_words = batch[<span class="hljs-string">&quot;raw_words&quot;</span>]<br>    <span class="hljs-keyword">for</span> words, output <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(raw_words, outputs):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;sentence:&quot;</span>, words)<br>        labels = [data_bundle.get_vocab(<span class="hljs-string">&quot;new_target&quot;</span>).idx2word[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> output[:<span class="hljs-built_in">len</span>(words)].tolist() ]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;labels:&quot;</span>, labels)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;outputs:&#x27;</span>,outputs)<br>predictor = Evaluator(model=ner_model, dataloaders=predict_dataloaders[<span class="hljs-string">&quot;predict&quot;</span>],<br>                      device=<span class="hljs-number">0</span>, evaluate_batch_step_fn=predict_output_labeling)<br>predictor.run(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>预测结果如下：</p>
<figure>
<img src="/2023/03/18/shi-yong-bert-jin-xing-ner-ming-ming-shi-ti-shi-bie-feat-fastnlp/预测结果.png" alt="预测结果">
<figcaption aria-hidden="true">预测结果</figcaption>
</figure>
<p>这种方法查看预测结果是没有问题的，但是evaluator没有设置返回的参数，我们无法保存预测的结果用于后面部署可视化展示。</p>
<h3 id="第二种方法手动调用模型中的evaluate_step方法">第二种方法：手动调用模型中的<code>evaluate_step</code>方法</h3>
<p>考虑到我们部署的需求，需要提前将label和idx的对应关系提取出来，在预测后得到outputs列表后翻译成label。下面是一些工具函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">label_idx_list = <span class="hljs-built_in">list</span>(data_bundle.get_vocab(<span class="hljs-string">&quot;new_target&quot;</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">write_list_into_text</span>(<span class="hljs-params">path,label_idx_list</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path,<span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> label_idx_list:<br>            f.writelines(<span class="hljs-built_in">str</span>(pair[<span class="hljs-number">0</span>])+<span class="hljs-string">&#x27;,&#x27;</span>+<span class="hljs-built_in">str</span>(pair[<span class="hljs-number">1</span>]))<br>            f.write(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;write over!&#x27;</span>)<br>        <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_list_from_text</span>(<span class="hljs-params">path</span>):<br>    final_list = []<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path,<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        lines = f.readlines()<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines:<br>            line = line.strip().split(<span class="hljs-string">&#x27;,&#x27;</span>)<br>            final_list.append((line[<span class="hljs-number">0</span>],<span class="hljs-built_in">int</span>(line[<span class="hljs-number">1</span>])))<br>    <span class="hljs-keyword">return</span> final_list<br>    <br>write_list_into_text(<span class="hljs-string">&#x27;label_idx_list.txt&#x27;</span>,label_idx_list)<br>label_idx_list = read_list_from_text(<span class="hljs-string">&#x27;label_idx_list.txt&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">idx2label</span>(<span class="hljs-params">label_idx_list:<span class="hljs-built_in">list</span>,idx:<span class="hljs-built_in">int</span></span>):<br>    <span class="hljs-comment"># [(&#x27;O&#x27;,0),(label,idx)...]</span><br>    <span class="hljs-comment"># 用于idx和label转换</span><br>    <span class="hljs-comment"># return label</span><br>    label = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> label_idx_list:<br>        <span class="hljs-keyword">if</span> pair[<span class="hljs-number">1</span>] == idx:<br>             label = pair[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> label<br></code></pre></td></tr></table></figure>
<p>接下来很简单，将制作好的输入数据整理成tensor，调用模型的<code>evaluate_step</code>方法进行预测。</p>
<blockquote>
<p>⚠️这里由于手动调用模型，一定记得使用eval函数将模型设置为评估模式，关闭dropout的影响。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">dev = <span class="hljs-built_in">next</span>(ner_model.parameters()).device<br>ner_model.<span class="hljs-built_in">eval</span>()<br><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> predict_dataloaders[<span class="hljs-string">&#x27;predict&#x27;</span>]:<br>    input_ids = torch.LongTensor(data[<span class="hljs-string">&#x27;input_ids&#x27;</span>]).to(dev)<br>    input_len = torch.LongTensor(data[<span class="hljs-string">&#x27;input_len&#x27;</span>]).to(dev)<br>    first =     torch.LongTensor(data[<span class="hljs-string">&#x27;first&#x27;</span>]).to(dev)<br><br>    result = ner_model.evaluate_step(input_ids,input_len,first)[<span class="hljs-string">&#x27;pred&#x27;</span>]<br></code></pre></td></tr></table></figure>
<p>预测结果如下：</p>
<figure>
<img src="/2023/03/18/shi-yong-bert-jin-xing-ner-ming-ming-shi-ti-shi-bie-feat-fastnlp/手动预测结果.png" alt="手动预测的结果">
<figcaption aria-hidden="true">手动预测的结果</figcaption>
</figure>
<h2 id="准备部署">准备部署</h2>
<p>将模型和txt文件保存好，到此为止模型的方面搞定了，接下来就是用flask搭建网页服务器的内容，内容太长，下一篇继续～</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Bert</tag>
        <tag>NLP</tag>
        <tag>NER</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Bert进行NER命名实体识别feat.fastNLP(下：使用flask部署模型)</title>
    <url>/2023/03/25/shi-yong-bert-jin-xing-ner-ming-ming-shi-ti-shi-bie-feat-fastnlp-xia-shi-yong-flask-bu-shu-mo-xing/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>下篇主要介绍使用flask搭建简单的网页和响应，并实现调用模型推理，完成NER任务可视化。</p>
<blockquote>
<p>增加bilstm+crf的模型确实在预测上更为准确，例子中的“崔永元真面”中可以准确分辨出"崔永元"才是人名，而mlp模型会将“崔永元真”作为一个人名🤣</p>
</blockquote>
<p>项目工程的Github仓库地址为：https://github.com/Ash-one/ChineseBert-finetuned-NER</p>
<figure>
<img src="/2023/03/25/shi-yong-bert-jin-xing-ner-ming-ming-shi-ti-shi-bie-feat-fastnlp-xia-shi-yong-flask-bu-shu-mo-xing/结果.png" alt="结果展示">
<figcaption aria-hidden="true">结果展示</figcaption>
</figure>
<p>服务器使用flask响应get请求，可视化结果部分使用python的displacy库生成HTML直接插入原始HTML。</p>
<h1 id="flask服务端">Flask服务端</h1>
<p>flask工程的目录结构如下，程序的入口在<code>run.py</code>中。</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><code class="hljs stylus">├── app<br>│   ├── __init__<span class="hljs-selector-class">.py</span><br>│   ├── loader<span class="hljs-selector-class">.py</span><br>│   ├── model<span class="hljs-selector-class">.py</span><br>│   ├── run<span class="hljs-selector-class">.py</span><br>│   ├── static<br>│   │   ├── bg<span class="hljs-selector-class">.jpg</span><br>│   │   ├── js<br>│   │   │   └── mystyle<span class="hljs-selector-class">.css</span><br>│   │   └── models<br>│   │       ├── rbt3-bilstm-crf-ner<span class="hljs-selector-class">.pth</span><br>│   │       ├── rbt3-bilstm-crf-ner<span class="hljs-selector-class">.txt</span><br>│   │       ├── rbt3-mlp-ner<span class="hljs-selector-class">.pth</span><br>│   │       └── rbt3-mlp-ner<span class="hljs-selector-class">.txt</span><br>│   └── templates<br>│       └── index<span class="hljs-selector-class">.html</span><br>├── test.py<br></code></pre></td></tr></table></figure>
<h2 id="基础路由">基础路由</h2>
<p>只要在<code>templates</code>文件夹下放置好html文件，就可以直接通过<code>render_template</code>方法渲染出页面。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request, make_response<br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Response, render_template<br><span class="hljs-keyword">import</span> loader<br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> BertNER,BertBilstmCrfNER<br><span class="hljs-keyword">from</span> spacy <span class="hljs-keyword">import</span> displacy<br><br>app = Flask(__name__)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">index</span>():<br>    <span class="hljs-keyword">return</span> render_template(<span class="hljs-string">&#x27;index.html&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="响应get请求">响应get请求</h2>
<p>下面这个装饰器专门响应/predict路径的get请求。</p>
<p>这里由于只需要根据输入参数返回预测结果，故选择使用get请求，检查参数合法后加载对应模型预测，并对预测结果进行后处理，由displacy库渲染为HTML，最后返回响应结果。</p>
<blockquote>
<p>displacy官方表示最好不要在服务器端渲染得到HTML，而是使用他们提供的js文件在客户端渲染，而那个js文件的仓库已经被archived了，不得不用这种方法......</p>
</blockquote>
<p>由于在这个文件中需要获取到模型，因此需要在import阶段加载定义的pytorch模型。加载模型推理的部分比较简单，上篇有所提及，这里不做展示，需要注意的是displacy库的输入格式是形如<code>&#123;'text': '我就要在中国传媒大学吃上崔永元真面', 'ents': [&#123;'label': 'GPE.NAM', 'start': 4, 'end': 6&#125;, &#123;'label': 'ORG.NAM', 'start': 6, 'end': 10&#125;, &#123;'label': 'PER.NAM', 'start': 12, 'end': 15&#125;], 'title': None&#125;</code>的字典，在得到模型预测序列后需要多一步转换为字典。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&#x27;/predict&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict__text</span>():<br>    text = request.args.get(<span class="hljs-string">&#x27;text&#x27;</span>)<br>    model_name = request.args.get(<span class="hljs-string">&#x27;model&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;text:&#x27;</span>,text,<span class="hljs-string">&#x27;model_name:&#x27;</span>,model_name)<br>    <span class="hljs-comment"># 下面对不合法或无法读取的模型进行处理</span><br>    <span class="hljs-keyword">try</span>:<br>        model,label_idx_list = loader.load_model_from_file(model_name)<br>    <span class="hljs-keyword">except</span> IOError:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;IOError&#x27;</span><br>    <span class="hljs-keyword">if</span> model == <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> label_idx_list == <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Model not found&#x27;</span><br>    <br>    result = &#123;&#125;<br>    result[<span class="hljs-string">&#x27;text&#x27;</span>] = text<br>    numbers = [<span class="hljs-built_in">int</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> loader.predict(text,model)]<br>    <br>    labels = loader.convert_result2label(numbers,label_idx_list)<br>    entities = loader.convert_label2entity(labels)<br><br>    result[<span class="hljs-string">&#x27;ents&#x27;</span>] = entities<br>    result[<span class="hljs-string">&#x27;title&#x27;</span>] = <span class="hljs-literal">None</span><br>    <span class="hljs-built_in">print</span>(result)<br>    <br>    <span class="hljs-comment"># 配置需要展示的实体，从loader中加载颜色配置</span><br>    options = &#123;<span class="hljs-string">&quot;ents&quot;</span>: [<span class="hljs-string">&quot;ORG.NAM&quot;</span>,<br>                        <span class="hljs-string">&quot;GPE.NAM&quot;</span>,<br>                        <span class="hljs-string">&quot;PER.NAM&quot;</span>,<br>                        <span class="hljs-string">&quot;LOC.NAM&quot;</span>,<br>                        <span class="hljs-string">&quot;LOC.NOM&quot;</span>,<br>                        <span class="hljs-string">&quot;PER.NOM&quot;</span>,<br>                        <span class="hljs-string">&quot;ORG.NOM&quot;</span><br>                        ], <span class="hljs-string">&quot;colors&quot;</span>: loader.load_colors_preset()&#125;<br>    html = displacy.render(result, style=<span class="hljs-string">&quot;ent&quot;</span>, manual=<span class="hljs-literal">True</span>, options=options)<br><br>    response = make_response(html,<span class="hljs-number">200</span>)<br>    <span class="hljs-keyword">return</span> response<br></code></pre></td></tr></table></figure>
<h1 id="web客户端">Web客户端</h1>
<p>预测过程在个人服务器上会花费较多时间，因此需要在页面中使用js异步控制发送get请求和获取响应，所以不能使用表单form提交get请求，不然会一直卡住不动而实际上是在等待响应，类似于客户端多线程请求，这里使用js的fetch发送get请求，并修改页面内容表示正在等待响应，等收到响应后修改html文件。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="language-javascript"></span><br><span class="language-javascript">    <span class="hljs-keyword">function</span> <span class="hljs-title function_">submitForm</span>(<span class="hljs-params"></span>) &#123;</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> text = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&quot;my-text&quot;</span>).<span class="hljs-property">value</span>;</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> model = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">querySelector</span>(<span class="hljs-string">&#x27;input[name=&quot;model&quot;]:checked&#x27;</span>).<span class="hljs-property">value</span>;</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> waiting = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&quot;waiting-text&quot;</span>);</span><br><span class="language-javascript">        waiting.<span class="hljs-property">innerHTML</span> = <span class="hljs-string">&#x27;正在预测...&#x27;</span>;</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> displacy = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&quot;visual&quot;</span>);</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> url = <span class="hljs-string">&quot;/predict?text=&quot;</span> + text + <span class="hljs-string">&quot;&amp;model=&quot;</span> + model;</span><br><span class="language-javascript">        <span class="hljs-keyword">const</span> response = <span class="hljs-title function_">fetch</span>(url, &#123;</span><br><span class="language-javascript">            <span class="hljs-attr">method</span>: <span class="hljs-string">&#x27;GET&#x27;</span>,</span><br><span class="language-javascript">        &#125;).<span class="hljs-title function_">then</span>(<span class="hljs-keyword">function</span> (<span class="hljs-params">response</span>) &#123;</span><br><span class="language-javascript">            <span class="hljs-keyword">return</span> response.<span class="hljs-title function_">text</span>();</span><br><span class="language-javascript">        &#125;)</span><br><span class="language-javascript">        .<span class="hljs-title function_">then</span>(<span class="hljs-keyword">function</span> (<span class="hljs-params">data</span>) &#123;</span><br><span class="language-javascript">                <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(data);</span><br><span class="language-javascript">                waiting.<span class="hljs-property">innerHTML</span> = <span class="hljs-string">&#x27;&#x27;</span>;</span><br><span class="language-javascript">                displacy.<span class="hljs-property">innerHTML</span> = data;</span><br><span class="language-javascript">                <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">&quot;ok!!!&quot;</span>);</span><br><span class="language-javascript">            &#125;);</span><br><span class="language-javascript">    &#125;</span><br><span class="language-javascript"></span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br>......<br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;input&quot;</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span>输入待预测文本：<span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">textarea</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;my-text&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">rows</span>=<span class="hljs-string">&quot;3&quot;</span> <span class="hljs-attr">cols</span>=<span class="hljs-string">&quot;20&quot;</span>&gt;</span>我就要在中国传媒大学吃上崔永元真面<span class="hljs-tag">&lt;/<span class="hljs-name">textarea</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span>选择一个模型：<span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;radio&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;model&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;rbt3-mlp-ner&quot;</span> <span class="hljs-attr">checked</span>=<span class="hljs-string">&quot;true&quot;</span>&gt;</span>rbt3-mlp-ner<span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;radio&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;model&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;rbt3-bilstm-crf-ner&quot;</span>&gt;</span>rbt3-bilstm-crf-ner<span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;submit&quot;</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;my-button&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;提交开始预测&quot;</span> <span class="hljs-attr">onclick</span>=<span class="hljs-string">&quot;submitForm()&quot;</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Bert</tag>
        <tag>NLP</tag>
        <tag>NER</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Surge开启SSH代理无法通过私钥连接的原因</title>
    <url>/2023/05/23/shi-yong-surge-kai-qi-ssh-dai-li-wu-fa-tong-guo-si-yao-lian-jie-de-yuan-yin/</url>
    <content><![CDATA[<h1 id="问题">问题</h1>
<figure>
<img src="/2023/05/23/shi-yong-surge-kai-qi-ssh-dai-li-wu-fa-tong-guo-si-yao-lian-jie-de-yuan-yin/SSH.png" alt="SSH代理">
<figcaption aria-hidden="true">SSH代理</figcaption>
</figure>
<p>如果不通过密码开启SSH代理就必须使用私钥，使用RSA私钥可以通过ssh连接服务器，但是在Surge设置后出现了<code>ssh authorazition failed</code>的情况，测试代理不通。</p>
<h1 id="解决">解决</h1>
<p><strong>结论放在前面：RSA密钥加密方式不对，更换到ed25519加密方式重新生成密钥</strong></p>
<p>Surge的SSH代理相当于<code>ssh -D</code>命令，开启动态端口转发功能。</p>
<p><strong>如果用的是dropbear这种<em>非openssh</em>工具，是不可以的。</strong></p>
<p>先来检查SSH的加密方式：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -v name@host<br></code></pre></td></tr></table></figure>
<p>找到输出中的：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">debug1: kex: algorithm: curve25519-sha256<br></code></pre></td></tr></table></figure>
<p>代表用的是25519这种加密方式，而我的密钥是RSA的，虽然可以登录，但不能Surge代理用。这种方式是新版本默认的加密方式，如果你的结果不同，那么下面的密钥你也要换成和这里一样的加密方式。</p>
<p>重新生成密钥：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh-keygen -t ed25519 -C <span class="hljs-string">&#x27;xxx@email.com&#x27;</span><br></code></pre></td></tr></table></figure>
<p>把公钥加入服务器-&gt;Surge添加私钥到密钥库-&gt;重新测试代理连接</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>SSH</tag>
        <tag>网络</tag>
        <tag>Surge</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title>使用中转服务器代理访问内网bySSinDocker</title>
    <url>/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/</url>
    <content><![CDATA[<h1 id="目的">目的</h1>
<p>通过常用的代理软件（小火箭）连接到处于内网环境的代理服务器，从而实现在任意地方访问内网的需求，进而可以使用内网跳板机连接其他内网机器，突破SSL会话限制。</p>
<figure>
<img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027122230481.png" alt="在外网可以使用代理服务器访问内网服务">
<figcaption aria-hidden="true">在外网可以使用代理服务器访问内网服务</figcaption>
</figure>
<h1 id="搭建步骤">搭建步骤</h1>
<h2 id="概览">概览</h2>
<ol type="1">
<li><p>为方便快捷，使用docker在内网中部署shadowsocks服务器，放出端口</p></li>
<li><p>为从外部访问内网，使用docker部署frpc监听ss服务器端口，连接带有公网IP的frps</p></li>
<li><p>终端设备上使用Shadowrocket连接ss服务器，配置节点</p></li>
</ol>
<h2 id="搭建ss服务器">搭建SS服务器</h2>
<p>此处选择的docker镜像是<a href="https://registry.hub.docker.com/r/gists/shadowsocks-libev/">gists/shadowsocks-libev</a>，优势是很轻量，只有12M，后面可以研究v2ray插件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker run -d \<br>						--name ss \<br>           -p 8388:8388 \<br>           -p 8388:8388/udp \<br>           -e METHOD=aes-256-gcm \<br>           -e PASSWORD=YOUR_PASSWORD \<br>						gists/shadowsocks-libev<br></code></pre></td></tr></table></figure>
<h2 id="搭建frpc">搭建frpc</h2>
<p>如果你本身就在用frpc，直接添加一个新的服务名和配置就好。</p>
<p>需要提前写好frpc的配置文件，里面需要配置frpc监听和转发到中转服务器的端口，记得打开中转服务器的防火墙放行该端口。我这边演示使用8389端口。</p>
<p>frpc.ini配置示例</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[common]</span><br><span class="hljs-attr">server_addr</span> = YOUR_IP<br><span class="hljs-attr">server_port</span> = <span class="hljs-number">7000</span><br><span class="hljs-attr">token</span> = YOUR_TOKEN<br><br><span class="hljs-section">[ss]</span><br><span class="hljs-attr">type</span> = tcp<br><span class="hljs-attr">local_ip</span> = <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span><br><span class="hljs-attr">local_port</span> = <span class="hljs-number">8388</span><br><span class="hljs-attr">remote_port</span> = <span class="hljs-number">8389</span><br></code></pre></td></tr></table></figure>
<p>运行frpc</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk">docker run  -d \<br>						--name frpc \<br>						--network host \ <br> 						-v <span class="hljs-regexp">/etc/</span>frp<span class="hljs-regexp">/frpc.ini:/</span>etc<span class="hljs-regexp">/frp/</span>frpc.ini \<br>						snowdreamtech/frpc<br></code></pre></td></tr></table></figure>
<h2 id="配置shadowrocket小火箭">配置Shadowrocket小火箭</h2>
<p>进入小火箭点击右上角的加号</p>
<p><img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027144752017.png" alt="image-20221027144752017" style="zoom: 25%;"></p>
<p>填写内容，需要对应ss服务器上的配置填写</p>
<p><img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027145506511.png" alt="image-20221027145506511" style="zoom: 25%;"></p>
<p>然后可以在首页的本地节点中看到刚添加的节点</p>
<p>点击连通性测试查看是否网络已打通</p>
<p>之后我们以外网的环境开始测试能否访问内网，我这里的内网使用的网段是192.168.31.0/24，而小火箭默认是不转发192.168.0.0/16网段的数据的（因为内网不需要规则转发），此处需要修改我们的规则，建议先导出保存一份</p>
<p><img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027150207562.png" alt="image-20221027150207562" style="zoom:25%;"></p>
<p>进入后点击通用</p>
<p><img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027150257581.png" alt="image-20221027150257581" style="zoom:25%;"></p>
<p>我删除这里的两个192.168.0.0/16网段，你需要根据自己的内网网段删除。</p>
<p>然后准备添加配置文件，目的是将你自己的内网IP通过ss服务器转发到内网中。（这一步建议将默认conf配置文件备份好）我这里进入default.conf，点击测试规则，测试你的内网IP。</p>
<p><img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027171319764.png" alt="image-20221027171319764" style="zoom:25%;"></p>
<p>我这里测试我的内网网关</p>
<p><img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027171655099.png" alt="image-20221027171655099" style="zoom:25%;"></p>
<p>可以看到它成功测试出了这条网关地址CIDR前缀是24，并选择使用PROXY规则转发给代理服务器。如果无误可以直接点击<strong>添加IP到规则</strong>。</p>
<p>或者你可以像我一样添加整个网段。</p>
<figure>
<img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027171938222.png" alt="image-20221027171938222">
<figcaption aria-hidden="true">image-20221027171938222</figcaption>
</figure>
<p>这样就可以直接访问子网下的所有设备了，我这里开启连接ss代理后就能直接访问内网中的nas</p>
<p><img src="/2022/10/27/shi-yong-zhong-zhuan-fu-wu-qi-dai-li-fang-wen-nei-wang-byssindocker/image-20221027172217114.png" alt="image-20221027172217114" style="zoom: 25%;"></p>
<p>后面只需要在需要访问内网时开启小火箭代理就可以了！</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title>在Linux上无sudo安装使用ProxyChains</title>
    <url>/2023/04/18/zai-linux-shang-shi-yong-proxychains-wu-root-quan-xian/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>多人共用服务器时经常遇到分配的账户无sudo权限、无法提权，但是经常需要安装软件。</p>
<p>通常来讲下载源码本地make然后install没有太多问题，不过由于很多软件开发者设置的路径问题会导致软件无法使用，</p>
<p>本文以ProxyChains为例进行整个过程，ProxyChains是一个全局代理工具，可以在需要的命令前加上<code>proxychains4</code>使得该命令按照设置通过代理访问。</p>
<p><strong>注意这个工具只能代理TCP，像<code>ping</code>命令这样的ICMP协议是不会被代理的！</strong></p>
<h1 id="安装">安装</h1>
<p>如果是有sudo权限直接用包管理器下载即可，Ubuntu上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo apt install proxychains4<br></code></pre></td></tr></table></figure>
<p>没有权限的需要从源码构建</p>
<p>ProxyChains的<a href="https://github.com/haad/proxychains">仓库</a>可以下载到源码，然后<code>cd</code>进入该目录</p>
<p>使用编辑器打开<code>src/main.c</code>文件，修改图中的内容：</p>
<figure>
<img src="/2023/04/18/zai-linux-shang-shi-yong-proxychains-wu-root-quan-xian/修改.png" alt="需要修改的部分">
<figcaption aria-hidden="true">需要修改的部分</figcaption>
</figure>
<p>这里代码指定的是程序运行时从哪里读取lib文件，当我们make
install完后，这个lib文件<code>libproxychains4.so</code>是在本项目源文件夹下的，</p>
<p>所以需要我们手动将需要放置lib文件的路径添加到这个字符串，我这里选择统一管理lib文件的路径，<strong>所以在这个字典里加上`/home/gxz/.local/lib'
</strong>，你要根据自己选择是否修改。</p>
<p>下面指定配置目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># --prefix是用来添加前缀的，表示从当前目录开始make的结果路径会加上这个前缀</span><br>./configue --prefix=build<br><br>make<br><br><span class="hljs-comment"># 注意这里的DESTDIR路径一定要从根目录开始写，install的结果会放在DESTDIR加上上面配置的prefix的文件夹中，当然也可以安装在其他位置统一管理</span><br>make install DESTDIR=<span class="hljs-string">&#x27;/home/gxz/dev/proxychains&#x27;</span><br></code></pre></td></tr></table></figure>
<p>没有报错就代表安装好了，可以找到<code>.so</code>文件，将它拷贝或者移动到刚才在c文件添加的目录下：</p>
<figure>
<img src="/2023/04/18/zai-linux-shang-shi-yong-proxychains-wu-root-quan-xian/make结果.png" alt="make结果">
<figcaption aria-hidden="true">make结果</figcaption>
</figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> libproxychains4.so /home/gxz/.local/lib/<br><span class="hljs-comment"># 这里直接mv也可以</span><br></code></pre></td></tr></table></figure>
<p>将ProxyChains添加到环境变量：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">vim ~/.bashrc<br><br><br><span class="hljs-comment">#proxychains</span><br><span class="hljs-built_in">export</span> PROXYCHAINS_HOME=<span class="hljs-variable">$HOME</span>/dev/proxychains<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PROXYCHAINS_HOME</span>/build/bin:<span class="hljs-variable">$PATH</span><br><br><span class="hljs-comment"># 如果你很熟悉dll文件调用，直接在这里将‘~/.local/lib‘路径加入库文件路径很方便。</span><br><span class="hljs-built_in">export</span> LD_LIBRARY_PATH=<span class="hljs-variable">$HOME</span>/.local/lib:<span class="hljs-variable">$LD_LIBRARY_PATH</span><br><br><br><span class="hljs-comment"># 还可以加上别名，毕竟这条命令有点长</span><br><span class="hljs-built_in">alias</span> pc=<span class="hljs-string">&#x27;proxychains4&#x27;</span><br></code></pre></td></tr></table></figure>
<p>到这里，命令行输入<code>pc</code>应该会看到提示你输入后面的命令。</p>
<p>但是我们还没有配置具体的代理地址，根据仓库中的指示，conf文件在这些路径上是会被自动检测到的：</p>
<figure>
<img src="/2023/04/18/zai-linux-shang-shi-yong-proxychains-wu-root-quan-xian/conf.png" alt="conf文件路径">
<figcaption aria-hidden="true">conf文件路径</figcaption>
</figure>
<p>我选择在<code>$(HOME)/.proxychains/proxychains.conf</code>这个路径下存储配置文件。将下面文件粘贴进该文件中。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">strict_chain<br>proxy_dns <br>remote_dns_subnet 224<br>tcp_read_time_out 15000<br>tcp_connect_time_out 8000<br>localnet 127.0.0.0/255.0.0.0<br><span class="hljs-comment"># ProxyList format</span><br><span class="hljs-comment">#       type  host  port [user pass]</span><br><span class="hljs-comment">#       (values separated by &#x27;tab&#x27; or &#x27;blank&#x27;)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#        Examples:</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#            	socks5	192.168.67.78	1080	lamer	secret</span><br><span class="hljs-comment">#		http	192.168.89.3	8080	justu	hidden</span><br><span class="hljs-comment">#	 	socks4	192.168.1.49	1080</span><br><span class="hljs-comment">#	        http	192.168.39.93	8080	</span><br><span class="hljs-comment">#		</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#       proxy types: http, socks4, socks5, raw</span><br><span class="hljs-comment">#        * raw: The traffic is simply forwarded to the proxy without modification.</span><br><span class="hljs-comment">#        ( auth types supported: &quot;basic&quot;-http  &quot;user/pass&quot;-socks )</span><br><span class="hljs-comment">#</span><br><br>[ProxyList]<br><span class="hljs-comment"># add proxy here ...</span><br><span class="hljs-comment"># meanwile</span><br><span class="hljs-comment"># defaults set to &quot;tor&quot;</span><br>socks5 10.56.0.237 1001 <br></code></pre></td></tr></table></figure>
<p>最终需要修改的代理内容就在最后修改即可，支持http/https/socks5等多种代理。</p>
<h1 id="使用">使用</h1>
<p>使用很简单，在需要的命令前加上<code>proxychains4</code>使得该命令按照设置通过代理访问。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">proxychains4 git <span class="hljs-built_in">clone</span> https://github.com/xcmyz/FastSpeech.git<br><br><span class="hljs-comment"># 配置别名后</span><br>pc git <span class="hljs-built_in">clone</span> https://github.com/xcmyz/FastSpeech.git<br></code></pre></td></tr></table></figure>
<figure>
<img src="/2023/04/18/zai-linux-shang-shi-yong-proxychains-wu-root-quan-xian/result.png" alt="结果">
<figcaption aria-hidden="true">结果</figcaption>
</figure>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>代理</tag>
        <tag>proxy</tag>
        <tag>tool</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>微调Bert模型完成文本分类feat.fastNLP</title>
    <url>/2023/03/31/wei-diao-bert-mo-xing-wan-cheng-wen-ben-fen-lei-feat-fastnlp/</url>
    <content><![CDATA[<h1 id="fine-tuned-bert-for-textclassification">Fine-tuned Bert for
TextClassification</h1>
<h2 id="前言">前言</h2>
<p>文本分类也是NLP领域的传统任务，在Bert模型的加持下可以轻松达到较高的准确率，相比之前的NER任务从数据到模型上都要简单。</p>
<p>如果直接手写训练函数，可以在模型上调用huggingface的<code>BertForSequenceClassification</code>类，它是在<code>BertModel</code>的后面接上dropout和一层分类头，直接输出loss和logits，其他输出详情在huggingface<a href="https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">官方文档</a>。这里使用fastNLP框架，减去了手写训练函数和验证函数的步骤，就需要将模型单独实现，思路和前面一样，但需要变换下BertModel的输出。</p>
<h2 id="外卖数据预处理">外卖数据预处理</h2>
<p>这次的数据集使用的是外卖平台的评论数据集，两个类别表示正向评论和负向评论，数据集按照
<strong>训练:验证:测试=7:1.5:1.5</strong>切分，总数据量约11800条。</p>
<p>需要用到tokenizer，所以在一开始就导入Bert模型加载BertTokenizer，BertModel。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span>  fastNLP.transformers.torch <span class="hljs-keyword">import</span> BertTokenizer<br><span class="hljs-keyword">from</span> fastNLP.transformers.torch <span class="hljs-keyword">import</span> BertModel<br><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&#x27;hfl/rbt3&#x27;</span>)<br>bert_model = BertModel.from_pretrained(<span class="hljs-string">&#x27;hfl/rbt3&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>预处理比较简单，数据集经过清洗，直接交给tokenizer做下encode，得到<code>input_ids</code>。</p>
<figure>
<img src="/2023/03/31/wei-diao-bert-mo-xing-wan-cheng-wen-ben-fen-lei-feat-fastnlp/dataset.png" alt="数据集">
<figcaption aria-hidden="true">数据集</figcaption>
</figure>
<p>然后放进databundle，指定vocab（其实只有两个类，也可以不用做vocab），放入dataloader做下padding，这是fastNLP的数据处理定番了，比之前NER的还是简单了不少。</p>
<h2 id="模型搭建">模型搭建</h2>
<p>这里搭建的模型跟前言提到的一样，就是在Bert的输出后加上全连接做分类头。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BertClassifier</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,bert_model,num_class</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.bert = bert_model<br>        self.mlp = nn.Sequential(nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size),<br>                                nn.Dropout(<span class="hljs-number">0.5</span>),<br>                                nn.Linear(self.bert.config.hidden_size, num_class))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids</span>):<br>      	<span class="hljs-comment"># 冻结bert参数</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            outputs = self.bert(input_ids=input_ids)<br>        last_hidden_state = outputs.last_hidden_state <span class="hljs-comment"># last_hidden_state的shape为[batch,seq_len,num_class]</span><br>        last_hidden_state = last_hidden_state[:, <span class="hljs-number">1</span>:-<span class="hljs-number">1</span>]  <span class="hljs-comment"># 删除 cls 和 sep</span><br><br>        last_hidden_state = last_hidden_state.mean(dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># 第一种写法：这里去掉中间一维，不需要seq_len，在seq_len维度求均值，数据进入num_class</span><br>        <span class="hljs-comment"># last_hidden_state = outputs.pooler_output # 第二种写法：pooler_output也是outputs中的输出</span><br>        pred = self.mlp(last_hidden_state)<br><br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;pred&#x27;</span>: pred&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_step</span>(<span class="hljs-params">self, input_ids, target</span>):<br>        pred = self(input_ids)[<span class="hljs-string">&#x27;pred&#x27;</span>]<br>        loss = F.cross_entropy(pred, target) <span class="hljs-comment"># 损失函数在这里</span><br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_step</span>(<span class="hljs-params">self, input_ids</span>):<br>        pred = self(input_ids)[<span class="hljs-string">&#x27;pred&#x27;</span>].argmax(dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;pred&#x27;</span>: pred&#125;<br><br>model = BertClassifier(bert_model, <span class="hljs-built_in">len</span>(data_bundle.get_vocab(<span class="hljs-string">&#x27;label&#x27;</span>)))<br><br></code></pre></td></tr></table></figure>
<h2 id="模型训练">模型训练</h2>
<p>和NER文章中的一样，使用fastNLP框架训练很简单，只需要准备好数据的格式和列名。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> Trainer, LoadBestModelCallback, TorchWarmupCallback<br><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> Accuracy<br><br>optimizer = optim.AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br>callbacks = [<br>    LoadBestModelCallback(),<br>    TorchWarmupCallback(),<br>]<br>metrics = &#123;<br>    <span class="hljs-string">&quot;acc&quot;</span>: Accuracy(),<br>&#125;<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">input_mapping</span>(<span class="hljs-params">data</span>):<br>    data[<span class="hljs-string">&#x27;target&#x27;</span>] = data[<span class="hljs-string">&#x27;label&#x27;</span>]<br>    <span class="hljs-keyword">return</span> data<br><br>trainer = Trainer(model=model, train_dataloader=dataloaders[<span class="hljs-string">&#x27;train&#x27;</span>], optimizers=optimizer,<br>                  evaluate_dataloaders=dataloaders[<span class="hljs-string">&#x27;dev&#x27;</span>],<br>                  metrics=metrics, n_epochs=<span class="hljs-number">50</span>, callbacks=callbacks,<br>                  monitor=<span class="hljs-string">&#x27;acc#acc&#x27;</span>,device=<span class="hljs-string">&#x27;cuda&#x27;</span>,driver=<span class="hljs-string">&quot;torch&quot;</span>,input_mapping=input_mapping)<br>trainer.run()<br></code></pre></td></tr></table></figure>
<p>这里metric中指定的是<code>Accuracy</code>，对分类任务求准确率，需要输入列名为target和pred的数据，所以多了一个<code>input_mapping</code>函数做预处理，也可以提前在dataset或者dataloader时做好处理。</p>
<blockquote>
<p>fastNLP在evaluate过程中可以直接输入形如<code>[batch,]</code>的label数据，所以前期不用手动将label转为one-hot向量，这一点方便了很多。</p>
</blockquote>
<p>训练结束后由于<code>LoadBestModelCallback</code>会自动加载最佳模型到model中。</p>
<figure>
<img src="/2023/03/31/wei-diao-bert-mo-xing-wan-cheng-wen-ben-fen-lei-feat-fastnlp/训练完成.png" alt="训练完成">
<figcaption aria-hidden="true">训练完成</figcaption>
</figure>
<p>最后得到在验证集上的准确率0.836485</p>
<h2 id="模型测试">模型测试</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastNLP <span class="hljs-keyword">import</span> Evaluator<br><br>evaluator = Evaluator(model=model, dataloaders=dataloaders[<span class="hljs-string">&quot;test&quot;</span>],metrics=metrics,callbacks=callbacks,<br>                      device=<span class="hljs-number">0</span>, input_mapping=input_mapping,evaluate_batch_step_fn=<span class="hljs-literal">None</span>)<br>evaluator.run(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>输出测试集上准确率：这个模型结果为0.8125</p>
<h2 id="tnews数据集测试">TNEWS'数据集测试</h2>
<p>最后用<a href="https://github.com/CLUEbenchmark/CLUE">CLUE</a>上的基准数据集做下测试，使用今日头条新闻数据集TNEWS'。共有15个类，表示新闻的不同类别，训练集53k，验证集10k大小。数据格式如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;label&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;102&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;label_desc&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;news_entertainment&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;sentence&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;江疏影甜甜圈自拍，迷之角度竟这么好看，美吸引一切事物&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;keywords&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;江疏影,美少女,经纪人,甜甜圈&quot;</span><span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;label&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;110&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;label_desc&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;news_military&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;sentence&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;以色列大规模空袭开始！伊朗多个军事目标遭遇打击，誓言对等反击&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;keywords&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;伊朗,圣城军,叙利亚,以色列国防军,以色列&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>
<p>验证集上最终准确率为0.5112，相比二分类难度确实更大。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Bert</tag>
        <tag>NLP</tag>
        <tag>文本分类</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习数学基础①线性代数</title>
    <url>/2022/07/24/ji-qi-xue-xi-shu-xue-ji-chu-xian-xing-dai-shu/</url>
    <content><![CDATA[<h1 id="机器学习数学基础①线性代数">机器学习数学基础①线性代数</h1>
<p>线性代数的核心问题是将一个向量空间的子空间映射到另一个向量空间的子空间,
这个过程使用过的方法叫<strong>线性变换</strong>,
而<strong>矩阵</strong>就是两个向量空间之间线性变换的表达形式</p>
<h2 id="基础概念">基础概念</h2>
<ul>
<li><p>矩阵</p></li>
<li><p>向量</p></li>
<li><p>矩阵乘法: 点积</p></li>
<li><p>矩阵转置</p></li>
<li><p>逆矩阵: 两个方阵相乘结果为单位阵, 记为<span class="math inline">\(A^{-1}\)</span>,称<span class="math inline">\(A\)</span>为可逆矩阵</p></li>
<li><p>正交: 向量<span class="math inline">\(x\)</span>与<span class="math inline">\(y\)</span>正交, 则<span class="math inline">\(x
\cdot y=0\)</span>, 意味着垂直</p></li>
<li><p>正交矩阵: 对于方阵<span class="math inline">\(A \in \mathbb{R}^{n
\times n}\)</span>, 若有<span class="math inline">\(AA^T=I_n=A^TA\)</span>, 其中<span class="math inline">\(A^{-1}=A^T\)</span>, 意味着其转置等于其逆的矩阵,
即<strong>正交矩阵</strong></p></li>
<li><p>对角矩阵</p></li>
<li><p>正定矩阵: 有<span class="math inline">\(n\times
n\)</span>实对称矩阵<span class="math inline">\(A\)</span>和n维非零向量<span class="math inline">\(x\)</span>, 如果<span class="math inline">\(x^TAx&gt;0\)</span>则称<span class="math inline">\(A\)</span>为<strong>正定矩阵</strong>, 如果<span class="math inline">\(x^TAx\geqslant 0\)</span>则称<span class="math inline">\(A\)</span>为<strong>半正定矩阵</strong>.</p>
<blockquote>
<p>正定矩阵<span class="math inline">\(A\)</span>保证变换后的向量<span class="math inline">\(Ax\)</span>与原向量<span class="math inline">\(x\)</span>都位于超平面的同一侧.</p>
</blockquote></li>
</ul>
<h2 id="重要概念">重要概念</h2>
<h3 id="范数">范数</h3>
<p>向量的范数就是向量的长度或大小, 通项公式为<span class="math inline">\(||\vec
x||=(\Sigma_{i=1}^{n}|x^i|^p)^{1/p}\)</span></p>
<p><em>在ML中常用来限制模型复杂度, 防止过拟合等</em></p>
<p>其中p为范数的阶, ML中常用两个:</p>
<ul>
<li>p=1,称为一阶范数<span class="math inline">\(l_1\)</span>范数
L1正则化, <span class="math inline">\(||\vec
x||=\Sigma_{i=1}^{n}|x^i|\)</span>, 表示向量<span class="math inline">\(x\)</span>中的各元素绝对值的和</li>
<li>p=2, 称为二阶范数<span class="math inline">\(l_2\)</span>范数
L2正则化,<span class="math inline">\(||\vec x||=\sqrt{
\Sigma_{i=1}^{n}|x^i|^2}\)</span>, 表示向量中的元素平方和再开平方</li>
</ul>
<h3 id="柯西不等式">柯西不等式</h3>
<p>由余弦定理<span class="math inline">\(\vec a \cdot \vec b=|\vec
a||\vec b|\cos \theta\)</span>得: <span class="math display">\[
|\vec a \cdot \vec b|\leqslant |\vec a||\vec b|
\]</span></p>
<h2 id="矩阵运算常用技巧">矩阵运算常用技巧</h2>
<ol type="1">
<li><p>若<span class="math inline">\(A\)</span>和<span class="math inline">\(B\)</span>是n阶方阵, 且<span class="math inline">\(A+B\)</span>可逆, 有: <span class="math display">\[
A(A+B)^{-1}B=B(A+B)^{-1}A
\]</span></p></li>
<li><p><strong>矩阵指数</strong> <span class="math inline">\(A\)</span>和<span class="math inline">\(B\)</span>是n阶方阵, 有:</p>
<ul>
<li><p><span class="math display">\[
  e^{A^{T}}=(e^A)^T
  \]</span></p></li>
<li><p>若<span class="math inline">\(AB=BA\)</span>, 则</p></li>
</ul>
<p><span class="math display">\[
e^Ae^B = e^Be^A = e^{A+B}
\]</span></p></li>
</ol>
<h2 id="张量和张量积">张量和张量积</h2>
<p><strong>张量</strong>是在ML中常用的概念,
可理解为存在[标量,向量,矩阵...]等形式的一种数据结构 张量积(tensor
product)又称克罗内克积(Kronecker product)</p>
<h3 id="定义">定义</h3>
<p><span class="math inline">\(A=(a_{ij})_{m\times n}\)</span> , <span class="math inline">\(B\)</span> 为<span class="math inline">\(p\times
q\)</span>矩阵, 张量积<span class="math inline">\(A\otimes
B\)</span>是一个<span class="math inline">\(mp\times nq\)</span>矩阵: $$
AB =</p>
<p>$$</p>
<h2 id="特征分解">特征分解</h2>
<p>是指将矩阵分为一组特征向量和特征值</p>
<h3 id="特征向量和特征值">特征向量和特征值</h3>
<p>一个可对角化的矩阵<span class="math inline">\(A\)</span>的<strong>特征向量</strong><span class="math inline">\(v\)</span> 有: <span class="math display">\[
Av= \lambda v
\]</span></p>
<blockquote>
<p>一个方阵与特征向量相乘 相当于 对特征向量进行缩放.</p>
</blockquote>
<p>标量<span class="math inline">\(\lambda\)</span>就是这个特征向量的<strong>特征值</strong></p>
<h3 id="奇异值分解svd">奇异值分解(SVD)</h3>
<p>由于特征分解要求矩阵<span class="math inline">\(A\)</span>是一个可对角化的矩阵, 要求很高</p>
<p>为将特征分解进行推广, 使用的方法叫"矩阵的奇异值分解", 对于一个<span class="math inline">\(m \times n\)</span>的矩阵<span class="math inline">\(A\)</span>: <span class="math display">\[
A= UDV^T
\]</span> <span class="math inline">\(U\)</span>是<span class="math inline">\(m\times m\)</span>方阵, <span class="math inline">\(D\)</span>是<span class="math inline">\(m\times
n\)</span>矩阵, <span class="math inline">\(V\)</span>是<span class="math inline">\(n\times n\)</span>方阵</p>
<p><span class="math inline">\(UV\)</span>都是正交矩阵, <span class="math inline">\(D\)</span>是对角矩阵, <span class="math inline">\(D\)</span>的对角线上的元素就是矩阵<span class="math inline">\(A\)</span>的<strong>奇异值</strong>,<span class="math inline">\(U\)</span>的列向量被称为<strong>左奇异向量</strong>,
<span class="math inline">\(V\)</span>的列向量被称为<strong>右奇异向量</strong></p>
<h2 id="距离计算">距离计算</h2>
<p>计算两个向量之间的距离, 可以反映之间的相似程度</p>
<p>现有两个n维变量 <span class="math display">\[
A= [x_{11},x_{12},\dots,x_{1n}]\\
B= [x_{21},x_{22},\dots,x_{2n}]
\]</span></p>
<h3 id="曼哈顿距离">1. 曼哈顿距离</h3>
<p>表示向量对应元素的距离和 <span class="math display">\[
d_{12} = \sum \limits _{k=1}^n |x_{1k}-x_{2k}|
\]</span></p>
<h3 id="欧氏距离">2. 欧氏距离</h3>
<p>就是L2范数, 表示对应元素的距离的平方和的开方 <span class="math display">\[
d_{12} = \sqrt{\sum \limits _{k=1}^n (x_{1k}-x_{2k})^2}
\]</span></p>
<h3 id="切比雪夫距离">3. 切比雪夫距离</h3>
<p>也是无穷范数, 表示各元素上距离中的最大值 <span class="math display">\[
d_{12} = \max (|x_{1k}-x_{2k}|)
\]</span></p>
<h3 id="余弦距离">4. 余弦距离</h3>
<p>两个方向的夹角余弦取值范围为[-1,1]</p>
<p>夹角余弦越大,表示两个向量夹角越小; 方向重合的两个向量,
余弦值为1;方向相反时, 余弦值为-1 <span class="math display">\[
\begin{aligned}
\cos \theta&amp;= \frac {AB}{|A||B|} \\
&amp;= \frac {\sum \limits _{k=1}^{n}x_{1k}x_{2k}}{\sqrt {\sum \limits
_{k=1}^{n}x_{1k}^2}\sqrt {\sum \limits _{k=1}^{n}x_{2k}^2}}
\end{aligned}
\]</span></p>
<h3 id="汉明距离">5. 汉明距离</h3>
<p>定义两个字符串中的不同位数的数目</p>
<p><span class="math inline">\(e.g.\)</span>
字符串<code>1111</code>和<code>1001</code>的汉明距离为2</p>
<h3 id="杰卡德相似系数">6. 杰卡德相似系数</h3>
<p>两个集合AB的交集元素在并集中的比例 <span class="math display">\[
J(A,B) = \frac {|A\cap B|}{|A\cup B|}
\]</span></p>
<h3 id="杰卡德距离">7. 杰卡德距离</h3>
<p>与杰卡德相似系数表示的内容相反 <span class="math display">\[
J_{\sigma}=1 - J(A,B) = 1- \frac {|A\cap B|}{|A\cup B|}
\]</span></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>ML</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习数学基础②概率论和信息论</title>
    <url>/2022/07/26/ji-qi-xue-xi-shu-xue-ji-chu-gai-lu-lun-he-xin-xi-lun/</url>
    <content><![CDATA[<h1 id="机器学习数学基础②概率论与信息论">机器学习数学基础②概率论与信息论</h1>
<h1 id="基础概念">基础概念</h1>
<ul>
<li><p>随机变量:可以是连续的也可以是离散的</p></li>
<li><p>概率分布:符合随机变量取值范围的某个对象属于某个类别或服从某种趋势的可能性</p></li>
<li><p>联合概率分布:<span class="math inline">\(P(\mathrm x =x,\mathrm
y=y)\)</span>表示x=<span class="math inline">\(x\)</span>和y=<span class="math inline">\(y\)</span>同时发生的概率,简写为<span class="math inline">\(P(x,y)\)</span></p></li>
<li><p>概率函数和似然函数</p>
<ul>
<li><p>Note:区别</p>
<p>对于一个函数<span class="math inline">\(P(x|\theta)\)</span>,其中x表示一个具体的数据,<span class="math inline">\(\theta\)</span>表示模型的参数.</p>
<p>如果<span class="math inline">\(\theta\)</span>已知,x为变量,这个函数就是<strong>概率函数</strong>.表示对于不同的样本点x,其出现的概率是多少.</p>
<p>如果x已知,<span class="math inline">\(\theta\)</span>为变量,这个函数就是<strong>似然函数</strong>.表示对于不同的参数,出现x样本点的概率是多少.</p></li>
</ul></li>
<li><p>期望:<span class="math inline">\(E(X)=\sum \limits
_{k=1}^{n}x_kP(x_k), E(x)=\int xf(x)dx\)</span></p></li>
<li><p>方差:各个样本数据分别与平均数之差的平方和的平均数<span class="math inline">\(Var(x)\)</span></p></li>
<li><p>协方差:衡量随机变量X和Y之间的总体误差<span class="math inline">\(Cov(X,Y)\)</span></p></li>
</ul>
<h1 id="重要概念">重要概念</h1>
<ul>
<li><strong>条件概率</strong>:对于给定<span class="math inline">\(X=x\)</span>时发生<span class="math inline">\(Y=y\)</span>的概率记为<span class="math inline">\(P(Y=y|X=x)\)</span>,计算公式为<span class="math inline">\(P(Y=y|X=x)=\frac {P(x,y)}{P(X=x)}\)</span></li>
<li><strong>先验概率和后验概率</strong></li>
<li><strong>贝叶斯公式</strong>:利用先验概率计算后验概率
<ul>
<li><p>Note:贝叶斯公式推导</p>
<p><span class="math display">\[
  P(B|A)=\frac {P(AB)}{P(A)}, P(A|B)=\frac {P(AB)}{P(B)}
  \]</span></p>
<p><span class="math display">\[
  P(AB)=P(B|A)P(A)=P(A|B)P(B)
  \]</span></p>
<p><span class="math display">\[
  P(B|A)=\frac {P(B|A)P(B)}{P(A)}
  \]</span></p>
<p>全概率公式求<span class="math inline">\(P(A)\)</span></p>
<p><span class="math display">\[
  P(A)=\sum \limits _{i=1}^{N}P(A|B_i)P(B_i)
  \]</span></p>
<p>代入得到贝叶斯公式:</p>
<p><span class="math display">\[
  P(B_i|A)=\frac {P(A|B_i)P(B_i)}{\sum \limits _{i=1}^{N}P(A|B_i)P(B_i)}
  \]</span></p></li>
</ul></li>
<li><strong>最大似然估计(MLE):</strong>在”模型已定,参数<span class="math inline">\(\theta\)</span>未知”的情况下,通过观测数据来估计未知参数<span class="math inline">\(\theta\)</span>的一种方法,要求所有采样都是独立同分布.
<ul>
<li>Note:最大似然估计的使用
<ol type="1">
<li>写出似然函数</li>
<li>对似然函数取对数</li>
<li>两边同时求导(多个变量就求偏导)</li>
<li>令导数为0,解出似然方程</li>
</ol>
<ul>
<li><p>例子</p>
<figure>
<img src="https://s2.loli.net/2022/07/26/yXuBHYVrIP5LpNZ.png" alt="例题">
<figcaption aria-hidden="true">例题</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2022/07/26/LFjf2RnIMZbyuOo.png" alt="例题解答">
<figcaption aria-hidden="true">例题解答</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul>
<h1 id="常见分布函数">常见分布函数</h1>
<ol type="1">
<li><p>0-1分布</p>
<p><span class="math display">\[
P(X=1)=p \\ P(X=0)=1-p
\]</span></p></li>
<li><p>几何分布</p>
<p>离散型概率分布.在n次伯努利试验中,前k-1次失败,第k次成功的概率,其概率分布函数为:<span class="math inline">\(P(X=k)=(1-p)^{k-1}p\)</span></p>
<p><span class="math display">\[
E(X)=\frac {1}{p} \\ Var(X)=\frac {1-p}{p^2}
\]</span></p></li>
<li><p>二项分布</p>
<p>n次伯努利试验中,每次试验只有两种可能结果,并且两种结果相互独立.在n次重复独立试验中事件发生k次的概率为:<span class="math inline">\(P(X=k)=C_n^kp^k(1-p)^{n-k}\)</span> <span class="math display">\[
E(X)=np \\ Var(X)=np(1-p)
\]</span></p></li>
<li><p>高斯分布/正态分布</p>
<p>ML中最常用的概率分布.其中 <span class="math inline">\(\mu\)</span>决定分布中心的位置,<span class="math inline">\(\sigma\)</span> 标准差决定正态分布的幅度.</p>
<figure>
<img src="https://s2.loli.net/2022/07/26/EXJlHW7oDNhqCbI.png" alt="正态分布例图">
<figcaption aria-hidden="true">正态分布例图</figcaption>
</figure>
<p><span class="math display">\[
X \sim N(\mu,\sigma^2)
\]</span></p></li>
<li><p>指数分布</p>
<p>指数分布是一种连续概率分布,可以用来表示独立随机事件发生的时间间隔.其中<span class="math inline">\(\lambda
&gt;0\)</span>表示每单位时间内发生事件的次数.</p>
<figure>
<img src="https://s2.loli.net/2022/07/26/afSYlZeE3C8jOKy.png" alt="指数分布例图">
<figcaption aria-hidden="true">指数分布例图</figcaption>
</figure>
<p><span class="math display">\[
X\sim Exp(\lambda)
\]</span></p>
<p>概率密度函数为:</p>
<p><span class="math display">\[
f(x;\lambda)=
\left\{
\begin{aligned}
&amp;\lambda e^{-\lambda x} &amp;x\geq0 \\
&amp;0&amp;x&lt;0
\end{aligned}
\right.
\]</span></p>
<p>特点为无记忆性,在任意时间段内某个事件发生的概率相同,结合期望理解.期望为:<span class="math inline">\(E(x)=\frac {1}{\lambda}\)</span>.</p></li>
<li><p>泊松分布</p>
<p>泊松分布是一种常见的离散概率分布.适合描述单位时间内随机事件发生的次数的概率分布.参数<span class="math inline">\(\lambda\)</span>是随机事件发生次数的数学期望.</p>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/650px-Poisson_pmf.svg.png" alt="泊松分布例图">
<figcaption aria-hidden="true">泊松分布例图</figcaption>
</figure>
<p>概率密度函数为:</p>
<p><span class="math display">\[
P(X=k)=\frac {e^{-\lambda}\lambda^k}{k!}
\]</span></p>
<p>泊松分布表示为:</p>
<p><span class="math display">\[
X \sim Pois(\lambda)
\]</span></p>
<p>性质有</p>
<ol type="1">
<li><p>期望与方差相等,都等于参数<span class="math inline">\(\lambda\)</span></p></li>
<li><p>两个独立且服从泊松分布的随机变量,其和仍然服从泊松分布</p>
<p><span class="math display">\[
X \sim Poisson(\lambda_1),Y \sim Possion(\lambda_2)\\
X+Y \sim Poisson(\lambda_1+\lambda_2)
\]</span></p></li>
</ol></li>
</ol>
<h1 id="信息论">信息论</h1>
<p><strong>自信息:</strong></p>
<p>一个事件x=<span class="math inline">\(x\)</span>的自信息为<span class="math inline">\(I(x)=-\log P(x)\)</span></p>
<p><strong>香农熵:</strong></p>
<p>一个分布P(x)的事件产生的信息总量的期望</p>
<p><span class="math display">\[
H(x)=\mathbb{E}_{X\sim P}[I(x)]=-\mathbb{E}_{X\sim P}[\log P(x)]
\]</span></p>
<p><strong>KL散度(KL divergence):</strong></p>
<p>衡量两个单独的概率分布P(x)和Q(x)的差异.KL散度非负,为0时表示分布相同.</p>
<p><span class="math display">\[
D_{KL}(P||Q)=\mathbb{E}_{X\sim P}\left[ \log \frac {P(x)}{Q(x)}
\right]=\mathbb{E}_{X\sim P}[\log P(x)- \log Q(x)]
\]</span></p>
<aside>
💡 KL散度中的P分布和Q分布不能交换顺序
</aside>
<p><strong>交叉熵(cross-entropy):</strong></p>
<p><span class="math display">\[
H(P,Q)=H(P)+D_{KL}(P||Q)=-\mathbb{E}_{X\sim P}\log Q(x)
\]</span></p>
<aside>
💡 在信息论中0log0结果取0
</aside>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习数学基础③数值计算和最优化理论</title>
    <url>/2022/07/30/ji-qi-xue-xi-shu-xue-ji-chu-shu-zhi-ji-suan-he-zui-you-hua-li-lun/</url>
    <content><![CDATA[<h1 id="数值计算">数值计算</h1>
<h2 id="上溢和下溢">上溢和下溢</h2>
<p>在数字计算机中我们需要通过有限的位数表示无限多的实数,这意味着会引入误差.</p>
<ul>
<li><strong>下溢(underflow):</strong>当接近零的数被四舍五入为零时发生下溢。许多函数会在其参数为零而不是一个很小的正数时才会表现出质的不同。例如，我们通常要避免被零除<strong>。</strong></li>
<li><strong>上溢(overflow):</strong>当大量级的数被近似为<span class="math inline">\(\infin\)</span>或<span class="math inline">\(-\infin\)</span>时发生上溢。进一步的运算通常将这些无限值变为非数字。</li>
</ul>
<p>避免数值上溢或者下溢的方法常用softmax函数.</p>
<figure>
<img src="/2022/07/30/ji-qi-xue-xi-shu-xue-ji-chu-shu-zhi-ji-suan-he-zui-you-hua-li-lun/softmax函数.png" alt="softmax函数">
<figcaption aria-hidden="true">softmax函数</figcaption>
</figure>
<p>softmax函数能够将上下接近溢出的数据<em>压缩</em>至0-1的范围内.</p>
<h1 id="最优化">最优化</h1>
<h2 id="最优化理论">最优化理论</h2>
<p><strong>经验风险最小化</strong></p>
<p>用最小的代价取得最大的收益.也就是我们今天常说的算法.</p>
<h2 id="凸集与凸集分离定理">凸集与凸集分离定理</h2>
<h3 id="凸集">1.凸集</h3>
<p>在实数域的向量空间中.如果一个集合中任意两点的连线上的点都在该集合中,则该集合为<strong>凸集</strong>.</p>
<figure>
<img src="https://pic1.zhimg.com/v2-608f89f47688c41e4c3f83cfad095c84_r.jpg" alt="凸集和非凸集">
<figcaption aria-hidden="true">凸集和非凸集</figcaption>
</figure>
<p>数学定义: 一个集合<span class="math inline">\(S\subset
R^T\)</span>,若对于任意两点<span class="math inline">\(x,y \in
S\)</span>,以及实数<span class="math inline">\(\lambda(0\leqslant
\lambda \leqslant 1)\)</span>,都有<span class="math inline">\(\lambda
x+(1-\lambda )y \in S\)</span>,则称集合S为凸集.</p>
<h3 id="超平面和半空间">2.超平面和半空间</h3>
<p>三维空间的<strong>超平面</strong>就是一个面(曲面),二维空间的超平面就是一条线(曲线),推广到n维空间.</p>
<p>超平面的某一个方向的所有样本组成<strong>半空间.</strong></p>
<h3 id="凸集分离定理">3.凸集分离定理</h3>
<p>所谓两个凸集分离，直观地看是指两个凸集合没有交叉和重合的部分，因此可以用一张超平面将两者隔在两边，如下图所示：</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-4116a3bda12faa5e2421ce27efb7fb71_1440w.jpg" alt="凸集分离">
<figcaption aria-hidden="true">凸集分离</figcaption>
</figure>
<h3 id="凸函数">4.凸函数</h3>
<p>凸函数是一个定义域在某个向量空间的凸子集上的实值函数.</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-f1b39d0aad4388433158679221f813d2_1440w.jpg" alt="凸函数">
<figcaption aria-hidden="true">凸函数</figcaption>
</figure>
<aside>
💡 在图中直线始终在凸函数曲线上方
</aside>
<p>数学定义:对于函数f(x),如果其定义域C是凸集,且对于<span class="math inline">\(\forall x,y \in C, 0\leqslant \alpha \leqslant
1\)</span>,有:</p>
<p><span class="math display">\[
f(\theta x+(1-\theta )y)\leqslant \theta f(x)+(1-\theta )f(y)
\]</span></p>
<p><strong>如果一个函数是凸函数,则其局部最优点就是其全局最优点.</strong></p>
<p>因为在ML中我们就是在求模型的全局最优点,所以一旦证明ML模型中的损失函数为凸函数,相当于我们只需要求它的局部最优点.</p>
<aside>
💡 求解非凸函数的全局最优点也就成了神经网络中的常见难题.
</aside>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>清河村支教回忆</title>
    <url>/2021/09/23/qing-he-cun-zhi-jiao-hui-yi/</url>
    <content><![CDATA[<p><em>成文于2021年8月11日离开清河村。</em><br>
  大包小包的行李，颠颠簸簸的山路，出发前忐忐忑忑的心情在进入清河村后终于有所平复，深山、公路、虫鸣、鸟叫，不仔细观察很难发现这座隐藏在山峦间的完全小学。设施落后、环境糟糕、蚊虫困扰、饮食不同，完全符合一个城市人对农村的印象。农村生活过的我自认为对环境要求不高，到了这里也难免有些烦闷。<br>
<img src="https://i.loli.net/2021/09/24/1mYu6dJgSeHTXDx.jpg" alt="清河村完全小学的清晨"> <img src="https://i.loli.net/2021/09/24/aDiCOMYG7mFnoRQ.jpg" alt="山">
  闲时无事，揣起相机，沿着新修的道路在村里漫步，才发现这里的一切都不是想象中的那样。道路上摩托车和大货车不断，即使急转或陡坡也都轻松通过，山路两旁都是村民种植的茶树，时不时有个斗笠冒出来，采摘着最新鲜的三片茶叶。村中邻里相互十分熟悉，抱着小孩，背着菜筐，在村公所门口摆着龙门阵，爽朗的笑声老远外就能听到。最让我意外的就是脱贫援建建设的网络设施已经成为了村民们最佳的休闲方式，在路边时不时就能听到短视频平台的神曲，想必不少村民也是某些平台的大V。</p>
<p><img src="https://i.loli.net/2021/09/24/idPy38m9OIn6hea.jpg" alt="清河村的晚霞"> <img src="https://i.loli.net/2021/09/24/qpxP5ImXbkTgFwz.jpg" alt="清河村的晚霞"></p>
<p>  这里离天很近，或者说这里就在所谓的“天上”，“天上”小学的学生自然都是“天兵天将”。这次梦想教室教授的对象是四年级的小学生，这天早上8点多我们还在硬板床上做着梦，“天兵天将”已经冲进了大门，在水泥操场上撒欢了。即使很多“天兵天将”穿着相同的“制服”和“盔甲”，明亮的眼神却在黝黑的皮肤中更显耀眼。或许是对未知事物的一丝丝恐惧，每当我用镜头想要捕捉到一张张笑脸时，他们会用远超我按下快门的速度表演一个变脸，迅速板起表情，我也只能悻悻地放下相机。
<img src="https://i.loli.net/2021/09/24/d5Iw9AcqlbP6NyT.jpg" alt="小学">
  对相机有所顾忌的学生们对待知识的态度就完全不同了，即使课上常常提到陌生的概念他们也十分愿意聆听学习，常常是一提问就好多双小手在空中挥舞。上过几天课后逐渐有学生不怕我的镜头了，下课期间几个好事的小男生上来摆弄我脚架上的相机快门，吸引了其他同学的注意，“天兵天将”便纷纷在相机里留下自己的鬼脸。最后一天，小孩子们拿着纸笔一个一个问我们的电话号码，看着一张张期待的小脸，一瞬间我就扭过了头，属实是不能被看见眼红啊。<br>
<img src="https://i.loli.net/2021/09/24/KBYmuUxLbeMypRw.jpg" alt="山路">
  总有人说，不要去支教，即使去教这些大山中的孩子，给他们看了外界的美好，他们也走不出去，或是因为能力，或是因为家庭，支教的故事只是给他们徒增烦恼罢了。对待短期支教，我更想做的是给他们送去新鲜的思想，告诉他们“绿水青山就是金山银山”，告诉他们梦想绝不渺小，梦想永远伟大。<br>
<img src="https://i.loli.net/2021/09/24/hnegQSNylC7tz25.jpg" alt="银河"></p>
<p>  我从不认为自己是一个运气很好的人，但是我为能来到这座深山中的小小村庄倍感荣幸。<br>
<img src="https://i.loli.net/2021/09/24/AT6KXrjhfLvO7Rb.jpg" alt="村里的兔兔"> <img src="https://i.loli.net/2021/09/24/BTdOIXhmJCYlViM.jpg" alt="银河"></p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>支教</tag>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>爱快路由下无法正常解析DNS的问题</title>
    <url>/2022/03/04/ai-kuai-lu-you-xia-wu-fa-zheng-chang-jie-xi-dns-de-wen-ti/</url>
    <content><![CDATA[<blockquote>
<p>最原始的问题是发现300M的电信宽带在经过软路由后下行只有30M,
而上行还保持正常, 在排查中出现了另外的问题: 直连爱快软路由DNS解析失败,
本文解决了这两个问题</p>
</blockquote>
<p>先说结论:</p>
<p>在客户机DNS服务器设置为网关(ikuai)的情况下,
必须设置爱快的DNS加速服务中使用代理模式才能生效,
同时要开启强制客户端DNS代理,
而此时使用爱快的DNS缓存模式无法正常解析DNS</p>
<p><img src="https://s2.loli.net/2022/03/04/nbLDmNeuoryJIFv.png"></p>
<hr>
<p>以下是完整版:</p>
<p>家中稳定运行半年的网络配置如图所示, 出现问题后开始排查问题位置</p>
<p>①查看是否是运营商限制了下行带宽:
测试家中网络硬路由部分的速率发现一切正常, 所以问题出在软路由</p>
<p>②逐个排查软路由内各部分: 依次关闭adg, openwrt没有改善问题,
所以问题可能在ikuai上</p>
<figure>
<img src="https://s2.loli.net/2022/03/04/7X6kQ9LiKyqpxIu.png" alt="家中原始网络拓扑图, 分为经过软路由的改造部分和初始路由器部分">
<figcaption aria-hidden="true">家中原始网络拓扑图,
分为经过软路由的改造部分和初始路由器部分</figcaption>
</figure>
<p>将电脑直连ikuai, 手动设置IP, DNS和网关均为ikuai,
在未做其他修改的情况下出现了无法解析DNS的情况</p>
<figure>
<img src="https://s2.loli.net/2022/03/04/qJOzB1orpgMm54n.png" alt="7X6kQ9LiKyqpxIu">
<figcaption aria-hidden="true">7X6kQ9LiKyqpxIu</figcaption>
</figure>
<blockquote>
<p>qq和微信都是不需要解析DNS的软件,
如果这两个软件能正常使用而网页无法打开就能确定DNS出问题</p>
</blockquote>
<p>先后修改了ikuai和电脑的DNS服务器, 从openwrt内到ikuai再到阿里腾讯,
均不能正常上网</p>
<figure>
<img src="https://s2.loli.net/2022/03/04/brmS398LFOdwzJC.jpg" alt="ikuai内的设置, 无法解析DNS">
<figcaption aria-hidden="true">ikuai内的设置, 无法解析DNS</figcaption>
</figure>
<p>ikuai内的设置, 无法解析DNS</p>
<p>然后怀疑是不是ikuai本身就无法正常上网,
使用ikuai内的测试工具发现能够ping通域名</p>
<p><img src="https://s2.loli.net/2022/03/04/OAGZUVnaegkl3Xi.jpg"></p>
<p>到这里完全没有思路, 之前也没见过路由能解析DNS但主机不能的情况,
在网上和论坛搜索了很久都没有找到相关的情况</p>
<p>最后的最后在ikuai官方的手册里找到了答案</p>
<p><a href="https://www.ikuai8.com/index.php?option=com_content&amp;view=article&amp;id=129:dns&amp;catid=39&amp;Itemid=228">https://www.ikuai8.com/index.php?option=com_content&amp;view=article&amp;id=129:dns&amp;catid=39&amp;Itemid=228</a></p>
<p><img src="https://s2.loli.net/2022/03/04/r9JVAwTgPLbYpqu.jpg"></p>
<p>所以修改了代理模式, 开启了强制代理, 问题解决</p>
<p><img src="https://s2.loli.net/2022/03/04/BHkuZeJ2OarSUNR.jpg"></p>
<blockquote>
<p>回到最初的降速问题,
经历了iperf测速等9981种方法也没有头绪，最后竟然在V2上找到了同样的病友，最后是修改了WiFi的信道和带宽...果然没再出问题，可能是过了个年周围的邻居变多了吧...</p>
</blockquote>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title>生成模型之Flow-based Model(1)前置知识</title>
    <url>/2022/07/08/sheng-cheng-mo-xing-zhi-flow-based-model-1-qian-zhi-zhi-shi/</url>
    <content><![CDATA[<h1 id="flow-based-model前置知识">Flow-based Model前置知识</h1>
<blockquote>
<p>流模型是数学上严密推理得到的模型,本篇为数学上的前置内容</p>
</blockquote>
<h2 id="雅各比矩阵-jacobian-matrix">雅各比矩阵 Jacobian Matrix</h2>
<p>对于两个矩阵<span class="math inline">\(x\)</span>和<span class="math inline">\(z\)</span><br>
<span class="math display">\[z =
\left[\begin{matrix}z_{1}\\z_{2}\end{matrix}\right]\]</span> <span class="math display">\[x =
\left[\begin{matrix}x_{1}\\x_{2}\end{matrix}\right]\]</span></p>
<p><span class="math inline">\(x\)</span>和<span class="math inline">\(z\)</span>之间存在关系:<br>
<span class="math inline">\(x = f(z)\)</span>, <span class="math inline">\(z = f^{-1}(x)\)</span></p>
<p>Jacobian Matrix定义为:<br>
<span class="math display">\[
J_{f} = \left[ \begin{matrix}
\partial x_{1}/\partial z_{1} &amp;&amp; \partial x_{1}/\partial z_{2}
\\
\partial x_{2}/\partial z_{1} &amp;&amp; \partial x_{2}/\partial z_{2}
\end{matrix} \right]
\]</span></p>
<p><span class="math display">\[
J_{f^{-1}} = \left[ \begin{matrix}
\partial z_{1}/\partial x_{1} &amp;&amp; \partial z_{1}/\partial x_{2}
\\
\partial z_{2}/\partial x_{1} &amp;&amp; \partial z_{2}/\partial x_{2}
\end{matrix} \right]
\]</span></p>
<p><span class="math display">\[
J_{f}J_{f^{-1}}=1
\]</span></p>
<h2 id="行列式-determinant">行列式 Determinant</h2>
<p>对于一个矩阵<span class="math inline">\(A\)</span><br>
<span class="math display">\[
A = \left[ \begin{matrix}a &amp;&amp; b\\c &amp;&amp;
d\end{matrix}\right]
\]</span> 其行列式结果为:<br>
<span class="math display">\[
\det(A) = ad-bc
\]</span></p>
<p>对于一个矩阵<span class="math inline">\(B\)</span><br>
<span class="math display">\[
B = \left[ \begin{matrix}a_{1} &amp;&amp; a_{2} &amp;&amp; a_{3}\\a_{4}
&amp;&amp; a_{5} &amp;&amp; a_{6}\\a_{7} &amp;&amp; a_{8} &amp;&amp;
a_{9}\end{matrix}\right]
\]</span> 其行列式结果为:<br>
<span class="math display">\[
\det(B) =
a_{1}a_{5}a_{9}+a_{2}a_{6}a_{7}+a_{3}a_{4}a_{8}-a_{3}a_{5}a_{7}-a_{2}a_{4}a_{9}-a_{1}a_{6}a_{8}
\]</span></p>
<p>有公式:<br>
<span class="math display">\[
\det (A) = \frac {1}{\det(A^{-1})}
\]</span></p>
<p><span class="math display">\[
\det (J_{f}) = \frac {1}{\det(J_{f^{-1})}}
\]</span></p>
<h2 id="可变理论-change-of-variable-theorem">可变理论 change of variable
theorem</h2>
<p>对于正态分布<span class="math inline">\(\pi(z)\)</span>和概率分布<span class="math inline">\(p(x)\)</span><br>
其中<span class="math inline">\(x\)</span>和<span class="math inline">\(z\)</span>满足<span class="math inline">\(x=f(z)\)</span></p>
<h3 id="一维形式">一维形式</h3>
<p><span class="math display">\[ p(x&#39;)\Delta x = \pi (z&#39;)\Delta
z\]</span> <span class="math display">\[p(x&#39;) = \pi (z&#39;) |\frac
{\mathrm{d} z}{\mathrm{d} x}| \]</span></p>
<h3 id="二维形式">二维形式</h3>
<p><span class="math display">\[p(x&#39;)|det(J_f)|=\pi(z&#39;)\]</span>
<span class="math display">\[p(x&#39;) =
\pi(z&#39;)|det(J_{f^{-1}})|\]</span></p>
<h3 id="引申">引申</h3>
<p>如果<span class="math inline">\(x\)</span>和<span class="math inline">\(z\)</span>满足<span class="math inline">\(x=f(z)\)</span>,则他们的分布之间关系就是相差<span class="math inline">\(|det(J_f)|\)</span></p>
<h2 id="生成器generator">生成器Generator</h2>
<p>对于一个网络<span class="math inline">\(G\)</span>,我们定义他的分布为<span class="math inline">\(P_{G}\)</span>,对于真实样本的分布为<span class="math inline">\(P_{data}\)</span><br>
对于输入<span class="math inline">\(z\)</span>,经过生成器得到的结果为<span class="math inline">\(x\)</span>,记为<span class="math inline">\(x=G(z)\)</span><br>
说明<span class="math inline">\(x\)</span>服从<span class="math inline">\(P_{G}(x)\)</span>分布
显然一个好的生成器应当使得<span class="math inline">\(P_{G}(x)\)</span>接近<span class="math inline">\(P_{data}(x)\)</span></p>
<p>因此理论上有最优生成器<span class="math inline">\(G^{*}\)</span><br>
<span class="math inline">\(G^{*}= argmax_{G}
\sum\limits_{i=1}^{m}logP_{G}(x^{i})\)</span> 其中 <span class="math inline">\({x^i from P_{data}(x)}\)</span></p>
<p><span class="math inline">\(G^{*} \approx argmin_{G}KL(P_{data} ||
P_{G})\)</span><br>
(KL散度越小,两个分布越接近)</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>生成模型之Flow-based-Model(2)</title>
    <url>/2022/07/09/sheng-cheng-mo-xing-zhi-flow-based-model-2-liu-mo-xing-tui-dao/</url>
    <content><![CDATA[<h1 id="生成模型flow-based-model2流模型">生成模型Flow-Based
Model（2）流模型</h1>
<h2 id="推导">推导</h2>
<p>根据生成器相关知识可知：一个最佳的生成器<span class="math inline">\(G^{*}= argmax_{G}
\sum\limits_{i=1}^{m}logP_{G}(x^{i})\)</span></p>
<p>根据可变理论有：<span class="math inline">\(P_G(x^i)=\pi(z^i)|\det(J_{G^{-1}})|\)</span>,
其中<span class="math inline">\(z^i=G^{-1}(x^i)\)</span></p>
<p>等号两侧取对数有: <span class="math inline">\(logP_G(x^i)=log\pi(G^{-1}(x^i))+log|\det(J_{G^{-1}}|\)</span></p>
<p>由此得到最佳生成器<span class="math inline">\(G^*\)</span>的右式,
即让<span class="math inline">\(logP_G(x^i)\)</span>最大,
便得到最佳<span class="math inline">\(G^*\)</span></p>
<p>然而<span class="math inline">\(z^i=G^{-1}(x^i)\)</span>对<span class="math inline">\(G\)</span>提出了限制:</p>
<ol type="1">
<li><span class="math inline">\(\det(J_G)\)</span>需要可计算</li>
<li><span class="math inline">\(G^{-1}\)</span>要求生成器<span class="math inline">\(G\)</span>本身可逆, 输入输出的形状一样</li>
</ol>
<p>解决方法: 使用多个生成器<span class="math inline">\(G\)</span>连续生成, 以达到拟合<span class="math inline">\(P_{data}\)</span>的目的</p>
<h2 id="多个生成器的情况">多个生成器的情况</h2>
<p>对于多个<span class="math inline">\(G\)</span>的生成结果有: <span class="math inline">\(\log(P_K(x^i))=log\pi(z^i)+\sum\limits_{i=1}^Klog|\det(J_{G_{K^{-1}}})|\)</span>,
其中<span class="math inline">\(z^i=G_1^{-1}G_2^{-1}...G_K^{-1}(x^i)\)</span></p>
<blockquote>
<p>依旧是取左式最大</p>
</blockquote>
<h2 id="流模型实质">流模型实质</h2>
<p>以一个生成器为例:</p>
<pre><code class=" mermaid">graph LR
z --&gt; G --&gt; x
</code></pre>
<p><span class="math display">\[
logP_G(x^i)=log\pi(G^{-1}(x^i))+log|\det(J_{G^{-1}})|
\]</span></p>
<p>发现为得到左式中的<span class="math inline">\(G\)</span>,
右式只是用到了<span class="math inline">\(G^{-1}\)</span>,
因此我们直接训练出<span class="math inline">\(G^{-1}\)</span></p>
<pre><code class=" mermaid">graph RL
x --&gt; G-1 --&gt; z
</code></pre>
<p>其中, <span class="math inline">\(x^i\)</span>是从<span class="math inline">\(P_{data}(x)\)</span>中采样的, <span class="math inline">\(z^i=G^{-1}(x^i)\)</span></p>
<p>欲使左式最大, 右侧两项应尽可能大</p>
<ul>
<li>右侧第一项是对数函数, 而正态分布<span class="math inline">\(\pi(z^i)\)</span>在<span class="math inline">\(z^i\)</span>等于0向量时最大,
因此可能导致训练出的<span class="math inline">\(G^{-1}\)</span>使所有生成的<span class="math inline">\(z^i\)</span>都为零向量, 进而导致<span class="math inline">\(J_{G^{-1}}\)</span>变成全零矩阵, 行列式<span class="math inline">\(\det(J_{G^{-1}})\)</span>也为0,
最终右侧第二项变为<span class="math inline">\(-\inf\)</span></li>
</ul>
<p>所以流模型实际上在做的事情就是: 在第一项趋零的情况下,
使用第二项约束结果防止全零, 最终得到最佳生成器</p>
<h2 id="应用-coupling-layer">应用-Coupling Layer</h2>
<figure>
<img src="https://s2.loli.net/2022/07/10/pqBCRzcYLbiu2Uo.png" alt="coupling-layer">
<figcaption aria-hidden="true">coupling-layer</figcaption>
</figure>
<p>左侧为<span class="math inline">\(z^i\)</span>, 右侧为<span class="math inline">\(x^i\)</span> <span class="math display">\[
\begin{equation}
\left\{
\begin{aligned}
z_{i\leq d}&amp;=x^i\\
z_{i &gt; d}&amp;=\frac {x^i-\gamma^i}{\beta^i}
\end{aligned}
\right.
\end{equation}
\]</span></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>生成模型之VAE</title>
    <url>/2022/08/02/sheng-cheng-mo-xing-zhi-vae/</url>
    <content><![CDATA[<h1 id="生成模型之variational-auto-encoder">生成模型之Variational
Auto-Encoder</h1>
<blockquote>
<p>本篇内容主要参考台大李宏毅教授的视频，作为笔记使用</p>
<p><a href="https://www.youtube.com/watch?v=3oHlf8-J3Nc">【機器學習2021】自編碼器
(Auto-encoder) (上) - 基本概念</a></p>
<p><a href="https://www.youtube.com/watch?v=8zomhgKrsmQ">ML Lecture 18:
Unsupervised Learning - Deep Generative Model (Part II)</a></p>
</blockquote>
<h1 id="auto-encoder自动编码器">Auto-Encoder自动编码器</h1>
<aside>
💡 可以认为是自监督学习的一种方法，不需要标注
</aside>
<h2 id="压缩自动编码器">压缩自动编码器</h2>
<pre><code class=" mermaid">graph LR
	高维图片 --&gt; NN-Encoder --&gt; 低维向量 --&gt; NN-Decoder--&gt; 生成图 --越接近越好--&gt;高维图片
</code></pre>
<h2 id="降噪自动编码器">降噪自动编码器</h2>
<pre><code class=" mermaid">graph LR
	原图.-原图+噪声
	原图+噪声 --&gt; NN-Encoder --&gt; 低维向量 --&gt; NN-Decoder--&gt; 生成图 --与原图越接近越好--&gt;原图
	
</code></pre>
<h2 id="解缠feature-disentangle">解缠（Feature Disentangle）</h2>
<p>输入信息常常由各种信息纠缠在一起，如</p>
<ul>
<li>图片中存在物体、纹理</li>
<li>声音中存在文本内容、说话人信息</li>
<li>一句话包含格式、语法</li>
<li>……</li>
</ul>
<p>这时候需要通过解缠得到不同维度包含的信息</p>
<p>应用：Voice Conversion语者转换</p>
<h1 id="vae变分自动编码器">VAE变分自动编码器</h1>
<h2 id="ae和vae区别">AE和VAE区别</h2>
<p>Auto-encoder</p>
<pre><code class=" mermaid">graph LR
  高维图片 --&gt; NN-Encoder --&gt; 低维向量 --&gt; NN-Decoder--&gt; 生成图
</code></pre>
<p>VAE</p>
<p>是在自动编码器的基础上做变分处理，使编码器的输出为目标分布的均值方差。</p>
<pre><code class=" mermaid">graph LR
  input --&gt; NN-Encoder --&gt; mu
	NN-Encoder --&gt; sigma
	sigma --exp--&gt; times((相乘))
	e --&gt; times
	mu --&gt; plus((相加))
	times --&gt;plus
	plus --&gt; z --&gt;

 NN-Decoder--&gt; output
</code></pre>
<p>其中mu、sigma、e、z均为向量，并且e内元素服从正态分布，<span class="math inline">\(z_i=\exp(\sigma_i)\times e_i + \mu_i\)</span></p>
<p>mu是均值，e是噪声，sigma代表噪声的大小即variance方差，z就是目标概率分布。为避免variance方差被生成为0，即没有噪声，需要加上限制条件。</p>
<p>所以需要最小化如下函数：</p>
<p><span class="math display">\[
\min \sum \limits _{i=1} ^n (\exp(\sigma_i)-(1+\sigma_i)+\mu_i^2)
\]</span></p>
<h2 id="vae推导">VAE推导</h2>
<h3 id="高斯混合模型gmm">高斯混合模型（GMM）</h3>
<blockquote>
<p>部分内容参考</p>
<p><a href="http://www.gwylab.com/note-vae.html">【学习笔记】生成模型--变分自编码器</a></p>
</blockquote>
<p>高斯混合模型是单一高斯概率密度函数的延伸，由于GMM能够平滑的近似任意形状的密度分布，因此常用在语音领域。</p>
<p>GMM的工作就是将复杂的P(x)分布变为多个高斯分布的混合，当拆分的越多时，越接近原始P(x)分布。</p>
<figure>
<img src="https://s2.loli.net/2022/08/02/JBOLqVHPE9yYFmQ.png" alt="高斯混合模型离散变量">
<figcaption aria-hidden="true">高斯混合模型离散变量</figcaption>
</figure>
<p><u>如果用每一组高斯分布的取值作为一个维度，就可以用m表示第几个维度，如果有512维，m的取值就是1,2,3……512</u></p>
<p>从多项式分布P(m)中采样一个整数m，表示一个高斯分布<span class="math inline">\(N(\mu^m,\sigma^m)\)</span>，P(x)可表示为所有这些高斯分布的和：</p>
<p><span class="math display">\[
P(x)=\sum \limits _mP(m)P(x|m)
\]</span></p>
<p>其中，<span class="math inline">\(m\sim P(m)\)</span>，<span class="math inline">\(x|m \sim N(\mu^m,\sigma^m)\)</span></p>
<p>不过这种混合方式是离散的，还存在失真的地方，于是我们将其转化为连续的。</p>
<figure>
<img src="https://s2.loli.net/2022/08/02/zrjWQXFZgGVYfRP.png" alt="高斯混合模型连续变量">
<figcaption aria-hidden="true">高斯混合模型连续变量</figcaption>
</figure>
<p>现在将离散变量m改为连续变量z，依旧是z的某一个取值对应一个高斯分布。</p>
<aside>
💡
与离散的GMM不同点在于，此时我们不能直接得到z所对应的高斯分布的均值和方差，因为z有无数个取值无法穷尽。
</aside>
<p><span class="math inline">\(z\sim N(0,I)\)</span>，<span class="math inline">\(x|z\sim N(\mu(z),\sigma(z))\)</span>，其中<span class="math inline">\(\mu\)</span>是得到z均值的函数，<span class="math inline">\(\sigma\)</span>是得到z方差的函数。</p>
<p>于是P(x)的分布就可以表示为:</p>
<p><span class="math display">\[
P(x)=\int\limits _zP(z)P(x|z)dz
\]</span></p>
<p>所以我们的目标就变成求解上面这个公式。</p>
<h3 id="求解目标公式">求解目标公式</h3>
<p><span class="math display">\[
P(x)=\int\limits _zP(z)P(x|z)dz
\]</span></p>
<p>其中<span class="math inline">\(P(z)\)</span>已知，<span class="math inline">\(P(x|z)\)</span>未知，<span class="math inline">\(P(x|z)\)</span>中<span class="math inline">\(x|z\sim
N(\mu(z),\sigma(z))\)</span>，所以求<strong>解<span class="math inline">\(P(x|z)\)</span>转换为求解<span class="math inline">\(\mu,\sigma\)</span>两个函数的表达式</strong>。</p>
<p><strong>如何求解<span class="math inline">\(\mu,\sigma\)</span>函数?使用神经网络!</strong></p>
<pre><code class=" mermaid">graph LR
	z --&gt; NN-Decoder --&gt; mu
	NN-Decoder --&gt; sigma
</code></pre>
<p>同时我们再加上一个<strong>新的函数<span class="math inline">\(q(z|x)\)</span></strong>用来表示任意高斯分布，其中<span class="math inline">\(z|x \sim
N(\mu&#39;(x),\sigma&#39;(x))\)</span>，表示对于一个输入的x，能够得到一对均值和方差，用于生成z的概率分布。</p>
<pre><code class=" mermaid">graph LR
  x --&gt; NN-Encoder --&gt; mu&#x27;
	NN-Encoder --&gt; sigma&#x27;
</code></pre>
<p>因为实际上我们有数据x，现在是在求解参数，所以需要求<span class="math inline">\(P(x)\)</span>的最大似然函数<span class="math inline">\(L=\sum \limits _x \log P(x)\)</span></p>
<ul>
<li><strong>最大似然估计(MLE):</strong>在”模型已定,参数<span class="math inline">\(\theta\)</span>未知”的情况下,通过观测数据来估计未知参数<span class="math inline">\(\theta\)</span>的一种方法,要求所有采样都是独立同分布.
<ul>
<li>Note:最大似然估计的使用
<ol type="1">
<li>写出似然函数</li>
<li>对似然函数取对数</li>
<li>两边同时求导(多个变量就求偏导)</li>
<li>令导数为0,解出似然方程</li>
</ol>
<ul>
<li><p>例子</p>
<figure>
<img src="/2022/08/02/sheng-cheng-mo-xing-zhi-vae/Untitled.png" alt="最大似然函数例题">
<figcaption aria-hidden="true">最大似然函数例题</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2022/08/02/X48H3Blukqw15Op.png" alt="例题解答">
<figcaption aria-hidden="true">例题解答</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul>
<p>由于<span class="math inline">\(q(z|x)\)</span>是一个任意的高斯分布，于是有<span class="math inline">\(\int \limits _z
q(z|x)dz=1\)</span>，表示整个高斯分布的面积为1。</p>
<p><span class="math display">\[
\begin{aligned}
\log P(x) &amp;=\int \limits _zq(z|x)\log P(x)dz \\ &amp;=\int \limits
_zq(z|x)\log \big(\frac{P(x|z)P(z)}{P(z|x)}\big)dz \\
&amp;=\int \limits _zq(z|x)\log
(\frac{P(x|z)P(z)}{q(z|x)}\cdot\frac{q(z|x)}{p(z|x)})dz \\
&amp;= \int \limits _zq(z|x)\log(\frac{P(x|z)P(z)}{q(z|x)})dz + \int
\limits _zq(z|x)\log(\frac{q(z|x)}{P(z|x)})dz \\
&amp;= \int \limits _zq(z|x)\log(\frac{P(x|z)P(z)}{q(z|x)})dz
+KL(q(z|x)||P(z|x))
\end{aligned}
\]</span></p>
<p>最后得到两项，第二项KL散度非负，所以第一项就是结果的下界<span class="math inline">\(L_b\)</span></p>
<p><span class="math display">\[
\log P(x) \geqslant \int \limits _z
q(z|x)\log(\frac{P(x|z)P(z)}{q(z|x)})dz
\]</span></p>
<p><span class="math display">\[
\log P(x) = L_b+KL(q(z|x)||P(z|x))
\]</span></p>
<p>这里将原本的问题：求<span class="math inline">\(P(x|z)\)</span>使得<span class="math inline">\(\log P(x)\)</span>最大化</p>
<p>转换为了<strong>新的问题</strong>：<strong>求P(x|z)和q(z|x)使得<span class="math inline">\(\log P(x)\)</span>最大化</strong></p>
<p>看起来像是多了一个<span class="math inline">\(q(z|x)\)</span>，其实不然，我们开始观察<span class="math inline">\(\log P(x)\)</span>跟这两项的关系：</p>
<figure>
<img src="https://s2.loli.net/2022/08/02/CZJpxOlEad8nNh3.jpg" alt="logP(x)和新问题的关系">
<figcaption aria-hidden="true">logP(x)和新问题的关系</figcaption>
</figure>
<p>根据<span class="math inline">\(P(x)=\int\limits
_zP(z)P(x|z)dz\)</span>:</p>
<p>当我们保持<span class="math inline">\(P(x|z)\)</span>不变时，<span class="math inline">\(P(z)\)</span>不会变，<span class="math inline">\(P(x)\)</span>也不会变，<span class="math inline">\(\log P(x)\)</span>也不会变</p>
<p>再根据<span class="math inline">\(\log P(x) =
L_b+KL(q(z|x)||P(z|x))\)</span>：</p>
<p>整个<span class="math inline">\(\log P(x)\)</span>的大小不变，<span class="math inline">\(L_b\)</span>越大，KL散度越小，当KL散度减小到零时，<span class="math inline">\(\log P(x)=L_b\)</span>，<strong>而<span class="math inline">\(L_b\)</span>此时只和<span class="math inline">\(q(z|x)\)</span>有关。</strong></p>
<p>此时我们发现：</p>
<p>求<span class="math inline">\(\max \log P(x)\)</span>等价于求<span class="math inline">\(\max L_b\)</span></p>
<aside>
💡 宏观上我们可以将此时的VAE理解为两个部分： 调节<span class="math inline">\(P(x|z)\)</span>，就是在调节NN-Decoder 调节<span class="math inline">\(q(z|x)\)</span>，就是在调节NN-Encoder
</aside>
<blockquote>
<p>VAE算法：Decoder每改进一次，Encoder就调节成与其一致，利用约束条件逼迫Decoder前进</p>
</blockquote>
<p>开始求解<span class="math inline">\(\max L_b\)</span></p>
<p><span class="math display">\[
\begin{aligned}
L_b &amp;= \int \limits _zq(z|x)\log (\frac {P(x|z)P(z)}{q(z|x)})dz \\
&amp;= \int \limits _zq(z|x)\log (\frac {P(z)}{q(z|x)})dz + \int \limits
_zq(z|x)\log P(x|z)dz \\
&amp;=-KL(q(z|x)||P(z))+\int \limits _zq(z|x)\log P(x|z)dz
\end{aligned}
\]</span></p>
<p>记第一项为A，第二项为B，现在求解<span class="math inline">\(L_b\)</span>的最大值，需要求A的最大值（KL散度的最小值），B的最大值</p>
<p>展开A后可以得到约束项：<span class="math inline">\(\min \sum \limits
_{i=1} ^n
(\exp(\sigma_i)-(1+\sigma_i)+\mu_i^2)\)</span>，证明方法来自VAE原论文《Auto-Encoding
Variational Bayes》</p>
<p>求B的最大值：</p>
<p><span class="math display">\[
\max B = \max E_{q(z|x)}[\log P(x|z)]
\]</span></p>
<p>可理解为<strong>提供一个x的值，在<span class="math inline">\(q(z|x)\)</span>这个分布下，让<span class="math inline">\(\log
P(x|z)\)</span>值越大越好，这件事情就是NN-Encoder在做的。</strong></p>
<pre><code class=" mermaid">graph LR
  x --&gt; NN-Encoder --&gt; mu&#x27;
	NN-Encoder --&gt; sigma&#x27;
	mu&#x27;--&gt;z
	sigma&#x27;--&gt;z
	z--&gt;NN-Decoder--&gt;mu
	NN-Decoder--&gt;sigma
	mu .-越接近越好.-&gt; x

</code></pre>
<p>VAE的损失函数的两部分，一是重建损失，二是约束项。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>VAE</tag>
        <tag>生成模型</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络中的优化算法和正则化问题</title>
    <url>/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/</url>
    <content><![CDATA[<blockquote>
<p>本文主要参考邱锡鹏老师的nndl-book，作为笔记使用</p>
<p><a href="https://www.bilibili.com/video/BV19u411d7r3">神经网络与深度学习（第7-10讲）（更新至：第9讲
无监督学习）_哔哩哔哩_bilibili</a></p>
</blockquote>
<h1 id="非凸优化问题">非凸优化问题</h1>
<p>高维空间中常常遇到的都是非凸函数</p>
<p>非凸优化问题中难点有：</p>
<ul>
<li>如何逃离鞍点</li>
<li>会出现平坦最小值</li>
</ul>
<h2 id="鞍点">鞍点</h2>
<p>在某些维度上是最高点,另一些维度上是最低点.其一阶导数为0,二阶梯度Hessian矩阵不是半正定矩阵.</p>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled.png" alt="鞍点示例">
<figcaption aria-hidden="true">鞍点示例</figcaption>
</figure>
<h2 id="平坦最小值">平坦最小值</h2>
<blockquote>
<p>由于DL中的参数非常多且具有冗余,单个参数对最终的损失影响比较小,这会导致损失函数在局部最小解附近通常是一个平坦的区域</p>
</blockquote>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled%201.png" alt="平坦最小值和尖锐最小值">
<figcaption aria-hidden="true">平坦最小值和尖锐最小值</figcaption>
</figure>
<ul>
<li>一个平坦最小值的邻域内,所有点对应的训练损失都比较接近</li>
<li>大部分局部最小解是等价的</li>
<li>局部最小解对应的训练损失有可能非常接近于全局最小解训练损失</li>
</ul>
<aside>
💡
在训练神经网络时,可以用局部最小解代替全局最优解,以防止过拟合,鲁棒性更好
</aside>
<h1 id="神经网络优化算法">神经网络优化算法</h1>
<h2 id="随机梯度下降法sgd">随机梯度下降法(SGD)</h2>
<p>小批量随机梯度下降,每次选择k个样本计算偏导数的平均数,然后在梯度反向上更新参数</p>
<h2 id="批量大小调整">批量大小调整</h2>
<p>不影响梯度的期望,但会影响方差.</p>
<ul>
<li><p>batch越大,方差越小,学习率需要设置较大</p></li>
<li><p>batch越小,需要设置较小的学习率,否则模型不会收敛</p></li>
<li><p>NOTE:batch和学习率可遵守线性缩放原则</p>
<p>batch变为m倍,学习率变为<span class="math inline">\(1/m\)</span></p></li>
</ul>
<aside>
💡
batch越大通常训练的效率越高,batch越小由于随机性更高,可能会获得更好的泛化能力
</aside>
<h2 id="梯度估计修正">梯度估计修正</h2>
<ul>
<li><p>Momentum Method 动量法</p>
<p>用之前累积的动量来代替真正的梯度（负梯度的加权移动平均）</p>
<aside>
<p>💡 每次的迭代方向相当于加速度，类似二阶梯度</p>
</aside>
<p>参数更新的差值为：</p>
<p><span class="math display">\[
  \Delta \theta_t =\rho \Delta \theta_{t-1}-\alpha g_t=-\alpha \sum
\limits _{\tau=1}^{t} \rho^{t-\tau}g_{\tau}
  \]</span></p></li>
<li><p>Nesterov 加速梯度</p></li>
<li><p>梯度截断</p>
<p>当某个时刻梯度（的模）过大如NaN，就把梯度的模限定在某个区间，将超过区间的部分进行截断</p>
<ul>
<li><p>按值截断</p>
<p>例如取<span class="math inline">\([a,b]\)</span>区间的值</p>
<p><span class="math display">\[
  g_t=\max(\min(g_t,b),a)
  \]</span></p></li>
<li><p>按模截断</p>
<p>把模的最大值限定为b</p>
<p><span class="math display">\[
  g_t=\frac{b}{||g_t||}g_t
  \]</span></p></li>
</ul></li>
<li><p>Adam算法</p>
<p>使用动量法优化梯度，加上RMSprop自适应调整学习率</p>
<p>先计算两个移动平均：</p>
<p><span class="math display">\[
  M_t = \beta _1M_{t-1}+(1-\beta_1)g_t
  \]</span></p>
<p><span class="math display">\[
  G_t = \beta_2G_{t-1}+(1-\beta_2)g_t \odot g_t
  \]</span></p>
<p>当t=1时，<span class="math inline">\(M_1\)</span>应该等于<span class="math inline">\(g_1\)</span>，但是在上述公式中不正确，于是加入偏差修正如下：</p>
<p><span class="math display">\[
  \hat M_t = \frac {M_t}{1-\beta_1^t}
  \]</span></p>
<p><span class="math display">\[
  \hat G_t=\frac{G_t}{1-\beta_2^t}
  \]</span></p>
<p>更新参数内容：</p>
<p><span class="math display">\[
  \Delta \theta_t = - \frac{\alpha}{\sqrt {G_t+\epsilon}}\hat M_t
  \]</span></p></li>
</ul>
<h2 id="学习率调整">学习率调整</h2>
<ul>
<li><p>学习率衰减</p>
<ul>
<li>阶梯衰减</li>
<li>逆时衰减:<span class="math inline">\(\alpha_t = \alpha_0
\frac{1}{1+\beta \times t}\)</span></li>
<li>指数衰减</li>
<li>余弦衰减</li>
</ul></li>
<li><p>周期性学习率调整</p>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled%202.png" alt="周期性学习率调整">
<figcaption aria-hidden="true">周期性学习率调整</figcaption>
</figure>
<p>跳出局部最优或鞍点的情况,找到更平坦的局部最优</p></li>
<li><p>学习率预热</p>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled%203.png" alt="学习率预热示例">
<figcaption aria-hidden="true">学习率预热示例</figcaption>
</figure></li>
<li><p>AdaGrad算法</p>
<p>借鉴L2正则化的思想，在第t次迭代的时候，先计算每个参数梯度平方的累计值。</p>
<p><span class="math display">\[
  G_t=\sum \limits _{\tau}^{t}g_{\tau}\odot g_{\tau}
  \]</span></p>
<p>参数更新的差值为：</p>
<p><span class="math display">\[
  \Delta \theta _{t} = - \frac {\alpha}{\sqrt {G_t+\epsilon}}\odot g_t
  \]</span></p>
<p>其中<span class="math inline">\(\alpha\)</span>是初始学习率，<span class="math inline">\(\epsilon\)</span>是为保持数值稳定一个小常数（大小通常是<span class="math inline">\(e^{-7}\sim
e^{-10}\)</span>），公式内的运算都是按元素进行的操作。</p>
<blockquote>
<p>from nndl-book:</p>
<p>在 AdaGrad
算法中，如果某个参数的偏导数累积比较大，其学习率相对较小;相反，如果其偏导数累积较小，其学习率相对较大.但整体是随着迭代次数的增加，学习率逐渐缩小.
AdaGrad
算法的缺点是在经过一定次数的迭代依然没有找到最优点时，由于这时的学习率已经非常小，很难再继续找到最优点.</p>
</blockquote></li>
<li><p>RMSprop算法</p>
<p>避免AdaGrad算法中学习率不断单调下降导致过早衰减的问题。</p>
<p>参数更新的差值和AdaGrad算法是相同的：</p>
<p><span class="math display">\[
  \Delta \theta _{t} = - \frac {\alpha}{\sqrt {G_t+\epsilon}}\odot g_t
  \]</span></p>
<p>区别在于计算<span class="math inline">\(G_t\)</span>:</p>
<p><span class="math display">\[
  \begin{aligned}
  G_{t} &amp;=\beta G_{t-1}+(1-\beta) \boldsymbol{g}_{t} \odot
\boldsymbol{g}_{t} \\
  &amp;=(1-\beta) \sum_{\tau=1}^{t} \beta^{t-\tau} \boldsymbol{g}_{\tau}
\odot \boldsymbol{g}_{\tau}
  \end{aligned}
  \]</span></p>
<p>由于参数的学习率变化由单调衰减变成了指数加权的移动平均，既可以变大也可以变小。</p></li>
<li><p>AdaDelta算法</p>
<p>参数更新的差值为：</p>
<p><span class="math display">\[
  \Delta \theta_{t}=-\frac{\sqrt{\Delta
X_{t-1}^{2}+\epsilon}}{\sqrt{G_{t}+\epsilon}} \mathbf{g}_{t}
  \]</span></p>
<p>其中<span class="math inline">\(G_t\)</span>和RMSprop算法相同：</p>
<p><span class="math display">\[
  \begin{aligned}
  G_{t} &amp;=\beta G_{t-1}+(1-\beta) \boldsymbol{g}_{t} \odot
\boldsymbol{g}_{t} \\
  &amp;=(1-\beta) \sum_{\tau=1}^{t} \beta^{t-\tau} \boldsymbol{g}_{\tau}
\odot \boldsymbol{g}_{\tau}
  \end{aligned}
  \]</span></p>
<p>分子上：</p>
<p><span class="math display">\[
  \Delta X_{t-1}^{2}=\beta_{1} \Delta
X_{t-2}^{2}+\left(1-\beta_{1}\right) \Delta \theta_{t-1} \odot \Delta
\theta_{t-1}
  \]</span></p>
<p>其中<span class="math inline">\(\beta _1\)</span>是衰减率</p>
<p>由于将原本的学习率修改为了带衰减率的移动平均，能够抑制住学习率的波动。</p></li>
</ul>
<h2 id="参数初始化">参数初始化</h2>
<p>当使用梯度下降法优化网络参数时，参数的初始值非常重要，直接影响到网络的优化效率和泛化能力</p>
<p>神经网络的参数不能初始化为0，会出现对称权重问题，导致层内所有权重相同。</p>
<p>因此对于参数的初始化也有许多方法。</p>
<ul>
<li>预训练初始化</li>
<li>随机初始化
<ul>
<li><p>基于固定方差的参数初始化</p>
<ul>
<li><p>高斯分布初始化</p>
<p>使用方差和均值的高斯分布</p></li>
<li><p>均匀分布初始化</p>
<p>采用在区间<span class="math inline">\([-r,r]\)</span>内采用均匀分布进行初始化</p></li>
</ul></li>
<li><p>基于方差缩放的参数初始化</p>
<p><span class="math inline">\(M_l\)</span>是第<span class="math inline">\(l\)</span>层的神经元个数</p>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled%204.png" alt="基于方差缩放的参数初始化设置">
<figcaption aria-hidden="true">基于方差缩放的参数初始化设置</figcaption>
</figure></li>
<li><p>正交初始化</p>
<p>由于上述两种初始化对每个参数都是独立采样，依旧存在梯度消失或梯度爆炸问题。</p>
<p>此处我们从最开始就构建一个L层的等宽线性网络：</p>
<p><span class="math display">\[
  \bold y= \bold W^L \bold W^{L-1} \dots \bold W^1 \bold x
  \]</span></p>
<p>在反向传播中误差项<span class="math inline">\(\delta\)</span>的反向传播公式为：<span class="math inline">\(\delta ^{l-1}=(W^l)^T\delta ^l\)</span></p>
<p><strong>范数保持性：</strong>指误差项在反向传播中的范数保持不变，满足<span class="math inline">\(||\delta^{l-1}||^2=||\delta^l||^2=||(W^l)^T\delta^l||^2\)</span>。</p>
<p>于是在初始化就可以使用均值为0，方差为<span class="math inline">\(1/M\)</span>的高斯分布来做初始化</p>
<hr>
<p>或者采用更直接的方式：直接将 <span class="math inline">\(W^l\)</span>初始化为正交矩阵，即<span class="math inline">\(W^l(W^l)^T=I\)</span></p>
<ol type="1">
<li>y地方用均值为0，方差为1的高斯分布初始化一个矩阵</li>
<li>将这个矩阵用奇异值分解得到两个正交矩阵，用其中之一作为权重矩阵</li>
</ol>
<aside>
<p>💡 正交初始化通常用在RNN的循环边上的权重矩阵</p>
</aside></li>
</ul></li>
</ul>
<h2 id="数据预处理">数据预处理</h2>
<h3 id="尺度不变性scale-invariance">尺度不变性（Scale Invariance）</h3>
<p>对于机器算法中的数据，在缩放部分特征或者全部特征后，不影响学习和预测。</p>
<p>例如：将厘米单位的特征，缩放为毫米单位。</p>
<p><em>NOTE:KNN算法的尺度不变性较差，因为其计算的欧式距离对数据要求高</em></p>
<p>不同输入特征的尺度差异较大会带来两个问题：</p>
<ol type="1">
<li>参数初始化困难</li>
<li>优化效率较低</li>
</ol>
<h3 id="归一化规范化-normalization">归一化（规范化 Normalization）</h3>
<ul>
<li><p><strong>最小最大值规范化</strong>：</p>
<p>找到数据中的最小最大值，将所有数据缩放到这个范围内</p></li>
<li><p><strong>标准化（Z值规范化）</strong>：</p>
<p>对每一维数据计算均值和方差</p>
<p><span class="math display">\[
  \mu = \frac{1}{N} \sum \limits _{n=1}^Nx^n
  \]</span></p>
<p><span class="math display">\[
  \sigma ^2 = \frac{1}{N}\sum \limits _{n=1}^N (x^n-\mu)^2
  \]</span></p>
<p>然后将特征<span class="math inline">\(x^n\)</span>进行变换：</p>
<p><span class="math display">\[
  \hat x^n = \frac{x^n-\mu}{\sigma}
  \]</span></p>
<p>标准差<span class="math inline">\(\sigma\)</span>做分母不为零的含义：</p>
<p>表示这一维度的特征相同，不重要可以直接去掉</p></li>
<li><p><strong>白化（whitening，PCA）</strong>:</p>
<p>去除所有成分之间的相关性</p>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled%205.png" alt="标准化和白化">
<figcaption aria-hidden="true">标准化和白化</figcaption>
</figure></li>
</ul>
<h3 id="逐层规范化">逐层规范化</h3>
<p>ML中的常用方法，应用到DL的目的是：</p>
<ol type="1">
<li><p>更好的尺度不变性</p>
<p>解决内部协变量偏移问题，防止在深度学习中某一个层的输入分布的微小变化引起更深层中的较大偏移。</p></li>
<li><p>更平滑的优化地形</p></li>
</ol>
<ul>
<li>规范化方法
<ul>
<li><p><strong>批量规范化（Batch Normalization）</strong></p>
<p>对于一个神经网络，第<span class="math inline">\(l\)</span>层的净输入为<span class="math inline">\(z^l\)</span>，神经元的输出为<span class="math inline">\(a^l\)</span>，即：</p>
<p><span class="math display">\[
  a^l = f(z^l)=f(Wa^{l-1}+b)
  \]</span></p>
<p>对于一个样本数为k的批量样本，计算其方差和均值：</p>
<p><span class="math display">\[
  \begin{aligned}
  &amp;\boldsymbol{\mu}_{\mathcal{B}}=\frac{1}{K} \sum_{k=1}^{K}
\boldsymbol{z}^{(k, l)} \\
  &amp;\boldsymbol\sigma_{\mathcal{B}}^{2}=\frac{1}{K}
\sum_{k=1}^{K}\left(\boldsymbol{z}^{(k,
l)}-\boldsymbol{\mu}_{\mathcal{B}}\right) \odot\left(\boldsymbol{z}^{(k,
l)}-\boldsymbol{\mu}_{\mathcal{B}}\right) .
  \end{aligned}
  \]</span></p>
<p>批量规范化：</p>
<p><span class="math display">\[
  \begin{aligned}
  \hat{\boldsymbol{z}}^{l}
&amp;=\frac{\boldsymbol{z}^{l}-\mu_{\mathcal{B}}}{\sqrt{\sigma_{\mathcal{B}}^{2}+\epsilon}}
\odot \boldsymbol{\gamma}+\boldsymbol{\beta} \\
  &amp; \triangleq \mathrm{BN}_{\gamma,
\boldsymbol{\beta}}\left(\boldsymbol{z}^{l}\right),
  \end{aligned}
  \]</span></p>
<p>其中<span class="math inline">\(\boldsymbol{\gamma}\)</span>是缩放参数向量，<span class="math inline">\(\boldsymbol{\beta}\)</span>是平移参数向量，都是可学习参数。能够增强规范化的能力。</p>
<aside>
<p>💡 批量规范化可以作为神经网络的一层（BN层）直接加入网络结构中。</p>
</aside></li>
<li><p><strong>层规范化（Layer Normalization）</strong></p>
<p>不看batch的内容，对一层内所有神经元进行规范化</p>
<p>计算层内均值和方差：</p>
<p><span class="math display">\[
  \begin{aligned}
  \mu^{l} &amp;=\frac{1}{M_{l}} \sum_{i=1}^{M_{l}} z_{i}^{l} \\
  (\sigma^{l})^{2} &amp;=\frac{1}{M_{l}}
\sum_{i=1}^{M_{l}}\left(z_{i}^{l}-\mu^{l}\right)^{2}
  \end{aligned}
  \]</span></p>
<p>层规范化：</p>
<p><span class="math display">\[
  \begin{aligned}
  \hat{\boldsymbol{z}}^{l}
&amp;=\frac{\boldsymbol{z}^{l}-\mu^{l}}{\sqrt{(\sigma^{(l)})^{2}+\epsilon}}
\odot \boldsymbol{\gamma}+\boldsymbol\beta \\
  &amp; \triangleq \mathrm{LN}_{\boldsymbol {\gamma,
\beta}}\left(\boldsymbol{z}^{l}\right)
  \end{aligned}
  \]</span></p>
<aside>
<p>💡
层规范化也可以作为神经网络的一层（LN层）直接加入网络结构中。应用较多。</p>
</aside>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled%206.png" alt="BN和LN的区别">
<figcaption aria-hidden="true">BN和LN的区别</figcaption>
</figure>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled%207.png" alt="各种规范化的对比">
<figcaption aria-hidden="true">各种规范化的对比</figcaption>
</figure></li>
<li><p>权重规范化</p></li>
<li><p>局部响应规范化</p></li>
</ul></li>
</ul>
<h2 id="超参数优化">超参数优化</h2>
<h3 id="超参数">超参数</h3>
<ul>
<li>层数</li>
<li>每层神经元个数</li>
<li>激活函数</li>
<li>学习率（以及动态调整算法）</li>
<li>正则化系数</li>
<li>mini-batch大小</li>
</ul>
<h3 id="优化方法">优化方法</h3>
<ul>
<li><p>网格搜索</p>
<p>对每一个超参数取几个”经验值“，比如对于学习率<span class="math inline">\(\alpha\)</span>，可以设置</p>
<p><span class="math display">\[
  \alpha  \in \{0.01,0.1,0.5,1.0\}
  \]</span></p></li>
<li><p>随机搜索</p>
<p>对超参数进行随机组合</p></li>
<li><p>贝叶斯优化</p></li>
<li><p>动态资源分配</p></li>
<li><p>神经架构搜索</p></li>
</ul>
<h2 id="网络正则化">网络正则化</h2>
<p>由于神经网络的拟合能力强，会将模型过度参数化，会导致模型泛化性差。为提高神经网络的泛化能力通常要加入正则化。</p>
<p><strong>正则化</strong>就是所有损害优化方法的方法。通常分为两种方式：</p>
<ol type="1">
<li>增加优化约束：L1、L2约束</li>
<li>干扰优化过程：提前停止、随机梯度下降、暂退法、权重衰减。</li>
</ol>
<h3 id="早停法">早停法</h3>
<p>引入<strong>验证集（Validation
Dataset）</strong>测试每一次迭代的参数时候在验证集上最优，如果在验证集上错误率不再下降就停止迭代。防止过拟合。</p>
<h3 id="权重衰减">权重衰减</h3>
<p>限制权重取值范围。在每次参数更新时，引入一个衰减系数<span class="math inline">\(\beta\)</span></p>
<p><span class="math display">\[
\theta_t=(1-\beta)\theta_{t-1}-\alpha \bold g_t
\]</span></p>
<h3 id="暂退法dropout">暂退法（Dropout）</h3>
<p>有一个神经层<span class="math inline">\(y=f(Wx+b)\)</span>，引入一个随机的掩蔽函数<span class="math inline">\(mask(x)=m\odot x\)</span>，<span class="math inline">\(m \in \{0,1\}^D\)</span>.得到神经层的输出<span class="math inline">\(y=f(Wmask(x)+b)\)</span>.</p>
<aside>
💡
可以理解为从原始网络中采样得到一个子网络，如果有n个神经元，则可以采样出<span class="math inline">\(2^n\)</span>个子网络。
</aside>
<h3 id="ell_1和ell_2正则化"><span class="math inline">\(\ell_1\)</span>和<span class="math inline">\(\ell_2\)</span>正则化</h3>
<p>在原本的优化问题中加入<span class="math inline">\(\ell_1\)</span><span class="math inline">\(\ell_2\)</span>范数防止过拟合</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\theta^{*}=\underset{\theta}{\arg \min } \frac{1}{N} \sum_{n=1}^N
\mathcal{L}\left(y^{(n)}, f\left(\boldsymbol{x}^{(n)} ;
\theta\right)\right) \\
&amp;\text { s.t. } \quad \ell_{p}(\theta) \leq 1
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\ell_2\)</span>正则化的参数更新结果为：<span class="math inline">\(\theta_t =
\theta_{t-1}-\alpha(g_t+\lambda\theta_{t-1})=(1-\alpha\lambda)\theta_{t-1}-\alpha
g_t\)</span></p>
<p>形式上和权重衰减的类似：<span class="math inline">\(\theta_t=(1-\beta)\theta_{t-1}-\alpha \bold
g_t\)</span></p>
<aside>
💡 在SGD中 <span class="math inline">\(\ell_2\)</span>
正则化和权重衰减是等价的，但在复杂的优化算法如Adam中则不能等价。
</aside>
<figure>
<img src="/2022/07/31/shen-jing-wang-luo-zhong-de-you-hua-suan-fa-he-zheng-ze-hua-wen-ti/Untitled%208.png" alt="不同范数的约束条件示例">
<figcaption aria-hidden="true">不同范数的约束条件示例</figcaption>
</figure>
<h1 id="总结">总结</h1>
<table>

<thead>
<tr class="header">
<th>模型</th>
<th>优化</th>
<th>正则化</th>
<th>隐式正则化</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>用ReLU作为激活函数</td>
<td>SGD+mini-batch(动态学习率、Adam算法优先)</td>
<td>早停法</td>
<td>SGD</td>
</tr>
<tr class="even">
<td>残差链接</td>
<td>每次迭代都重新随机排序</td>
<td>暂退法</td>
<td>批量规范化</td>
</tr>
<tr class="odd">
<td>逐层规范化</td>
<td>数据预处理（规范化）</td>
<td>权重衰减</td>
<td><span class="math inline">\(\ell_1\)</span>和<span class="math inline">\(\ell_2\)</span>正则化</td>
</tr>
<tr class="even">
<td></td>
<td>参数初始化（预训练）</td>
<td></td>
<td>数据增强</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>DL</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>虚拟局域网技术VLAN解析</title>
    <url>/2022/10/17/xu-ni-ju-yu-wang-ji-zhu-vlan-jie-xi/</url>
    <content><![CDATA[<h1 id="虚拟局域网技术">虚拟局域网技术</h1>
<p>## 前言</p>
<p>工作在数据链路层的以太网交换机由于以太网规模的扩大导致广播域扩大，造成的<u>广播风暴</u>可能会导致网络瘫痪。</p>
<p>广播信息的来源主要是涉及到地址解析、名称解析的行为：</p>
<ol type="1">
<li>网络层
TCP/IP协议栈中的协议：地址解析协议ARP，路由信息协议RIP，DHCP</li>
<li>会话层协议：网上基本输入输出系统NETBIOS</li>
<li>应用层协议：链路本地多播名称解析LLMNR</li>
</ol>
<p>网络中的广播信息无处不在，想要克制不去使用是<strong>不现实的</strong>，因此我们应该想办法减小广播的影响范围即广播域。</p>
<p>对于网络负载过高、通信性能下降的情况，往往需要管理员手动更改网络拓扑结构，如变更主机网段、硬件线路改造等。出现VLAN之后就<strong>只需要修改网络结构</strong>。</p>
<h2 id="定义">定义</h2>
<p>虚拟局域网（Virtual
LAN,VLAN），是将一个物理的LAN在逻辑上划分成多个广播域的通信技术。每个VLAN是一个广播域，VLAN内的主机间通信就和在一个LAN内一样，而VLAN间则不能直接互通，这样，广播报文就被限制在一个VLAN内。</p>
<h2 id="实现">实现</h2>
<h1 id="虚拟扩展局域网">虚拟扩展局域网</h1>
<h2 id="vlan的限制">VLAN的限制</h2>
<p>传统VLAN标识ID字段的VID只有12bit，最多能取4094个值，对于大型的应用场景能力有限。</p>
<h2 id="vxlan">VXLAN</h2>
<h3 id="定义-1">定义</h3>
<p>本质上是隧道技术。</p>
<h3 id="原理解析">原理解析</h3>
<h2 id="优缺点">优缺点</h2>
<h2 id="虚拟局域网技术展望">虚拟局域网技术展望</h2>
<h1 id="虚拟局域网实验">虚拟局域网实验</h1>
<p>把一个物理网络从逻辑上划分为几个单独的局域网</p>
<h2 id="没有划分vlan的网络">没有划分VLAN的网络</h2>
<h2 id="划分vlan的网络">划分VLAN的网络</h2>
<h2 id="vlan之间互通">VLAN之间互通</h2>
]]></content>
  </entry>
  <entry>
    <title>使用wireguard搭建属于自己的虚拟内网</title>
    <url>/2022/10/16/shi-yong-wireguard-da-jian-shu-yu-zi-ji-de-xu-ni-nei-wang/</url>
    <content><![CDATA[<h1 id="使用wireguard搭建属于自己的虚拟内网">使用wireguard搭建属于自己的虚拟内网</h1>
<blockquote>
<p>本文将使用wireguard的docker镜像，借助中转服务器，快速方便的部署出一个属于自己的虚拟内网，网内地址完全自定义，支持全平台。</p>
</blockquote>
<h2 id="wireguard结果展示">wireguard结果展示</h2>
<p>wireguard分为服务端和客户端，其中服务端需要部署在有公网IP的服务器上，需要加入内网的设备需要单独安装客户端并启动。</p>
<p>在部署完成后是这样的效果：</p>
<figure>
<img src="/2022/10/16/shi-yong-wireguard-da-jian-shu-yu-zi-ji-de-xu-ni-nei-wang/部署完成测速.png" alt="部署完成测速">
<figcaption aria-hidden="true">部署完成测速</figcaption>
</figure>
<p>右侧测速结果显示5.67/5.63Mbps，<strong>跑满</strong>了我的中转服务器的<strong>6Mbps</strong>，速度还是十分给力的。</p>
<p>在手机上我也可以直接通过<strong>内网IP</strong>在外面访问到NAS中的数据：</p>
<p><img src="/2022/10/16/shi-yong-wireguard-da-jian-shu-yu-zi-ji-de-xu-ni-nei-wang/手机上的群晖.PNG" alt="手机上的群晖" style="zoom:33%;"></p>
<p>同时配置在lab内网的个人服务器也可以直接用内网ssh访问，这一点和配置frp的效果倒是相同的。不过我认为wireguard强大就在于，不用像frp每个需要开放的端口都得配置，然后在中转服务器开端口。wireguard本体只需要在中转服务器开一个UDP端口就可以使用内网访问其他客户端所有的端口。这在做调试工作时会方便许多。</p>
<figure>
<img src="/2022/10/16/shi-yong-wireguard-da-jian-shu-yu-zi-ji-de-xu-ni-nei-wang/image-20221016121811707.png" alt="访问虚拟内网中的hadoop">
<figcaption aria-hidden="true">访问虚拟内网中的hadoop</figcaption>
</figure>
<blockquote>
<p>虽然lab内的环境更舒适，但总是想随时访问某些服务的冲动我想好多人都会有吧哈哈哈哈哈</p>
</blockquote>
<h2 id="快速搭建wireguard">快速搭建wireguard</h2>
<blockquote>
<p>搭建过程也可以参考：https://gitee.com/spoto/wireguard</p>
</blockquote>
<p>本文使用<code>weejewel/wg-easy</code>的docker镜像快速搭建起可用的虚拟内网。</p>
<p>首先登陆中转服务器，我这里使用的是腾讯云上的ubuntu服务器，将下面的命令改好后直接运行（IP、密码、网段都需要填自己的哦）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo docker run -d \<br>  --name=wg-easy \<br>  -e WG_HOST=123.123.123.123 (🚨这里输入服务器的公网IP) \<br>  -e PASSWORD=passwd123 (🚨这里输入你的密码) \<br>  -e WG_DEFAULT_ADDRESS=10.0.8.x （🚨默认IP地址）\<br>  -e WG_ALLOWED_IPS=10.0.8.0/24 （🚨允许连接的IP段）\<br>  -e WG_PERSISTENT_KEEPALIVE=25 （🚨重连间隔）\<br>  -v ~/.wg-easy:/etc/wireguard \<br>  -p 51820:51820/udp \<br>  -p 51821:51821/tcp \<br>  --cap-add=NET_ADMIN \<br>  --cap-add=SYS_MODULE \<br>  --sysctl=<span class="hljs-string">&quot;net.ipv4.conf.all.src_valid_mark=1&quot;</span> \<br>  --sysctl=<span class="hljs-string">&quot;net.ipv4.ip_forward=1&quot;</span> \<br>  --restart unless-stopped \<br>  weejewel/wg-easy<br></code></pre></td></tr></table></figure>
<p>运行起来之后记得开启两个设置过的端口，一个udp一个tcp，然后可以根据tcp端口登陆到管理界面，输入刚才设置的密码，这就是这个镜像的方便快捷之处，减少了手动创建配置的过程。</p>
<figure>
<img src="/2022/10/16/shi-yong-wireguard-da-jian-shu-yu-zi-ji-de-xu-ni-nei-wang/image-20221016122810680.png" alt="创建完成配置完成后的样子">
<figcaption aria-hidden="true">创建完成配置完成后的样子</figcaption>
</figure>
<p>我这里显示的就是配置客户端之后的样子，一开始进来还什么都没有，先点击<code>+New</code>创建一个新的配置。</p>
<ol type="1">
<li><p>如果不熟悉的话可以先用手机下载对应的客户端（名字就是wireguard），然后扫码添加配置，就进入到内网了。</p></li>
<li><p>如果是Mac和Windows也是一样的配置方法：</p>
<ul>
<li>先下载客户端，Mac直接在appstore搜索wireguard，港区可以点这里<a href="https://apps.apple.com/hk/app/wireguard/id1451685025?mt=12">港区wireguard链接</a></li>
<li>下载管理界面的配置文件xxx.conf</li>
<li>客户端内添加隧道，选择xxx.conf</li>
<li>开启隧道链接，进入内网，可以<code>ping</code>命令查看是否通畅</li>
</ul></li>
<li><p>如果你想把ubuntu等服务器加入wireguard:</p>
<ul>
<li>在Ubuntu上要下载客户端<code>sudo apt install wireguard</code></li>
<li>下载管理界面的配置文件xxx.conf</li>
<li>scp上传conf文件到ubuntu，或者直接在ubuntu上新建文档将内容复制进去，保证文件名一样</li>
<li><code>sudo wg-quick up xxx</code>开启配置，<code>sudo wg-quick down xxx</code>关闭配置</li>
<li><code>sudo wg</code>可以查看wireguard开启的服务。</li>
</ul>
<figure>
<img src="/2022/10/16/shi-yong-wireguard-da-jian-shu-yu-zi-ji-de-xu-ni-nei-wang/image-20221016161236707.png" alt="wireguard查看当前开放的虚拟网卡">
<figcaption aria-hidden="true">wireguard查看当前开放的虚拟网卡</figcaption>
</figure></li>
<li><p>如果你想把NAS加入wireguard(以群晖为例)：</p>
<ul>
<li><p>群晖的套件中心功能不多，需要加入社群扩展，点击套件中心-设置-套件来源-新增，名称随意，位置https://spk7.imnks.com/</p>
<figure>
<img src="/2022/10/16/shi-yong-wireguard-da-jian-shu-yu-zi-ji-de-xu-ni-nei-wang/image-20221016162618677.png" alt="群晖内的套件中心">
<figcaption aria-hidden="true">群晖内的套件中心</figcaption>
</figure></li>
<li><p>在社群中搜索wireguard安装，需要ssh到群晖上执行<code>sudo sed -i 's/package/root/g' /var/packages/WireGuard/conf/privilege</code></p></li>
<li><p>后面步骤同Ubuntu，只是省略了安装apt安装的步骤。</p></li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>内网</tag>
        <tag>wireguard</tag>
      </tags>
  </entry>
  <entry>
    <title>ESXi6.7安装Realtek8125bg四口网卡驱动并直通</title>
    <url>/2023/10/11/esxi6-7-an-zhuang-realtek8125bg-si-kou-wang-qia-qu-dong-bing-zhi-tong/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>众所周知，螃蟹网卡Realtek在ESXi7之后的版本都不被支持，虽然也有一些邪道方法安装上去，不过都是更推荐Intel网卡，但是架不住螃蟹网卡太便宜了，没有钱是我的问题。。。正好手上的ESXi是6.7版本，只需要安装下对应的驱动就可以使用。和PCIe四口网卡一起还配了一个单口的全高8125网卡给Manjaro，一个USB网卡给Mac，简单组建了一下2.5G内网，把固态硬盘的速度利用起来，也不需要花费太多，一共只需要不到400元完成升级。</p>
<p>下文介绍如何在ESXi中安装8125的驱动并将网卡直通给虚拟机使用。</p>
<h1 id="一找驱动">一、找驱动</h1>
<p>ESXi的驱动还在更新，不过
GitHub这位大佬没有更新了2022年之后的版本，相对旧了一点，不过也提供了完整的编译源码，等后续用着不顺利可以考虑手动编译一下</p>
<p><strong>驱动下载：</strong></p>
<p>https://github.com/realganfan/r8125-esxi/releases/tag/9.007.01-1</p>
<p>压缩包解压出来是一个vib文件，就是我们需要安装的文件</p>
<p><img src="/2023/10/11/esxi6-7-an-zhuang-realtek8125bg-si-kou-wang-qia-qu-dong-bing-zhi-tong/image-20231012001229001-7040756.png" alt="等待安装的vib文件" style="zoom: 50%;"></p>
<h1 id="二安装驱动">二、安装驱动</h1>
<p>先在ESXi网页中开启SSH服务，在本地通过scp命令上传上面的vib文件到<code>/tmp</code>文件夹下（任意位置都行）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">scp 本地vib文件路径/xxx.vib root@ESXiIP:/tmp/ <br></code></pre></td></tr></table></figure>
<p>然后ssh登陆到后台，cd到/tmp文件夹下执行命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">vmware -vl #查看系统具体版本<br>esxcli software -h #帮助指南<br><br>esxcli software vib install -v /tmp/Realtek_bootbank_net-r8125_9.007.01-1.vib<br></code></pre></td></tr></table></figure>
<p><img src="/2023/10/11/esxi6-7-an-zhuang-realtek8125bg-si-kou-wang-qia-qu-dong-bing-zhi-tong/iShot_2023-10-10_22.54.41-7041025.png" alt="详细指令" style="zoom:50%;"></p>
<p>上面vib的路径名称一定要完整，是绝对路径，不然会安装失败</p>
<p>如果输出内容如图所示则安装成功，直接重启后就能够在硬件中找到4个网卡～</p>
<h1 id="三直通">三、直通</h1>
<p>在硬件里可以直接选中网卡点击切换直通，切换后需要重新引导系统识别（相当于重启），然后在ESXi网络适配器中就无法再见到这几个网卡了，不用慌张。</p>
<p>然后我们进入需要用直通网卡的虚拟机，这时候需要退出ESXi的维护模式才能编辑虚拟机。</p>
<p><img src="/2023/10/11/esxi6-7-an-zhuang-realtek8125bg-si-kou-wang-qia-qu-dong-bing-zhi-tong/iShot_2023-10-11_09.27.52-7041509.png" alt="添加网卡到虚拟机" style="zoom: 50%;"></p>
<p>添加PCIe网卡需要从PCI设备中添加，这里我把4个网口都添加了进去。</p>
<p>值得一提的是一开始我这里PCI设备是<strong>灰色</strong>无法添加的，实际上需要多一步操作：</p>
<p>在管理-系统-高级设置里搜ACSC，然后把第一个选项选中点击编辑选项</p>
<figure>
<img src="/2023/10/11/esxi6-7-an-zhuang-realtek8125bg-si-kou-wang-qia-qu-dong-bing-zhi-tong/iShot_2023-10-11_09.22.31-7041617.png" alt="修改ACS检查">
<figcaption aria-hidden="true">修改ACS检查</figcaption>
</figure>
<p>将它修改为True：</p>
<p><img src="/2023/10/11/esxi6-7-an-zhuang-realtek8125bg-si-kou-wang-qia-qu-dong-bing-zhi-tong/iShot_2023-10-11_09.22.42-7041699.png" alt="设置关闭检查" style="zoom:50%;"></p>
<p>这样就能正常添加PCI设备到虚拟机了。</p>
<p>还有需要注意的一点是，一定要勾选预留全部内存：</p>
<p><img src="/2023/10/11/esxi6-7-an-zhuang-realtek8125bg-si-kou-wang-qia-qu-dong-bing-zhi-tong/iShot_2023-10-11_09.30.52-7041763.png" alt="勾选这里" style="zoom:50%;"></p>
<blockquote>
<p>实际上如果没有勾选这里根本没法启动虚拟机～相当于把固定的内存划分给这个虚拟机</p>
</blockquote>
<p>然后开机后就可以在系统中找到这几个新的网卡了。如果你的系统也是OpenWrt那么不用关心一开始显示的半双工，连接握手后会正常显示握手速率，只要测速没有问题，显示什么无所谓。</p>
<h1 id="后言">后言</h1>
<p>这几个8125的网卡在ESXi中不支持SR-IOV技术，刚在系统中发现之后不免还是有些失落，这就是便宜的代价～不过已经很满意了，至少看到OpenWrt里的测速数字增长的喜悦是真的。。。</p>
<p><img src="/2023/10/11/esxi6-7-an-zhuang-realtek8125bg-si-kou-wang-qia-qu-dong-bing-zhi-tong/iShot_2023-10-11_10.20.28-7042144.png" alt="后续长时间连续测试也能够达到速度" style="zoom:50%;"></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>虚拟机</tag>
        <tag>ESXi</tag>
      </tags>
  </entry>
</search>
